{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kindNum</th>\n",
       "      <th>neuterYn</th>\n",
       "      <th>sexCd</th>\n",
       "      <th>weight</th>\n",
       "      <th>noticeDays</th>\n",
       "      <th>age2</th>\n",
       "      <th>processState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.0</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>7.46</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.0</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22787</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22788</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22789</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22790</th>\n",
       "      <td>128.0</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>6.00</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22791</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22777 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       kindNum neuterYn sexCd  weight  noticeDays  age2  processState\n",
       "0        128.0        N     F    7.46          10    12             0\n",
       "1        114.0        N     M    7.00          14     1             1\n",
       "2        114.0        U     M    4.50          11     2             0\n",
       "3         67.0        N     M   10.00           8     1             0\n",
       "4        114.0        N     M    6.00           8     4             0\n",
       "...        ...      ...   ...     ...         ...   ...           ...\n",
       "22787    114.0        N     M    1.00          10     0             1\n",
       "22788    114.0        N     M    1.00          10     0             1\n",
       "22789    114.0        N     M    1.00          10     0             1\n",
       "22790    128.0        U     F    6.00          12     3             0\n",
       "22791    114.0        N     M    3.50          10     0             0\n",
       "\n",
       "[22777 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doginfo.csv파일 데이터를 pandas를 이용해 읽어옵니다.\n",
    "dog_data=pd.read_csv(\"doginfo.csv\")\n",
    "dog_train=pd.read_csv(\"testDog.csv\")\n",
    "kindCd=pd.read_csv(\"kindCd.csv\")\n",
    "\n",
    "dog_data = dog_data.dropna(axis=0)\n",
    "dog_train = dog_train.dropna(axis=0)\n",
    "kindCd_data = kindCd.dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54.  56.  55. 118. 115.  37.  81. 204.  83.  82.  38.  39.  40.  43.\n",
      "  42. 153.  41. 120. 155.  69.  71. 142.  93. 167.  70. 166.  94. 121.\n",
      " 152.  73. 146.  72. 159.  76.  75.  79.  78.  77.  74.  80. 114. 133.\n",
      "  12.  17.  15. 164. 157. 148.  16.  20.  21.  22.  24. 208.  23.  26.\n",
      "  27. 169.  25.  19.  13.  18.  14. 162.  85.  96.  95.   1.  34. 104.\n",
      "  31.  99. 122. 123.  97. 132. 105. 154. 124. 100. 103. 151. 139. 101.\n",
      " 102.  98. 136. 202. 160. 203.   8. 131.   9. 119. 150. 210.  57.  58.\n",
      "  59.   6.   4.   7.   5. 143.  11.  10. 137.  84. 163. 112. 113. 149.\n",
      " 211. 110. 205. 108. 109.  60.  46.  47.  44.  45.  53.  62.  61.  52.\n",
      " 165.  51. 156. 129.  67.  35.  33.  32. 158. 144.  30.  29.  64. 207.\n",
      "  28.   2.  68. 125. 141. 145.  36.  66.  65.  63. 140. 107. 106. 209.\n",
      "  86.  88.  90.  87. 138.  89. 126. 127. 128.  91.   3. 161.  50. 168.\n",
      "  49. 147.  92.  48. 135. 206. 130. 134. 111.]\n",
      "(177,)\n"
     ]
    }
   ],
   "source": [
    "kindCd = np.array(kindCd_data, dtype = np.float64)\n",
    "kindCd_train=np.array(kindCd_data, dtype=np.float64)\n",
    "\n",
    "kindCd = kindCd.reshape(177)\n",
    "kindCd_train=kindCd_train.reshape(177)\n",
    "print(kindCd)\n",
    "print(kindCd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuterYn</th>\n",
       "      <th>sexCd</th>\n",
       "      <th>weight</th>\n",
       "      <th>noticeDays</th>\n",
       "      <th>age2</th>\n",
       "      <th>processState</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>202.0</th>\n",
       "      <th>203.0</th>\n",
       "      <th>204.0</th>\n",
       "      <th>205.0</th>\n",
       "      <th>206.0</th>\n",
       "      <th>207.0</th>\n",
       "      <th>208.0</th>\n",
       "      <th>209.0</th>\n",
       "      <th>210.0</th>\n",
       "      <th>211.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>7.46</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22787</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22788</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22789</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22790</th>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>6.00</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22791</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22777 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neuterYn sexCd  weight  noticeDays  age2  processState  1.0  2.0  3.0  \\\n",
       "0            N     F    7.46          10    12             0    0    0    0   \n",
       "1            N     M    7.00          14     1             1    0    0    0   \n",
       "2            U     M    4.50          11     2             0    0    0    0   \n",
       "3            N     M   10.00           8     1             0    0    0    0   \n",
       "4            N     M    6.00           8     4             0    0    0    0   \n",
       "...        ...   ...     ...         ...   ...           ...  ...  ...  ...   \n",
       "22787        N     M    1.00          10     0             1    0    0    0   \n",
       "22788        N     M    1.00          10     0             1    0    0    0   \n",
       "22789        N     M    1.00          10     0             1    0    0    0   \n",
       "22790        U     F    6.00          12     3             0    0    0    0   \n",
       "22791        N     M    3.50          10     0             0    0    0    0   \n",
       "\n",
       "       4.0  ...  202.0  203.0  204.0  205.0  206.0  207.0  208.0  209.0  \\\n",
       "0        0  ...      0      0      0      0      0      0      0      0   \n",
       "1        0  ...      0      0      0      0      0      0      0      0   \n",
       "2        0  ...      0      0      0      0      0      0      0      0   \n",
       "3        0  ...      0      0      0      0      0      0      0      0   \n",
       "4        0  ...      0      0      0      0      0      0      0      0   \n",
       "...    ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "22787    0  ...      0      0      0      0      0      0      0      0   \n",
       "22788    0  ...      0      0      0      0      0      0      0      0   \n",
       "22789    0  ...      0      0      0      0      0      0      0      0   \n",
       "22790    0  ...      0      0      0      0      0      0      0      0   \n",
       "22791    0  ...      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       210.0  211.0  \n",
       "0          0      0  \n",
       "1          0      0  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "...      ...    ...  \n",
       "22787      0      0  \n",
       "22788      0      0  \n",
       "22789      0      0  \n",
       "22790      0      0  \n",
       "22791      0      0  \n",
       "\n",
       "[22777 rows x 183 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kindNum을 원핫 인코딩\n",
    "kindCd = pd.concat((pd.get_dummies(dog_data.kindNum, columns=kindCd), pd.DataFrame(columns=kindCd))).fillna(0)\n",
    "\n",
    "\n",
    "# 학습데이터에서 kindNum 열을 삭제한 후, 원핫 인코딩된 kindCd를 붙임\n",
    "dog_data.drop(['kindNum'], axis='columns', inplace=True)\n",
    "dog_data = pd.concat([dog_data, kindCd], axis=1)\n",
    "\n",
    "\n",
    "# kindNum을 원핫 인코딩\n",
    "kindCd_train = pd.concat((pd.get_dummies(dog_train.kindNum, columns=kindCd_train), pd.DataFrame(columns=kindCd_train))).fillna(0)\n",
    "\n",
    "# 테스트데이터에서 kindNum 열을 삭제한 후, 원핫 인코딩된 kindCd를 붙임\n",
    "dog_train.drop(['kindNum'], axis='columns', inplace=True)\n",
    "dog_train = pd.concat([dog_train, kindCd_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix = column)], axis = 1)\n",
    "        data = data.drop(column, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       weight  noticeDays  age2  processState  1.0  2.0  3.0  4.0  5.0  6.0  \\\n",
      "0        7.46          10    12             0    0    0    0    0    0    0   \n",
      "1        7.00          14     1             1    0    0    0    0    0    0   \n",
      "2        4.50          11     2             0    0    0    0    0    0    0   \n",
      "3       10.00           8     1             0    0    0    0    0    0    0   \n",
      "4        6.00           8     4             0    0    0    0    0    0    0   \n",
      "...       ...         ...   ...           ...  ...  ...  ...  ...  ...  ...   \n",
      "22787    1.00          10     0             1    0    0    0    0    0    0   \n",
      "22788    1.00          10     0             1    0    0    0    0    0    0   \n",
      "22789    1.00          10     0             1    0    0    0    0    0    0   \n",
      "22790    6.00          12     3             0    0    0    0    0    0    0   \n",
      "22791    3.50          10     0             0    0    0    0    0    0    0   \n",
      "\n",
      "       ...  208.0  209.0  210.0  211.0  neuterYn_N  neuterYn_U  neuterYn_Y  \\\n",
      "0      ...      0      0      0      0           1           0           0   \n",
      "1      ...      0      0      0      0           1           0           0   \n",
      "2      ...      0      0      0      0           0           1           0   \n",
      "3      ...      0      0      0      0           1           0           0   \n",
      "4      ...      0      0      0      0           1           0           0   \n",
      "...    ...    ...    ...    ...    ...         ...         ...         ...   \n",
      "22787  ...      0      0      0      0           1           0           0   \n",
      "22788  ...      0      0      0      0           1           0           0   \n",
      "22789  ...      0      0      0      0           1           0           0   \n",
      "22790  ...      0      0      0      0           0           1           0   \n",
      "22791  ...      0      0      0      0           1           0           0   \n",
      "\n",
      "       sexCd_F  sexCd_M  sexCd_Q  \n",
      "0            1        0        0  \n",
      "1            0        1        0  \n",
      "2            0        1        0  \n",
      "3            0        1        0  \n",
      "4            0        1        0  \n",
      "...        ...      ...      ...  \n",
      "22787        0        1        0  \n",
      "22788        0        1        0  \n",
      "22789        0        1        0  \n",
      "22790        1        0        0  \n",
      "22791        0        1        0  \n",
      "\n",
      "[22777 rows x 187 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy_columns = [\"neuterYn\", \"sexCd\"]\n",
    "data = dummy_data(dog_data, dummy_columns)\n",
    "train_data = dummy_data(dog_train, dummy_columns)\n",
    "\n",
    "print(data)\n",
    "\n",
    "data = np.array(data, dtype = np.float64)\n",
    "train_data = np.array(train_data, dtype = np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[:, :3]\n",
    "b = data[:, 4:]\n",
    "\n",
    "#numpy 배열에서 데이터 변화요인(kindCd, neuterYn, sexCd, weight, noticeDays, age2)으로 사용할 데이터를 뽑아냅니다.\n",
    "xData = np.concatenate([a, b], axis = 1)\n",
    "\n",
    "a=train_data[:, :3]\n",
    "b=train_data[:, 4:]\n",
    "testX=np.concatenate([a, b], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy배열에서 결과(입양여부)로 사용할 데이터를 뽑아냅니다.\n",
    "yData=data[:,[3]]\n",
    "testY=train_data[:,[3]]\n",
    "\n",
    "print(yData)\n",
    "type(yData)\n",
    "yData.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22777 samples, validate on 22777 samples\n",
      "Epoch 1/100\n",
      "22777/22777 [==============================] - 8s 332us/sample - loss: 0.9581 - acc: 0.5969 - binary_crossentropy: 0.6662 - val_loss: 0.8545 - val_acc: 0.5925 - val_binary_crossentropy: 0.6707\n",
      "Epoch 2/100\n",
      "22777/22777 [==============================] - 8s 360us/sample - loss: 0.7676 - acc: 0.6369 - binary_crossentropy: 0.6399 - val_loss: 0.7288 - val_acc: 0.6208 - val_binary_crossentropy: 0.6426\n",
      "Epoch 3/100\n",
      "22777/22777 [==============================] - 7s 320us/sample - loss: 0.6959 - acc: 0.6403 - binary_crossentropy: 0.6321 - val_loss: 0.6816 - val_acc: 0.6392 - val_binary_crossentropy: 0.6343cc: 0.6394 - binary_crossentropy: \n",
      "Epoch 4/100\n",
      "22777/22777 [==============================] - 8s 372us/sample - loss: 0.6670 - acc: 0.6458 - binary_crossentropy: 0.6289 - val_loss: 0.6468 - val_acc: 0.6749 - val_binary_crossentropy: 0.6163\n",
      "Epoch 5/100\n",
      "22777/22777 [==============================] - 7s 304us/sample - loss: 0.6543 - acc: 0.6483 - binary_crossentropy: 0.6270 - val_loss: 0.6487 - val_acc: 0.6482 - val_binary_crossentropy: 0.6238\n",
      "Epoch 6/100\n",
      "22777/22777 [==============================] - 7s 296us/sample - loss: 0.6501 - acc: 0.6500 - binary_crossentropy: 0.6269 - val_loss: 0.6507 - val_acc: 0.6480 - val_binary_crossentropy: 0.6291\n",
      "Epoch 7/100\n",
      "22777/22777 [==============================] - 7s 329us/sample - loss: 0.6486 - acc: 0.6471 - binary_crossentropy: 0.6274 - val_loss: 0.6456 - val_acc: 0.6542 - val_binary_crossentropy: 0.6251\n",
      "Epoch 8/100\n",
      "22777/22777 [==============================] - 8s 352us/sample - loss: 0.6463 - acc: 0.6523 - binary_crossentropy: 0.6261 - val_loss: 0.6329 - val_acc: 0.6690 - val_binary_crossentropy: 0.6124\n",
      "Epoch 9/100\n",
      "22777/22777 [==============================] - 9s 375us/sample - loss: 0.6436 - acc: 0.6531 - binary_crossentropy: 0.6235 - val_loss: 0.6324 - val_acc: 0.6612 - val_binary_crossentropy: 0.6120\n",
      "Epoch 10/100\n",
      "22777/22777 [==============================] - 8s 338us/sample - loss: 0.6452 - acc: 0.6501 - binary_crossentropy: 0.6252 - val_loss: 0.6321 - val_acc: 0.6709 - val_binary_crossentropy: 0.6126\n",
      "Epoch 11/100\n",
      "22777/22777 [==============================] - 9s 379us/sample - loss: 0.6441 - acc: 0.6505 - binary_crossentropy: 0.6248 - val_loss: 0.6762 - val_acc: 0.6175 - val_binary_crossentropy: 0.6562\n",
      "Epoch 12/100\n",
      "22777/22777 [==============================] - 8s 335us/sample - loss: 0.6437 - acc: 0.6554 - binary_crossentropy: 0.6240 - val_loss: 0.6325 - val_acc: 0.6674 - val_binary_crossentropy: 0.6132\n",
      "Epoch 13/100\n",
      "22777/22777 [==============================] - 8s 352us/sample - loss: 0.6438 - acc: 0.6504 - binary_crossentropy: 0.6242 - val_loss: 0.6611 - val_acc: 0.6428 - val_binary_crossentropy: 0.6418\n",
      "Epoch 14/100\n",
      "22777/22777 [==============================] - 7s 313us/sample - loss: 0.6428 - acc: 0.6497 - binary_crossentropy: 0.6237 - val_loss: 0.6433 - val_acc: 0.6446 - val_binary_crossentropy: 0.6241\n",
      "Epoch 15/100\n",
      "22777/22777 [==============================] - 10s 420us/sample - loss: 0.6427 - acc: 0.6556 - binary_crossentropy: 0.6235 - val_loss: 0.6294 - val_acc: 0.6619 - val_binary_crossentropy: 0.6098\n",
      "Epoch 16/100\n",
      "22777/22777 [==============================] - 10s 441us/sample - loss: 0.6427 - acc: 0.6514 - binary_crossentropy: 0.6235 - val_loss: 0.6416 - val_acc: 0.6520 - val_binary_crossentropy: 0.6230\n",
      "Epoch 17/100\n",
      "22777/22777 [==============================] - 9s 382us/sample - loss: 0.6428 - acc: 0.6541 - binary_crossentropy: 0.6231 - val_loss: 0.6307 - val_acc: 0.6636 - val_binary_crossentropy: 0.6114\n",
      "Epoch 18/100\n",
      "22777/22777 [==============================] - 10s 446us/sample - loss: 0.6412 - acc: 0.6542 - binary_crossentropy: 0.6212 - val_loss: 0.6349 - val_acc: 0.6595 - val_binary_crossentropy: 0.6149\n",
      "Epoch 19/100\n",
      "22777/22777 [==============================] - 10s 420us/sample - loss: 0.6416 - acc: 0.6563 - binary_crossentropy: 0.6219 - val_loss: 0.6339 - val_acc: 0.6564 - val_binary_crossentropy: 0.6142\n",
      "Epoch 20/100\n",
      "22777/22777 [==============================] - 9s 405us/sample - loss: 0.6406 - acc: 0.6536 - binary_crossentropy: 0.6211 - val_loss: 0.6450 - val_acc: 0.6610 - val_binary_crossentropy: 0.6248\n",
      "Epoch 21/100\n",
      "22777/22777 [==============================] - 10s 423us/sample - loss: 0.6409 - acc: 0.6568 - binary_crossentropy: 0.6210 - val_loss: 0.6425 - val_acc: 0.6525 - val_binary_crossentropy: 0.6227\n",
      "Epoch 22/100\n",
      "22777/22777 [==============================] - 9s 406us/sample - loss: 0.6415 - acc: 0.6514 - binary_crossentropy: 0.6217 - val_loss: 0.6593 - val_acc: 0.6251 - val_binary_crossentropy: 0.6403\n",
      "Epoch 23/100\n",
      "22777/22777 [==============================] - 10s 422us/sample - loss: 0.6396 - acc: 0.6566 - binary_crossentropy: 0.6204 - val_loss: 0.6279 - val_acc: 0.6773 - val_binary_crossentropy: 0.6082\n",
      "Epoch 24/100\n",
      "22777/22777 [==============================] - 9s 416us/sample - loss: 0.6392 - acc: 0.6571 - binary_crossentropy: 0.6196 - val_loss: 0.6332 - val_acc: 0.6532 - val_binary_crossentropy: 0.6133\n",
      "Epoch 25/100\n",
      "22777/22777 [==============================] - 8s 371us/sample - loss: 0.6396 - acc: 0.6554 - binary_crossentropy: 0.6198 - val_loss: 0.7720 - val_acc: 0.4669 - val_binary_crossentropy: 0.7527\n",
      "Epoch 26/100\n",
      "22777/22777 [==============================] - 9s 378us/sample - loss: 0.6409 - acc: 0.6566 - binary_crossentropy: 0.6214 - val_loss: 0.6409 - val_acc: 0.6534 - val_binary_crossentropy: 0.6214\n",
      "Epoch 27/100\n",
      "22777/22777 [==============================] - 7s 294us/sample - loss: 0.6396 - acc: 0.6550 - binary_crossentropy: 0.6202 - val_loss: 0.6337 - val_acc: 0.6569 - val_binary_crossentropy: 0.6141\n",
      "Epoch 28/100\n",
      "22777/22777 [==============================] - 10s 418us/sample - loss: 0.6381 - acc: 0.6565 - binary_crossentropy: 0.6187 - val_loss: 0.6863 - val_acc: 0.6190 - val_binary_crossentropy: 0.6664\n",
      "Epoch 29/100\n",
      "22777/22777 [==============================] - 7s 320us/sample - loss: 0.6402 - acc: 0.6573 - binary_crossentropy: 0.6205 - val_loss: 0.6512 - val_acc: 0.6407 - val_binary_crossentropy: 0.6314\n",
      "Epoch 30/100\n",
      "22777/22777 [==============================] - 8s 334us/sample - loss: 0.6383 - acc: 0.6561 - binary_crossentropy: 0.6192 - val_loss: 0.6595 - val_acc: 0.6349 - val_binary_crossentropy: 0.6393\n",
      "Epoch 31/100\n",
      "22777/22777 [==============================] - 7s 322us/sample - loss: 0.6393 - acc: 0.6533 - binary_crossentropy: 0.6199 - val_loss: 0.6274 - val_acc: 0.6701 - val_binary_crossentropy: 0.6077\n",
      "Epoch 32/100\n",
      "22777/22777 [==============================] - 9s 394us/sample - loss: 0.6404 - acc: 0.6521 - binary_crossentropy: 0.6209 - val_loss: 0.6391 - val_acc: 0.6560 - val_binary_crossentropy: 0.6202\n",
      "Epoch 33/100\n",
      "22777/22777 [==============================] - 6s 285us/sample - loss: 0.6400 - acc: 0.6531 - binary_crossentropy: 0.6205 - val_loss: 0.6521 - val_acc: 0.6411 - val_binary_crossentropy: 0.6330\n",
      "Epoch 34/100\n",
      "22777/22777 [==============================] - 7s 319us/sample - loss: 0.6386 - acc: 0.6552 - binary_crossentropy: 0.6191 - val_loss: 0.6251 - val_acc: 0.6760 - val_binary_crossentropy: 0.6063\n",
      "Epoch 35/100\n",
      "22777/22777 [==============================] - 8s 350us/sample - loss: 0.6395 - acc: 0.6566 - binary_crossentropy: 0.6203 - val_loss: 0.6249 - val_acc: 0.6708 - val_binary_crossentropy: 0.6058\n",
      "Epoch 36/100\n",
      "22777/22777 [==============================] - 7s 320us/sample - loss: 0.6379 - acc: 0.6573 - binary_crossentropy: 0.6189 - val_loss: 0.6342 - val_acc: 0.6548 - val_binary_crossentropy: 0.6149\n",
      "Epoch 37/100\n",
      "22777/22777 [==============================] - 7s 296us/sample - loss: 0.6395 - acc: 0.6543 - binary_crossentropy: 0.6203 - val_loss: 0.6357 - val_acc: 0.6618 - val_binary_crossentropy: 0.6160\n",
      "Epoch 38/100\n",
      "22777/22777 [==============================] - 8s 338us/sample - loss: 0.6392 - acc: 0.6572 - binary_crossentropy: 0.6198 - val_loss: 0.6262 - val_acc: 0.6781 - val_binary_crossentropy: 0.6066\n",
      "Epoch 39/100\n",
      "22777/22777 [==============================] - 7s 307us/sample - loss: 0.6389 - acc: 0.6530 - binary_crossentropy: 0.6199 - val_loss: 0.6388 - val_acc: 0.6557 - val_binary_crossentropy: 0.6194\n",
      "Epoch 40/100\n",
      "22777/22777 [==============================] - 8s 352us/sample - loss: 0.6393 - acc: 0.6524 - binary_crossentropy: 0.6205 - val_loss: 0.6335 - val_acc: 0.6550 - val_binary_crossentropy: 0.6150\n",
      "Epoch 41/100\n",
      "22777/22777 [==============================] - 7s 313us/sample - loss: 0.6393 - acc: 0.6547 - binary_crossentropy: 0.6204 - val_loss: 0.6322 - val_acc: 0.6558 - val_binary_crossentropy: 0.6133\n",
      "Epoch 42/100\n",
      "22777/22777 [==============================] - 7s 306us/sample - loss: 0.6393 - acc: 0.6540 - binary_crossentropy: 0.6205 - val_loss: 0.6374 - val_acc: 0.6516 - val_binary_crossentropy: 0.6186\n",
      "Epoch 43/100\n",
      "22777/22777 [==============================] - 7s 328us/sample - loss: 0.6386 - acc: 0.6564 - binary_crossentropy: 0.6196 - val_loss: 0.6257 - val_acc: 0.6671 - val_binary_crossentropy: 0.6066\n",
      "Epoch 44/100\n",
      "22777/22777 [==============================] - 8s 342us/sample - loss: 0.6367 - acc: 0.6584 - binary_crossentropy: 0.6175 - val_loss: 0.6382 - val_acc: 0.6506 - val_binary_crossentropy: 0.6200\n",
      "Epoch 45/100\n",
      "22777/22777 [==============================] - 7s 308us/sample - loss: 0.6374 - acc: 0.6565 - binary_crossentropy: 0.6184 - val_loss: 0.6495 - val_acc: 0.6383 - val_binary_crossentropy: 0.6314\n",
      "Epoch 46/100\n",
      "22777/22777 [==============================] - 7s 308us/sample - loss: 0.6381 - acc: 0.6561 - binary_crossentropy: 0.6194 - val_loss: 0.6345 - val_acc: 0.6591 - val_binary_crossentropy: 0.6156\n",
      "Epoch 47/100\n",
      "22777/22777 [==============================] - 7s 297us/sample - loss: 0.6384 - acc: 0.6539 - binary_crossentropy: 0.6192 - val_loss: 0.6394 - val_acc: 0.6554 - val_binary_crossentropy: 0.6211\n",
      "Epoch 48/100\n",
      "22777/22777 [==============================] - 7s 297us/sample - loss: 0.6380 - acc: 0.6557 - binary_crossentropy: 0.6192 - val_loss: 0.6280 - val_acc: 0.6741 - val_binary_crossentropy: 0.6098\n",
      "Epoch 49/100\n",
      "22777/22777 [==============================] - 7s 299us/sample - loss: 0.6379 - acc: 0.6568 - binary_crossentropy: 0.6192 - val_loss: 0.6341 - val_acc: 0.6548 - val_binary_crossentropy: 0.6152\n",
      "Epoch 50/100\n",
      "22777/22777 [==============================] - 7s 298us/sample - loss: 0.6375 - acc: 0.6588 - binary_crossentropy: 0.6184 - val_loss: 0.6299 - val_acc: 0.6651 - val_binary_crossentropy: 0.6112\n",
      "Epoch 51/100\n",
      "22777/22777 [==============================] - 6s 275us/sample - loss: 0.6375 - acc: 0.6574 - binary_crossentropy: 0.6191 - val_loss: 0.6958 - val_acc: 0.5983 - val_binary_crossentropy: 0.6776\n",
      "Epoch 52/100\n",
      "22777/22777 [==============================] - 7s 313us/sample - loss: 0.6380 - acc: 0.6542 - binary_crossentropy: 0.6194 - val_loss: 0.6327 - val_acc: 0.6601 - val_binary_crossentropy: 0.6137\n",
      "Epoch 53/100\n",
      "22777/22777 [==============================] - 7s 315us/sample - loss: 0.6386 - acc: 0.6535 - binary_crossentropy: 0.6198 - val_loss: 0.6333 - val_acc: 0.6550 - val_binary_crossentropy: 0.6143\n",
      "Epoch 54/100\n",
      "22777/22777 [==============================] - 7s 314us/sample - loss: 0.6380 - acc: 0.6546 - binary_crossentropy: 0.6189 - val_loss: 0.6255 - val_acc: 0.6715 - val_binary_crossentropy: 0.6070\n",
      "Epoch 55/100\n",
      "22777/22777 [==============================] - 7s 308us/sample - loss: 0.6386 - acc: 0.6557 - binary_crossentropy: 0.6198 - val_loss: 0.6282 - val_acc: 0.6641 - val_binary_crossentropy: 0.6093\n",
      "Epoch 56/100\n",
      "22777/22777 [==============================] - 7s 299us/sample - loss: 0.6386 - acc: 0.6572 - binary_crossentropy: 0.6197 - val_loss: 0.6332 - val_acc: 0.6566 - val_binary_crossentropy: 0.61400.6410 - acc: 0.6586 - binary_crossentropy: 0 - ETA: 2s - loss: 0.6402 - ac - ETA: 0s - loss: 0.6390 - acc: 0.6555 - binary_crossentr\n",
      "Epoch 57/100\n",
      "22777/22777 [==============================] - 7s 323us/sample - loss: 0.6379 - acc: 0.6571 - binary_crossentropy: 0.6188 - val_loss: 0.6934 - val_acc: 0.5771 - val_binary_crossentropy: 0.6738\n",
      "Epoch 58/100\n",
      "22777/22777 [==============================] - 7s 308us/sample - loss: 0.6379 - acc: 0.6574 - binary_crossentropy: 0.6191 - val_loss: 0.6352 - val_acc: 0.6611 - val_binary_crossentropy: 0.6162\n",
      "Epoch 59/100\n",
      "22777/22777 [==============================] - 7s 320us/sample - loss: 0.6369 - acc: 0.6563 - binary_crossentropy: 0.6182 - val_loss: 0.6243 - val_acc: 0.6781 - val_binary_crossentropy: 0.6061\n",
      "Epoch 60/100\n",
      "22777/22777 [==============================] - 7s 305us/sample - loss: 0.6377 - acc: 0.6551 - binary_crossentropy: 0.6191 - val_loss: 0.6342 - val_acc: 0.6527 - val_binary_crossentropy: 0.6156\n",
      "Epoch 61/100\n",
      "22777/22777 [==============================] - 8s 334us/sample - loss: 0.6371 - acc: 0.6534 - binary_crossentropy: 0.6186 - val_loss: 0.6384 - val_acc: 0.6581 - val_binary_crossentropy: 0.6200\n",
      "Epoch 62/100\n",
      "22777/22777 [==============================] - 7s 306us/sample - loss: 0.6379 - acc: 0.6572 - binary_crossentropy: 0.6191 - val_loss: 0.6478 - val_acc: 0.6440 - val_binary_crossentropy: 0.6286\n",
      "Epoch 63/100\n",
      "22777/22777 [==============================] - 8s 339us/sample - loss: 0.6385 - acc: 0.6547 - binary_crossentropy: 0.6194 - val_loss: 0.6361 - val_acc: 0.6684 - val_binary_crossentropy: 0.6174\n",
      "Epoch 64/100\n",
      "22777/22777 [==============================] - 7s 310us/sample - loss: 0.6374 - acc: 0.6555 - binary_crossentropy: 0.6186 - val_loss: 0.6233 - val_acc: 0.6727 - val_binary_crossentropy: 0.6048loss: 0.6375 - acc: 0.6552 - binary_cros - ETA: 0s - loss: 0.6378 - acc: 0.6546 - binary_crossentropy: 0\n",
      "Epoch 65/100\n",
      "22777/22777 [==============================] - 7s 325us/sample - loss: 0.6370 - acc: 0.6592 - binary_crossentropy: 0.6185 - val_loss: 0.6269 - val_acc: 0.6665 - val_binary_crossentropy: 0.6085\n",
      "Epoch 66/100\n",
      "22777/22777 [==============================] - 7s 328us/sample - loss: 0.6380 - acc: 0.6558 - binary_crossentropy: 0.6194 - val_loss: 0.6573 - val_acc: 0.6368 - val_binary_crossentropy: 0.6384\n",
      "Epoch 67/100\n",
      "22777/22777 [==============================] - 7s 298us/sample - loss: 0.6379 - acc: 0.6545 - binary_crossentropy: 0.6190 - val_loss: 0.6265 - val_acc: 0.6696 - val_binary_crossentropy: 0.6079\n",
      "Epoch 68/100\n",
      "22777/22777 [==============================] - 7s 307us/sample - loss: 0.6385 - acc: 0.6549 - binary_crossentropy: 0.6195 - val_loss: 0.6400 - val_acc: 0.6628 - val_binary_crossentropy: 0.6215\n",
      "Epoch 69/100\n",
      "22777/22777 [==============================] - 7s 313us/sample - loss: 0.6382 - acc: 0.6582 - binary_crossentropy: 0.6194 - val_loss: 0.6325 - val_acc: 0.6602 - val_binary_crossentropy: 0.6134s: 0.6382 - acc: 0.658\n",
      "Epoch 70/100\n",
      "22777/22777 [==============================] - 8s 347us/sample - loss: 0.6370 - acc: 0.6575 - binary_crossentropy: 0.6182 - val_loss: 0.6393 - val_acc: 0.6502 - val_binary_crossentropy: 0.6212\n",
      "Epoch 71/100\n",
      "22777/22777 [==============================] - 8s 349us/sample - loss: 0.6384 - acc: 0.6559 - binary_crossentropy: 0.6201 - val_loss: 0.6520 - val_acc: 0.6442 - val_binary_crossentropy: 0.6337\n",
      "Epoch 72/100\n",
      "22777/22777 [==============================] - 8s 342us/sample - loss: 0.6371 - acc: 0.6558 - binary_crossentropy: 0.6185 - val_loss: 0.6267 - val_acc: 0.6671 - val_binary_crossentropy: 0.6081\n",
      "Epoch 73/100\n",
      "22777/22777 [==============================] - 7s 310us/sample - loss: 0.6373 - acc: 0.6565 - binary_crossentropy: 0.6187 - val_loss: 0.6246 - val_acc: 0.6692 - val_binary_crossentropy: 0.6063\n",
      "Epoch 74/100\n",
      "22777/22777 [==============================] - 8s 359us/sample - loss: 0.6373 - acc: 0.6561 - binary_crossentropy: 0.6186 - val_loss: 0.6356 - val_acc: 0.6515 - val_binary_crossentropy: 0.6168\n",
      "Epoch 75/100\n",
      "22777/22777 [==============================] - 7s 327us/sample - loss: 0.6374 - acc: 0.6551 - binary_crossentropy: 0.6186 - val_loss: 0.6251 - val_acc: 0.6696 - val_binary_crossentropy: 0.6060\n",
      "Epoch 76/100\n",
      "22777/22777 [==============================] - 7s 310us/sample - loss: 0.6364 - acc: 0.6584 - binary_crossentropy: 0.6173 - val_loss: 0.6278 - val_acc: 0.6575 - val_binary_crossentropy: 0.6089\n",
      "Epoch 77/100\n",
      "22777/22777 [==============================] - 7s 309us/sample - loss: 0.6358 - acc: 0.6626 - binary_crossentropy: 0.6174 - val_loss: 0.6316 - val_acc: 0.6599 - val_binary_crossentropy: 0.6125\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22777/22777 [==============================] - 7s 308us/sample - loss: 0.6369 - acc: 0.6603 - binary_crossentropy: 0.6179 - val_loss: 0.6331 - val_acc: 0.6627 - val_binary_crossentropy: 0.6146\n",
      "Epoch 79/100\n",
      "22777/22777 [==============================] - 7s 320us/sample - loss: 0.6365 - acc: 0.6597 - binary_crossentropy: 0.6179 - val_loss: 0.6258 - val_acc: 0.6691 - val_binary_crossentropy: 0.6073\n",
      "Epoch 80/100\n",
      "22777/22777 [==============================] - 7s 307us/sample - loss: 0.6391 - acc: 0.6531 - binary_crossentropy: 0.6207 - val_loss: 0.6480 - val_acc: 0.6465 - val_binary_crossentropy: 0.6298\n",
      "Epoch 81/100\n",
      "22777/22777 [==============================] - 7s 323us/sample - loss: 0.6380 - acc: 0.6551 - binary_crossentropy: 0.6194 - val_loss: 0.6276 - val_acc: 0.6739 - val_binary_crossentropy: 0.6092\n",
      "Epoch 82/100\n",
      "22777/22777 [==============================] - 7s 312us/sample - loss: 0.6376 - acc: 0.6550 - binary_crossentropy: 0.6191 - val_loss: 0.6241 - val_acc: 0.6693 - val_binary_crossentropy: 0.6053\n",
      "Epoch 83/100\n",
      "22777/22777 [==============================] - 7s 304us/sample - loss: 0.6382 - acc: 0.6546 - binary_crossentropy: 0.6197 - val_loss: 0.6335 - val_acc: 0.6617 - val_binary_crossentropy: 0.6153\n",
      "Epoch 84/100\n",
      "22777/22777 [==============================] - 7s 293us/sample - loss: 0.6388 - acc: 0.6518 - binary_crossentropy: 0.6209 - val_loss: 0.6232 - val_acc: 0.6770 - val_binary_crossentropy: 0.6049\n",
      "Epoch 85/100\n",
      "22777/22777 [==============================] - 7s 307us/sample - loss: 0.6380 - acc: 0.6543 - binary_crossentropy: 0.6197 - val_loss: 0.6351 - val_acc: 0.6550 - val_binary_crossentropy: 0.6165\n",
      "Epoch 86/100\n",
      "22777/22777 [==============================] - 7s 317us/sample - loss: 0.6374 - acc: 0.6590 - binary_crossentropy: 0.6188 - val_loss: 0.6286 - val_acc: 0.6692 - val_binary_crossentropy: 0.6102\n",
      "Epoch 87/100\n",
      "22777/22777 [==============================] - 7s 295us/sample - loss: 0.6364 - acc: 0.6574 - binary_crossentropy: 0.6178 - val_loss: 0.6434 - val_acc: 0.6499 - val_binary_crossentropy: 0.6246\n",
      "Epoch 88/100\n",
      "22777/22777 [==============================] - 7s 302us/sample - loss: 0.6373 - acc: 0.6579 - binary_crossentropy: 0.6186 - val_loss: 0.8051 - val_acc: 0.4905 - val_binary_crossentropy: 0.7867\n",
      "Epoch 89/100\n",
      "22777/22777 [==============================] - 6s 285us/sample - loss: 0.6378 - acc: 0.6584 - binary_crossentropy: 0.6189 - val_loss: 0.6431 - val_acc: 0.6425 - val_binary_crossentropy: 0.6244\n",
      "Epoch 90/100\n",
      "22777/22777 [==============================] - 7s 309us/sample - loss: 0.6354 - acc: 0.6610 - binary_crossentropy: 0.6170 - val_loss: 0.6361 - val_acc: 0.6535 - val_binary_crossentropy: 0.6173\n",
      "Epoch 91/100\n",
      "22777/22777 [==============================] - 7s 309us/sample - loss: 0.6356 - acc: 0.6563 - binary_crossentropy: 0.6172 - val_loss: 0.6517 - val_acc: 0.6435 - val_binary_crossentropy: 0.6332\n",
      "Epoch 92/100\n",
      "22777/22777 [==============================] - 8s 365us/sample - loss: 0.6379 - acc: 0.6551 - binary_crossentropy: 0.6194 - val_loss: 0.6873 - val_acc: 0.6121 - val_binary_crossentropy: 0.6682\n",
      "Epoch 93/100\n",
      "22777/22777 [==============================] - 8s 338us/sample - loss: 0.6383 - acc: 0.6570 - binary_crossentropy: 0.6194 - val_loss: 0.6283 - val_acc: 0.6704 - val_binary_crossentropy: 0.6090\n",
      "Epoch 94/100\n",
      "22777/22777 [==============================] - 7s 326us/sample - loss: 0.6369 - acc: 0.6590 - binary_crossentropy: 0.6184 - val_loss: 0.6529 - val_acc: 0.6388 - val_binary_crossentropy: 0.6350\n",
      "Epoch 95/100\n",
      "22777/22777 [==============================] - 7s 300us/sample - loss: 0.6369 - acc: 0.6572 - binary_crossentropy: 0.6188 - val_loss: 0.6335 - val_acc: 0.6590 - val_binary_crossentropy: 0.6151\n",
      "Epoch 96/100\n",
      "22777/22777 [==============================] - 7s 301us/sample - loss: 0.6368 - acc: 0.6579 - binary_crossentropy: 0.6181 - val_loss: 0.6358 - val_acc: 0.6556 - val_binary_crossentropy: 0.6175\n",
      "Epoch 97/100\n",
      "22777/22777 [==============================] - 7s 316us/sample - loss: 0.6375 - acc: 0.6576 - binary_crossentropy: 0.6193 - val_loss: 0.6351 - val_acc: 0.6620 - val_binary_crossentropy: 0.6171\n",
      "Epoch 98/100\n",
      "22777/22777 [==============================] - 7s 296us/sample - loss: 0.6373 - acc: 0.6558 - binary_crossentropy: 0.6192 - val_loss: 0.6284 - val_acc: 0.6694 - val_binary_crossentropy: 0.6104\n",
      "Epoch 99/100\n",
      "22777/22777 [==============================] - 8s 329us/sample - loss: 0.6367 - acc: 0.6561 - binary_crossentropy: 0.6186 - val_loss: 0.6277 - val_acc: 0.6690 - val_binary_crossentropy: 0.6101\n",
      "Epoch 100/100\n",
      "22777/22777 [==============================] - 8s 340us/sample - loss: 0.6372 - acc: 0.6535 - binary_crossentropy: 0.6194 - val_loss: 0.7592 - val_acc: 0.5821 - val_binary_crossentropy: 0.7408\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 16)                2992      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,281\n",
      "Trainable params: 3,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# L2규제만\n",
    "# l2_model = keras.models.Sequential([\n",
    "#     keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "#                        activation=tf.nn.relu, input_shape=(186,)),\n",
    "#     keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "#                        activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "# ])\n",
    "# sgd=optimizers.SGD(lr=0.01)\n",
    "\n",
    "# l2_model.compile(optimizer='sgd',\n",
    "#                  loss='binary_crossentropy',\n",
    "#                  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "# l2_model_history = l2_model.fit(xData, yData,\n",
    "#                                 epochs=100,\n",
    "#                                 batch_size=10,\n",
    "#                                 validation_data=(xData, yData),\n",
    "#                                 verbose=1)\n",
    "\n",
    "# l2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22777 samples, validate on 610 samples\n",
      "Epoch 1/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6814 - acc: 0.5678 - binary_crossentropy: 0.6814 - val_loss: 0.6751 - val_acc: 0.5984 - val_binary_crossentropy: 0.6751\n",
      "Epoch 2/100\n",
      "22777/22777 [==============================] - 1s 55us/sample - loss: 0.6630 - acc: 0.6075 - binary_crossentropy: 0.6630 - val_loss: 0.6617 - val_acc: 0.5967 - val_binary_crossentropy: 0.6617\n",
      "Epoch 3/100\n",
      "22777/22777 [==============================] - 1s 55us/sample - loss: 0.6567 - acc: 0.6214 - binary_crossentropy: 0.6567 - val_loss: 0.6530 - val_acc: 0.6000 - val_binary_crossentropy: 0.6530\n",
      "Epoch 4/100\n",
      "22777/22777 [==============================] - 2s 106us/sample - loss: 0.6490 - acc: 0.6306 - binary_crossentropy: 0.6490 - val_loss: 0.6500 - val_acc: 0.6131 - val_binary_crossentropy: 0.6500\n",
      "Epoch 5/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6448 - acc: 0.6368 - binary_crossentropy: 0.6448 - val_loss: 0.6480 - val_acc: 0.6082 - val_binary_crossentropy: 0.6480\n",
      "Epoch 6/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6399 - acc: 0.6457 - binary_crossentropy: 0.6399 - val_loss: 0.6468 - val_acc: 0.6197 - val_binary_crossentropy: 0.6468\n",
      "Epoch 7/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6410 - acc: 0.6406 - binary_crossentropy: 0.6410 - val_loss: 0.6455 - val_acc: 0.6230 - val_binary_crossentropy: 0.6455\n",
      "Epoch 8/100\n",
      "22777/22777 [==============================] - 2s 92us/sample - loss: 0.6387 - acc: 0.6424 - binary_crossentropy: 0.6387 - val_loss: 0.6444 - val_acc: 0.6164 - val_binary_crossentropy: 0.6444\n",
      "Epoch 9/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6336 - acc: 0.6473 - binary_crossentropy: 0.6336 - val_loss: 0.6414 - val_acc: 0.6279 - val_binary_crossentropy: 0.6414\n",
      "Epoch 10/100\n",
      "22777/22777 [==============================] - 1s 52us/sample - loss: 0.6349 - acc: 0.6434 - binary_crossentropy: 0.6349 - val_loss: 0.6449 - val_acc: 0.6279 - val_binary_crossentropy: 0.6449\n",
      "Epoch 11/100\n",
      "22777/22777 [==============================] - 1s 50us/sample - loss: 0.6316 - acc: 0.6493 - binary_crossentropy: 0.6316 - val_loss: 0.6400 - val_acc: 0.6197 - val_binary_crossentropy: 0.6400\n",
      "Epoch 12/100\n",
      "22777/22777 [==============================] - 1s 51us/sample - loss: 0.6312 - acc: 0.6477 - binary_crossentropy: 0.6312 - val_loss: 0.6533 - val_acc: 0.6344 - val_binary_crossentropy: 0.6533\n",
      "Epoch 13/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6298 - acc: 0.6497 - binary_crossentropy: 0.6298 - val_loss: 0.6386 - val_acc: 0.6328 - val_binary_crossentropy: 0.6386\n",
      "Epoch 14/100\n",
      "22777/22777 [==============================] - 2s 70us/sample - loss: 0.6288 - acc: 0.6490 - binary_crossentropy: 0.6288 - val_loss: 0.6438 - val_acc: 0.6098 - val_binary_crossentropy: 0.6438\n",
      "Epoch 15/100\n",
      "22777/22777 [==============================] - 1s 54us/sample - loss: 0.6262 - acc: 0.6507 - binary_crossentropy: 0.6262 - val_loss: 0.6384 - val_acc: 0.6361 - val_binary_crossentropy: 0.6384\n",
      "Epoch 16/100\n",
      "22777/22777 [==============================] - 1s 50us/sample - loss: 0.6274 - acc: 0.6524 - binary_crossentropy: 0.6274 - val_loss: 0.6400 - val_acc: 0.6328 - val_binary_crossentropy: 0.6400\n",
      "Epoch 17/100\n",
      "22777/22777 [==============================] - 1s 50us/sample - loss: 0.6245 - acc: 0.6550 - binary_crossentropy: 0.6245 - val_loss: 0.6361 - val_acc: 0.6344 - val_binary_crossentropy: 0.6361\n",
      "Epoch 18/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6250 - acc: 0.6558 - binary_crossentropy: 0.6250 - val_loss: 0.6407 - val_acc: 0.6295 - val_binary_crossentropy: 0.6407\n",
      "Epoch 19/100\n",
      "22777/22777 [==============================] - 1s 53us/sample - loss: 0.6210 - acc: 0.6579 - binary_crossentropy: 0.6210 - val_loss: 0.6450 - val_acc: 0.6279 - val_binary_crossentropy: 0.6450\n",
      "Epoch 20/100\n",
      "22777/22777 [==============================] - 1s 53us/sample - loss: 0.6216 - acc: 0.6572 - binary_crossentropy: 0.6216 - val_loss: 0.6356 - val_acc: 0.6197 - val_binary_crossentropy: 0.6356\n",
      "Epoch 21/100\n",
      "22777/22777 [==============================] - 1s 57us/sample - loss: 0.6202 - acc: 0.6579 - binary_crossentropy: 0.6202 - val_loss: 0.6357 - val_acc: 0.6295 - val_binary_crossentropy: 0.6357\n",
      "Epoch 22/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6197 - acc: 0.6615 - binary_crossentropy: 0.6197 - val_loss: 0.6386 - val_acc: 0.6459 - val_binary_crossentropy: 0.6386\n",
      "Epoch 23/100\n",
      "22777/22777 [==============================] - 2s 96us/sample - loss: 0.6198 - acc: 0.6586 - binary_crossentropy: 0.6198 - val_loss: 0.6426 - val_acc: 0.6393 - val_binary_crossentropy: 0.6426\n",
      "Epoch 24/100\n",
      "22777/22777 [==============================] - 1s 59us/sample - loss: 0.6194 - acc: 0.6601 - binary_crossentropy: 0.6194 - val_loss: 0.6406 - val_acc: 0.6361 - val_binary_crossentropy: 0.6406\n",
      "Epoch 25/100\n",
      "22777/22777 [==============================] - 2s 66us/sample - loss: 0.6198 - acc: 0.6608 - binary_crossentropy: 0.6198 - val_loss: 0.6595 - val_acc: 0.6246 - val_binary_crossentropy: 0.6595\n",
      "Epoch 26/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6208 - acc: 0.6608 - binary_crossentropy: 0.6208 - val_loss: 0.6418 - val_acc: 0.6393 - val_binary_crossentropy: 0.6418\n",
      "Epoch 27/100\n",
      "22777/22777 [==============================] - 2s 107us/sample - loss: 0.6179 - acc: 0.6636 - binary_crossentropy: 0.6179 - val_loss: 0.6442 - val_acc: 0.6213 - val_binary_crossentropy: 0.6442\n",
      "Epoch 28/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6162 - acc: 0.6648 - binary_crossentropy: 0.6162 - val_loss: 0.6428 - val_acc: 0.6426 - val_binary_crossentropy: 0.6428\n",
      "Epoch 29/100\n",
      "22777/22777 [==============================] - 1s 56us/sample - loss: 0.6185 - acc: 0.6597 - binary_crossentropy: 0.6185 - val_loss: 0.6378 - val_acc: 0.6279 - val_binary_crossentropy: 0.6378\n",
      "Epoch 30/100\n",
      "22777/22777 [==============================] - 1s 61us/sample - loss: 0.6176 - acc: 0.6610 - binary_crossentropy: 0.6176 - val_loss: 0.6358 - val_acc: 0.6459 - val_binary_crossentropy: 0.6358\n",
      "Epoch 31/100\n",
      "22777/22777 [==============================] - 2s 87us/sample - loss: 0.6163 - acc: 0.6640 - binary_crossentropy: 0.6163 - val_loss: 0.6315 - val_acc: 0.6492 - val_binary_crossentropy: 0.6315\n",
      "Epoch 32/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6170 - acc: 0.6629 - binary_crossentropy: 0.6170 - val_loss: 0.6332 - val_acc: 0.6393 - val_binary_crossentropy: 0.6332\n",
      "Epoch 33/100\n",
      "22777/22777 [==============================] - 1s 61us/sample - loss: 0.6146 - acc: 0.6654 - binary_crossentropy: 0.6146 - val_loss: 0.6415 - val_acc: 0.6164 - val_binary_crossentropy: 0.6415\n",
      "Epoch 34/100\n",
      "22777/22777 [==============================] - 1s 56us/sample - loss: 0.6171 - acc: 0.6623 - binary_crossentropy: 0.6171 - val_loss: 0.6471 - val_acc: 0.6213 - val_binary_crossentropy: 0.6471\n",
      "Epoch 35/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6145 - acc: 0.6676 - binary_crossentropy: 0.6145 - val_loss: 0.6420 - val_acc: 0.6213 - val_binary_crossentropy: 0.6420\n",
      "Epoch 36/100\n",
      "22777/22777 [==============================] - 2s 94us/sample - loss: 0.6164 - acc: 0.6638 - binary_crossentropy: 0.6164 - val_loss: 0.6402 - val_acc: 0.6361 - val_binary_crossentropy: 0.6402\n",
      "Epoch 37/100\n",
      "22777/22777 [==============================] - 1s 56us/sample - loss: 0.6139 - acc: 0.6665 - binary_crossentropy: 0.6139 - val_loss: 0.6356 - val_acc: 0.6492 - val_binary_crossentropy: 0.6356\n",
      "Epoch 38/100\n",
      "22777/22777 [==============================] - 1s 60us/sample - loss: 0.6141 - acc: 0.6646 - binary_crossentropy: 0.6141 - val_loss: 0.6301 - val_acc: 0.6443 - val_binary_crossentropy: 0.6301\n",
      "Epoch 39/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6127 - acc: 0.6681 - binary_crossentropy: 0.6127 - val_loss: 0.6361 - val_acc: 0.6246 - val_binary_crossentropy: 0.6361\n",
      "Epoch 40/100\n",
      "22777/22777 [==============================] - 2s 89us/sample - loss: 0.6159 - acc: 0.6661 - binary_crossentropy: 0.6159 - val_loss: 0.6381 - val_acc: 0.6262 - val_binary_crossentropy: 0.6381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "22777/22777 [==============================] - 1s 57us/sample - loss: 0.6147 - acc: 0.6653 - binary_crossentropy: 0.6147 - val_loss: 0.6336 - val_acc: 0.6410 - val_binary_crossentropy: 0.6336\n",
      "Epoch 42/100\n",
      "22777/22777 [==============================] - 1s 55us/sample - loss: 0.6144 - acc: 0.6665 - binary_crossentropy: 0.6144 - val_loss: 0.6484 - val_acc: 0.6148 - val_binary_crossentropy: 0.6484\n",
      "Epoch 43/100\n",
      "22777/22777 [==============================] - 2s 83us/sample - loss: 0.6128 - acc: 0.6683 - binary_crossentropy: 0.6128 - val_loss: 0.6649 - val_acc: 0.6164 - val_binary_crossentropy: 0.6649\n",
      "Epoch 44/100\n",
      "22777/22777 [==============================] - 2s 93us/sample - loss: 0.6173 - acc: 0.6633 - binary_crossentropy: 0.6173 - val_loss: 0.6541 - val_acc: 0.6213 - val_binary_crossentropy: 0.6541\n",
      "Epoch 45/100\n",
      "22777/22777 [==============================] - 2s 94us/sample - loss: 0.6137 - acc: 0.6668 - binary_crossentropy: 0.6137 - val_loss: 0.6297 - val_acc: 0.6213 - val_binary_crossentropy: 0.6297\n",
      "Epoch 46/100\n",
      "22777/22777 [==============================] - 2s 98us/sample - loss: 0.6131 - acc: 0.6661 - binary_crossentropy: 0.6131 - val_loss: 0.6343 - val_acc: 0.6180 - val_binary_crossentropy: 0.6343\n",
      "Epoch 47/100\n",
      "22777/22777 [==============================] - 2s 98us/sample - loss: 0.6128 - acc: 0.6654 - binary_crossentropy: 0.6128 - val_loss: 0.6367 - val_acc: 0.6213 - val_binary_crossentropy: 0.6367\n",
      "Epoch 48/100\n",
      "22777/22777 [==============================] - 2s 93us/sample - loss: 0.6138 - acc: 0.6653 - binary_crossentropy: 0.6138 - val_loss: 0.6464 - val_acc: 0.6246 - val_binary_crossentropy: 0.6464\n",
      "Epoch 49/100\n",
      "22777/22777 [==============================] - ETA: 0s - loss: 0.6129 - acc: 0.6675 - binary_crossentropy: 0.612 - 2s 69us/sample - loss: 0.6128 - acc: 0.6673 - binary_crossentropy: 0.6128 - val_loss: 0.6583 - val_acc: 0.6262 - val_binary_crossentropy: 0.6583\n",
      "Epoch 50/100\n",
      "22777/22777 [==============================] - 2s 74us/sample - loss: 0.6134 - acc: 0.6655 - binary_crossentropy: 0.6134 - val_loss: 0.6322 - val_acc: 0.6295 - val_binary_crossentropy: 0.6322\n",
      "Epoch 51/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6123 - acc: 0.6666 - binary_crossentropy: 0.6123 - val_loss: 0.6363 - val_acc: 0.6230 - val_binary_crossentropy: 0.6363\n",
      "Epoch 52/100\n",
      "22777/22777 [==============================] - 2s 69us/sample - loss: 0.6110 - acc: 0.6693 - binary_crossentropy: 0.6110 - val_loss: 0.6385 - val_acc: 0.6148 - val_binary_crossentropy: 0.6385\n",
      "Epoch 53/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6141 - acc: 0.6701 - binary_crossentropy: 0.6141 - val_loss: 0.6377 - val_acc: 0.6459 - val_binary_crossentropy: 0.6377\n",
      "Epoch 54/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6123 - acc: 0.6645 - binary_crossentropy: 0.6123 - val_loss: 0.6357 - val_acc: 0.6230 - val_binary_crossentropy: 0.6357\n",
      "Epoch 55/100\n",
      "22777/22777 [==============================] - 2s 87us/sample - loss: 0.6116 - acc: 0.6678 - binary_crossentropy: 0.6116 - val_loss: 0.6321 - val_acc: 0.6279 - val_binary_crossentropy: 0.6321\n",
      "Epoch 56/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6147 - acc: 0.6639 - binary_crossentropy: 0.6147 - val_loss: 0.6497 - val_acc: 0.6443 - val_binary_crossentropy: 0.6497\n",
      "Epoch 57/100\n",
      "22777/22777 [==============================] - 2s 75us/sample - loss: 0.6105 - acc: 0.6711 - binary_crossentropy: 0.6105 - val_loss: 0.6298 - val_acc: 0.6492 - val_binary_crossentropy: 0.6298\n",
      "Epoch 58/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6113 - acc: 0.6679 - binary_crossentropy: 0.6113 - val_loss: 0.6327 - val_acc: 0.6262 - val_binary_crossentropy: 0.6327\n",
      "Epoch 59/100\n",
      "22777/22777 [==============================] - 2s 83us/sample - loss: 0.6123 - acc: 0.6688 - binary_crossentropy: 0.6123 - val_loss: 0.6298 - val_acc: 0.6508 - val_binary_crossentropy: 0.6298\n",
      "Epoch 60/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6125 - acc: 0.6657 - binary_crossentropy: 0.6125 - val_loss: 0.6300 - val_acc: 0.6443 - val_binary_crossentropy: 0.6300\n",
      "Epoch 61/100\n",
      "22777/22777 [==============================] - 1s 61us/sample - loss: 0.6112 - acc: 0.6693 - binary_crossentropy: 0.6112 - val_loss: 0.6311 - val_acc: 0.6377 - val_binary_crossentropy: 0.6311\n",
      "Epoch 62/100\n",
      "22777/22777 [==============================] - 1s 60us/sample - loss: 0.6126 - acc: 0.6676 - binary_crossentropy: 0.6126 - val_loss: 0.6504 - val_acc: 0.6164 - val_binary_crossentropy: 0.6504\n",
      "Epoch 63/100\n",
      "22777/22777 [==============================] - 2s 88us/sample - loss: 0.6107 - acc: 0.6678 - binary_crossentropy: 0.6107 - val_loss: 0.6350 - val_acc: 0.6279 - val_binary_crossentropy: 0.6350\n",
      "Epoch 64/100\n",
      "22777/22777 [==============================] - 1s 61us/sample - loss: 0.6112 - acc: 0.6685 - binary_crossentropy: 0.6112 - val_loss: 0.6602 - val_acc: 0.6115 - val_binary_crossentropy: 0.6602\n",
      "Epoch 65/100\n",
      "22777/22777 [==============================] - 1s 61us/sample - loss: 0.6121 - acc: 0.6653 - binary_crossentropy: 0.6121 - val_loss: 0.6396 - val_acc: 0.6230 - val_binary_crossentropy: 0.6396\n",
      "Epoch 66/100\n",
      "22777/22777 [==============================] - 1s 60us/sample - loss: 0.6113 - acc: 0.6692 - binary_crossentropy: 0.6113 - val_loss: 0.6379 - val_acc: 0.6377 - val_binary_crossentropy: 0.6379\n",
      "Epoch 67/100\n",
      "22777/22777 [==============================] - 1s 52us/sample - loss: 0.6122 - acc: 0.6697 - binary_crossentropy: 0.6122 - val_loss: 0.6423 - val_acc: 0.6246 - val_binary_crossentropy: 0.6423\n",
      "Epoch 68/100\n",
      "22777/22777 [==============================] - 2s 97us/sample - loss: 0.6084 - acc: 0.6688 - binary_crossentropy: 0.6084 - val_loss: 0.6506 - val_acc: 0.6230 - val_binary_crossentropy: 0.6506\n",
      "Epoch 69/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6122 - acc: 0.6705 - binary_crossentropy: 0.6122 - val_loss: 0.6342 - val_acc: 0.6426 - val_binary_crossentropy: 0.6342\n",
      "Epoch 70/100\n",
      "22777/22777 [==============================] - 2s 67us/sample - loss: 0.6107 - acc: 0.6698 - binary_crossentropy: 0.6107 - val_loss: 0.6365 - val_acc: 0.6377 - val_binary_crossentropy: 0.6365\n",
      "Epoch 71/100\n",
      "22777/22777 [==============================] - 1s 56us/sample - loss: 0.6127 - acc: 0.6684 - binary_crossentropy: 0.6127 - val_loss: 0.6387 - val_acc: 0.6361 - val_binary_crossentropy: 0.6387\n",
      "Epoch 72/100\n",
      "22777/22777 [==============================] - 2s 90us/sample - loss: 0.6121 - acc: 0.6695 - binary_crossentropy: 0.6121 - val_loss: 0.6359 - val_acc: 0.6230 - val_binary_crossentropy: 0.6359\n",
      "Epoch 73/100\n",
      "22777/22777 [==============================] - 2s 84us/sample - loss: 0.6099 - acc: 0.6674 - binary_crossentropy: 0.6099 - val_loss: 0.6382 - val_acc: 0.6197 - val_binary_crossentropy: 0.6382\n",
      "Epoch 74/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6103 - acc: 0.6697 - binary_crossentropy: 0.6103 - val_loss: 0.6430 - val_acc: 0.6377 - val_binary_crossentropy: 0.6430\n",
      "Epoch 75/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6107 - acc: 0.6691 - binary_crossentropy: 0.6107 - val_loss: 0.6373 - val_acc: 0.6410 - val_binary_crossentropy: 0.6373\n",
      "Epoch 76/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6087 - acc: 0.6684 - binary_crossentropy: 0.6087 - val_loss: 0.6365 - val_acc: 0.6279 - val_binary_crossentropy: 0.6365\n",
      "Epoch 77/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6116 - acc: 0.6689 - binary_crossentropy: 0.6116 - val_loss: 0.6418 - val_acc: 0.6393 - val_binary_crossentropy: 0.6418\n",
      "Epoch 78/100\n",
      "22777/22777 [==============================] - 3s 116us/sample - loss: 0.6114 - acc: 0.6718 - binary_crossentropy: 0.6114 - val_loss: 0.6387 - val_acc: 0.6262 - val_binary_crossentropy: 0.6387\n",
      "Epoch 79/100\n",
      "22777/22777 [==============================] - 2s 98us/sample - loss: 0.6100 - acc: 0.6719 - binary_crossentropy: 0.6100 - val_loss: 0.6373 - val_acc: 0.6311 - val_binary_crossentropy: 0.6373\n",
      "Epoch 80/100\n",
      "22777/22777 [==============================] - 2s 75us/sample - loss: 0.6098 - acc: 0.6691 - binary_crossentropy: 0.6098 - val_loss: 0.6438 - val_acc: 0.6393 - val_binary_crossentropy: 0.6438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "22777/22777 [==============================] - 2s 73us/sample - loss: 0.6082 - acc: 0.6688 - binary_crossentropy: 0.6082 - val_loss: 0.6396 - val_acc: 0.6197 - val_binary_crossentropy: 0.6396\n",
      "Epoch 82/100\n",
      "22777/22777 [==============================] - 2s 67us/sample - loss: 0.6107 - acc: 0.6708 - binary_crossentropy: 0.6107 - val_loss: 0.6387 - val_acc: 0.6295 - val_binary_crossentropy: 0.6387\n",
      "Epoch 83/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6088 - acc: 0.6701 - binary_crossentropy: 0.6088 - val_loss: 0.6380 - val_acc: 0.6213 - val_binary_crossentropy: 0.6380\n",
      "Epoch 84/100\n",
      "22777/22777 [==============================] - 1s 62us/sample - loss: 0.6076 - acc: 0.6709 - binary_crossentropy: 0.6076 - val_loss: 0.6278 - val_acc: 0.6508 - val_binary_crossentropy: 0.6278\n",
      "Epoch 85/100\n",
      "22777/22777 [==============================] - 1s 66us/sample - loss: 0.6093 - acc: 0.6712 - binary_crossentropy: 0.6093 - val_loss: 0.6286 - val_acc: 0.6328 - val_binary_crossentropy: 0.6286\n",
      "Epoch 86/100\n",
      "22777/22777 [==============================] - 1s 58us/sample - loss: 0.6093 - acc: 0.6680 - binary_crossentropy: 0.6093 - val_loss: 0.6331 - val_acc: 0.6361 - val_binary_crossentropy: 0.6331\n",
      "Epoch 87/100\n",
      "22777/22777 [==============================] - 1s 55us/sample - loss: 0.6090 - acc: 0.6712 - binary_crossentropy: 0.6090 - val_loss: 0.6475 - val_acc: 0.6377 - val_binary_crossentropy: 0.6475\n",
      "Epoch 88/100\n",
      "22777/22777 [==============================] - 2s 84us/sample - loss: 0.6097 - acc: 0.6693 - binary_crossentropy: 0.6097 - val_loss: 0.6450 - val_acc: 0.6279 - val_binary_crossentropy: 0.6450\n",
      "Epoch 89/100\n",
      "22777/22777 [==============================] - 2s 70us/sample - loss: 0.6099 - acc: 0.6704 - binary_crossentropy: 0.6099 - val_loss: 0.6278 - val_acc: 0.6443 - val_binary_crossentropy: 0.6278\n",
      "Epoch 90/100\n",
      "22777/22777 [==============================] - 1s 56us/sample - loss: 0.6110 - acc: 0.6701 - binary_crossentropy: 0.6110 - val_loss: 0.6315 - val_acc: 0.6262 - val_binary_crossentropy: 0.6315\n",
      "Epoch 91/100\n",
      "22777/22777 [==============================] - 1s 54us/sample - loss: 0.6100 - acc: 0.6677 - binary_crossentropy: 0.6100 - val_loss: 0.6292 - val_acc: 0.6426 - val_binary_crossentropy: 0.6292\n",
      "Epoch 92/100\n",
      "22777/22777 [==============================] - 2s 77us/sample - loss: 0.6083 - acc: 0.6727 - binary_crossentropy: 0.6083 - val_loss: 0.6340 - val_acc: 0.6410 - val_binary_crossentropy: 0.6340\n",
      "Epoch 93/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6090 - acc: 0.6693 - binary_crossentropy: 0.6090 - val_loss: 0.6402 - val_acc: 0.6279 - val_binary_crossentropy: 0.6402\n",
      "Epoch 94/100\n",
      "22777/22777 [==============================] - 1s 58us/sample - loss: 0.6089 - acc: 0.6718 - binary_crossentropy: 0.6089 - val_loss: 0.6384 - val_acc: 0.6213 - val_binary_crossentropy: 0.6384\n",
      "Epoch 95/100\n",
      "22777/22777 [==============================] - 1s 59us/sample - loss: 0.6098 - acc: 0.6684 - binary_crossentropy: 0.6098 - val_loss: 0.6350 - val_acc: 0.6426 - val_binary_crossentropy: 0.6350\n",
      "Epoch 96/100\n",
      "22777/22777 [==============================] - 1s 62us/sample - loss: 0.6088 - acc: 0.6701 - binary_crossentropy: 0.6088 - val_loss: 0.6344 - val_acc: 0.6410 - val_binary_crossentropy: 0.6344\n",
      "Epoch 97/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6106 - acc: 0.6687 - binary_crossentropy: 0.6106 - val_loss: 0.6346 - val_acc: 0.6262 - val_binary_crossentropy: 0.6346\n",
      "Epoch 98/100\n",
      "22777/22777 [==============================] - 1s 59us/sample - loss: 0.6100 - acc: 0.6710 - binary_crossentropy: 0.6100 - val_loss: 0.6334 - val_acc: 0.6410 - val_binary_crossentropy: 0.6334\n",
      "Epoch 99/100\n",
      "22777/22777 [==============================] - 1s 54us/sample - loss: 0.6096 - acc: 0.6737 - binary_crossentropy: 0.6096 - val_loss: 0.6374 - val_acc: 0.6230 - val_binary_crossentropy: 0.6374\n",
      "Epoch 100/100\n",
      "22777/22777 [==============================] - 1s 52us/sample - loss: 0.6093 - acc: 0.6717 - binary_crossentropy: 0.6093 - val_loss: 0.6409 - val_acc: 0.6246 - val_binary_crossentropy: 0.6409\n"
     ]
    }
   ],
   "source": [
    "# 드롭아웃만\n",
    "\n",
    "# dpt_model = keras.models.Sequential([\n",
    "#     keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(186,)),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "#     keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# sgd=optimizers.SGD(lr=0.01)\n",
    "\n",
    "# # l2_model.compile(optimizer='sgd',\n",
    "# #                  loss='binary_crossentropy',\n",
    "# #                  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "\n",
    "# dpt_model.compile(optimizer='sgd',\n",
    "#                   loss='binary_crossentropy',\n",
    "#                   metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "# dpt_model_history = dpt_model.fit(xData, yData,\n",
    "#                                   epochs=100,\n",
    "#                                   batch_size=32,\n",
    "#                                   validation_data=(testX, testY),\n",
    "#                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22777 samples, validate on 22777 samples\n",
      "Epoch 1/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.8270 - binary_crossentropy: 0.6877 - val_loss: 0.7077 - val_binary_crossentropy: 0.6533\n",
      "Epoch 2/100\n",
      "22777/22777 [==============================] - 1s 62us/sample - loss: 0.6931 - binary_crossentropy: 0.6531 - val_loss: 0.6664 - val_binary_crossentropy: 0.6357\n",
      "Epoch 3/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6654 - binary_crossentropy: 0.6386 - val_loss: 0.6494 - val_binary_crossentropy: 0.6253\n",
      "Epoch 4/100\n",
      "22777/22777 [==============================] - 2s 70us/sample - loss: 0.6539 - binary_crossentropy: 0.6312 - val_loss: 0.6383 - val_binary_crossentropy: 0.6168\n",
      "Epoch 5/100\n",
      "22777/22777 [==============================] - 1s 61us/sample - loss: 0.6470 - binary_crossentropy: 0.6260 - val_loss: 0.6333 - val_binary_crossentropy: 0.6132\n",
      "Epoch 6/100\n",
      "22777/22777 [==============================] - 2s 75us/sample - loss: 0.6433 - binary_crossentropy: 0.6234 - val_loss: 0.6323 - val_binary_crossentropy: 0.6135\n",
      "Epoch 7/100\n",
      "22777/22777 [==============================] - 2s 91us/sample - loss: 0.6393 - binary_crossentropy: 0.6207 - val_loss: 0.6265 - val_binary_crossentropy: 0.6081\n",
      "Epoch 8/100\n",
      "22777/22777 [==============================] - 2s 83us/sample - loss: 0.6372 - binary_crossentropy: 0.6191 - val_loss: 0.6253 - val_binary_crossentropy: 0.6078\n",
      "Epoch 9/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6352 - binary_crossentropy: 0.6179 - val_loss: 0.6275 - val_binary_crossentropy: 0.6104\n",
      "Epoch 10/100\n",
      "22777/22777 [==============================] - 2s 70us/sample - loss: 0.6340 - binary_crossentropy: 0.6172 - val_loss: 0.6252 - val_binary_crossentropy: 0.6080\n",
      "Epoch 11/100\n",
      "22777/22777 [==============================] - 2s 106us/sample - loss: 0.6340 - binary_crossentropy: 0.6174 - val_loss: 0.6228 - val_binary_crossentropy: 0.6067\n",
      "Epoch 12/100\n",
      "22777/22777 [==============================] - 2s 74us/sample - loss: 0.6332 - binary_crossentropy: 0.6171 - val_loss: 0.6248 - val_binary_crossentropy: 0.6084\n",
      "Epoch 13/100\n",
      "22777/22777 [==============================] - 2s 67us/sample - loss: 0.6314 - binary_crossentropy: 0.6156 - val_loss: 0.6244 - val_binary_crossentropy: 0.6089\n",
      "Epoch 14/100\n",
      "22777/22777 [==============================] - 2s 70us/sample - loss: 0.6319 - binary_crossentropy: 0.6167 - val_loss: 0.6178 - val_binary_crossentropy: 0.6025\n",
      "Epoch 15/100\n",
      "22777/22777 [==============================] - 2s 104us/sample - loss: 0.6329 - binary_crossentropy: 0.6179 - val_loss: 0.6188 - val_binary_crossentropy: 0.6035\n",
      "Epoch 16/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6311 - binary_crossentropy: 0.6162 - val_loss: 0.6187 - val_binary_crossentropy: 0.6038\n",
      "Epoch 17/100\n",
      "22777/22777 [==============================] - 2s 70us/sample - loss: 0.6292 - binary_crossentropy: 0.6146 - val_loss: 0.6168 - val_binary_crossentropy: 0.6024\n",
      "Epoch 18/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6284 - binary_crossentropy: 0.6141 - val_loss: 0.6152 - val_binary_crossentropy: 0.6009\n",
      "Epoch 19/100\n",
      "22777/22777 [==============================] - 2s 86us/sample - loss: 0.6286 - binary_crossentropy: 0.6145 - val_loss: 0.6168 - val_binary_crossentropy: 0.6031\n",
      "Epoch 20/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6291 - binary_crossentropy: 0.6153 - val_loss: 0.6161 - val_binary_crossentropy: 0.6027\n",
      "Epoch 21/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6290 - binary_crossentropy: 0.6156 - val_loss: 0.6156 - val_binary_crossentropy: 0.6022\n",
      "Epoch 22/100\n",
      "22777/22777 [==============================] - 2s 87us/sample - loss: 0.6278 - binary_crossentropy: 0.6144 - val_loss: 0.6180 - val_binary_crossentropy: 0.6047\n",
      "Epoch 23/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6269 - binary_crossentropy: 0.6137 - val_loss: 0.6150 - val_binary_crossentropy: 0.6019\n",
      "Epoch 24/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6282 - binary_crossentropy: 0.6150 - val_loss: 0.6160 - val_binary_crossentropy: 0.6033\n",
      "Epoch 25/100\n",
      "22777/22777 [==============================] - 2s 83us/sample - loss: 0.6258 - binary_crossentropy: 0.6129 - val_loss: 0.6184 - val_binary_crossentropy: 0.6057\n",
      "Epoch 26/100\n",
      "22777/22777 [==============================] - 2s 101us/sample - loss: 0.6254 - binary_crossentropy: 0.6128 - val_loss: 0.6152 - val_binary_crossentropy: 0.6020\n",
      "Epoch 27/100\n",
      "22777/22777 [==============================] - 2s 66us/sample - loss: 0.6247 - binary_crossentropy: 0.6119 - val_loss: 0.6131 - val_binary_crossentropy: 0.6005\n",
      "Epoch 28/100\n",
      "22777/22777 [==============================] - 2s 69us/sample - loss: 0.6259 - binary_crossentropy: 0.6137 - val_loss: 0.6134 - val_binary_crossentropy: 0.6009\n",
      "Epoch 29/100\n",
      "22777/22777 [==============================] - 2s 73us/sample - loss: 0.6253 - binary_crossentropy: 0.6128 - val_loss: 0.6135 - val_binary_crossentropy: 0.6011\n",
      "Epoch 30/100\n",
      "22777/22777 [==============================] - 2s 101us/sample - loss: 0.6253 - binary_crossentropy: 0.6131 - val_loss: 0.6143 - val_binary_crossentropy: 0.6025\n",
      "Epoch 31/100\n",
      "22777/22777 [==============================] - 2s 67us/sample - loss: 0.6256 - binary_crossentropy: 0.6137 - val_loss: 0.6180 - val_binary_crossentropy: 0.6056\n",
      "Epoch 32/100\n",
      "22777/22777 [==============================] - 2s 69us/sample - loss: 0.6249 - binary_crossentropy: 0.6126 - val_loss: 0.6123 - val_binary_crossentropy: 0.6006\n",
      "Epoch 33/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6253 - binary_crossentropy: 0.6132 - val_loss: 0.6241 - val_binary_crossentropy: 0.6122\n",
      "Epoch 34/100\n",
      "22777/22777 [==============================] - 2s 109us/sample - loss: 0.6238 - binary_crossentropy: 0.6119 - val_loss: 0.6117 - val_binary_crossentropy: 0.5996\n",
      "Epoch 35/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6234 - binary_crossentropy: 0.6113 - val_loss: 0.6131 - val_binary_crossentropy: 0.6011\n",
      "Epoch 36/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6252 - binary_crossentropy: 0.6132 - val_loss: 0.6134 - val_binary_crossentropy: 0.6015\n",
      "Epoch 37/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6240 - binary_crossentropy: 0.6123 - val_loss: 0.6133 - val_binary_crossentropy: 0.6017\n",
      "Epoch 38/100\n",
      "22777/22777 [==============================] - 2s 92us/sample - loss: 0.6223 - binary_crossentropy: 0.6103 - val_loss: 0.6130 - val_binary_crossentropy: 0.6013\n",
      "Epoch 39/100\n",
      "22777/22777 [==============================] - 1s 62us/sample - loss: 0.6229 - binary_crossentropy: 0.6112 - val_loss: 0.6128 - val_binary_crossentropy: 0.6011\n",
      "Epoch 40/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6257 - binary_crossentropy: 0.6141 - val_loss: 0.6116 - val_binary_crossentropy: 0.6001\n",
      "Epoch 41/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6239 - binary_crossentropy: 0.6125 - val_loss: 0.6173 - val_binary_crossentropy: 0.6059\n",
      "Epoch 42/100\n",
      "22777/22777 [==============================] - 2s 95us/sample - loss: 0.6237 - binary_crossentropy: 0.6123 - val_loss: 0.6116 - val_binary_crossentropy: 0.6002\n",
      "Epoch 43/100\n",
      "22777/22777 [==============================] - 2s 75us/sample - loss: 0.6220 - binary_crossentropy: 0.6106 - val_loss: 0.6108 - val_binary_crossentropy: 0.5995\n",
      "Epoch 44/100\n",
      "22777/22777 [==============================] - 2s 85us/sample - loss: 0.6235 - binary_crossentropy: 0.6122 - val_loss: 0.6120 - val_binary_crossentropy: 0.6008\n",
      "Epoch 45/100\n",
      "22777/22777 [==============================] - 2s 91us/sample - loss: 0.6215 - binary_crossentropy: 0.6102 - val_loss: 0.6119 - val_binary_crossentropy: 0.6005\n",
      "Epoch 46/100\n",
      "22777/22777 [==============================] - 2s 85us/sample - loss: 0.6214 - binary_crossentropy: 0.6100 - val_loss: 0.6112 - val_binary_crossentropy: 0.5999\n",
      "Epoch 47/100\n",
      "22777/22777 [==============================] - 2s 88us/sample - loss: 0.6228 - binary_crossentropy: 0.6113 - val_loss: 0.6133 - val_binary_crossentropy: 0.6022\n",
      "Epoch 48/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6215 - binary_crossentropy: 0.6104 - val_loss: 0.6222 - val_binary_crossentropy: 0.6107\n",
      "Epoch 49/100\n",
      "22777/22777 [==============================] - 2s 96us/sample - loss: 0.6234 - binary_crossentropy: 0.6123 - val_loss: 0.6084 - val_binary_crossentropy: 0.5970\n",
      "Epoch 50/100\n",
      "22777/22777 [==============================] - 1s 66us/sample - loss: 0.6224 - binary_crossentropy: 0.6113 - val_loss: 0.6086 - val_binary_crossentropy: 0.5974\n",
      "Epoch 51/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6219 - binary_crossentropy: 0.6106 - val_loss: 0.6139 - val_binary_crossentropy: 0.6029\n",
      "Epoch 52/100\n",
      "22777/22777 [==============================] - 2s 86us/sample - loss: 0.6213 - binary_crossentropy: 0.6101 - val_loss: 0.6100 - val_binary_crossentropy: 0.5991\n",
      "Epoch 53/100\n",
      "22777/22777 [==============================] - 2s 93us/sample - loss: 0.6209 - binary_crossentropy: 0.6099 - val_loss: 0.6116 - val_binary_crossentropy: 0.6006\n",
      "Epoch 54/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6226 - binary_crossentropy: 0.6118 - val_loss: 0.6150 - val_binary_crossentropy: 0.6043\n",
      "Epoch 55/100\n",
      "22777/22777 [==============================] - 1s 62us/sample - loss: 0.6213 - binary_crossentropy: 0.6104 - val_loss: 0.6109 - val_binary_crossentropy: 0.6001\n",
      "Epoch 56/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6211 - binary_crossentropy: 0.6104 - val_loss: 0.6110 - val_binary_crossentropy: 0.6003\n",
      "Epoch 57/100\n",
      "22777/22777 [==============================] - 2s 95us/sample - loss: 0.6217 - binary_crossentropy: 0.6110 - val_loss: 0.6083 - val_binary_crossentropy: 0.5980\n",
      "Epoch 58/100\n",
      "22777/22777 [==============================] - 2s 68us/sample - loss: 0.6203 - binary_crossentropy: 0.6100 - val_loss: 0.6139 - val_binary_crossentropy: 0.6033\n",
      "Epoch 59/100\n",
      "22777/22777 [==============================] - 2s 66us/sample - loss: 0.6205 - binary_crossentropy: 0.6097 - val_loss: 0.6098 - val_binary_crossentropy: 0.5995\n",
      "Epoch 60/100\n",
      "22777/22777 [==============================] - 2s 84us/sample - loss: 0.6215 - binary_crossentropy: 0.6109 - val_loss: 0.6115 - val_binary_crossentropy: 0.6012\n",
      "Epoch 61/100\n",
      "22777/22777 [==============================] - 2s 104us/sample - loss: 0.6220 - binary_crossentropy: 0.6118 - val_loss: 0.6204 - val_binary_crossentropy: 0.6101\n",
      "Epoch 62/100\n",
      "22777/22777 [==============================] - 2s 68us/sample - loss: 0.6189 - binary_crossentropy: 0.6085 - val_loss: 0.6079 - val_binary_crossentropy: 0.5975\n",
      "Epoch 63/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6216 - binary_crossentropy: 0.6111 - val_loss: 0.6143 - val_binary_crossentropy: 0.6039\n",
      "Epoch 64/100\n",
      "22777/22777 [==============================] - 2s 74us/sample - loss: 0.6195 - binary_crossentropy: 0.6090 - val_loss: 0.6088 - val_binary_crossentropy: 0.5982\n",
      "Epoch 65/100\n",
      "22777/22777 [==============================] - 2s 86us/sample - loss: 0.6203 - binary_crossentropy: 0.6099 - val_loss: 0.6100 - val_binary_crossentropy: 0.5997\n",
      "Epoch 66/100\n",
      "22777/22777 [==============================] - 2s 85us/sample - loss: 0.6210 - binary_crossentropy: 0.6109 - val_loss: 0.6114 - val_binary_crossentropy: 0.6009\n",
      "Epoch 67/100\n",
      "22777/22777 [==============================] - 2s 73us/sample - loss: 0.6195 - binary_crossentropy: 0.6091 - val_loss: 0.6093 - val_binary_crossentropy: 0.5987\n",
      "Epoch 68/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6212 - binary_crossentropy: 0.6105 - val_loss: 0.6162 - val_binary_crossentropy: 0.6056\n",
      "Epoch 69/100\n",
      "22777/22777 [==============================] - 2s 96us/sample - loss: 0.6207 - binary_crossentropy: 0.6102 - val_loss: 0.6157 - val_binary_crossentropy: 0.6055\n",
      "Epoch 70/100\n",
      "22777/22777 [==============================] - 2s 100us/sample - loss: 0.6199 - binary_crossentropy: 0.6095 - val_loss: 0.6096 - val_binary_crossentropy: 0.5993\n",
      "Epoch 71/100\n",
      "22777/22777 [==============================] - 2s 94us/sample - loss: 0.6207 - binary_crossentropy: 0.6102 - val_loss: 0.6144 - val_binary_crossentropy: 0.6045\n",
      "Epoch 72/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6207 - binary_crossentropy: 0.6108 - val_loss: 0.6085 - val_binary_crossentropy: 0.5986\n",
      "Epoch 73/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6195 - binary_crossentropy: 0.6093 - val_loss: 0.6063 - val_binary_crossentropy: 0.5961\n",
      "Epoch 74/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6199 - binary_crossentropy: 0.6098 - val_loss: 0.6145 - val_binary_crossentropy: 0.6045\n",
      "Epoch 75/100\n",
      "22777/22777 [==============================] - 2s 86us/sample - loss: 0.6191 - binary_crossentropy: 0.6090 - val_loss: 0.6107 - val_binary_crossentropy: 0.6004\n",
      "Epoch 76/100\n",
      "22777/22777 [==============================] - 2s 67us/sample - loss: 0.6219 - binary_crossentropy: 0.6119 - val_loss: 0.6065 - val_binary_crossentropy: 0.5963\n",
      "Epoch 77/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6206 - binary_crossentropy: 0.6103 - val_loss: 0.6076 - val_binary_crossentropy: 0.5976\n",
      "Epoch 78/100\n",
      "22777/22777 [==============================] - 2s 87us/sample - loss: 0.6171 - binary_crossentropy: 0.6072 - val_loss: 0.6092 - val_binary_crossentropy: 0.5992\n",
      "Epoch 79/100\n",
      "22777/22777 [==============================] - 2s 88us/sample - loss: 0.6199 - binary_crossentropy: 0.6100 - val_loss: 0.6072 - val_binary_crossentropy: 0.5973\n",
      "Epoch 80/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6184 - binary_crossentropy: 0.6084 - val_loss: 0.6076 - val_binary_crossentropy: 0.5977\n",
      "Epoch 81/100\n",
      "22777/22777 [==============================] - 2s 74us/sample - loss: 0.6180 - binary_crossentropy: 0.6080 - val_loss: 0.6113 - val_binary_crossentropy: 0.6014\n",
      "Epoch 82/100\n",
      "22777/22777 [==============================] - 2s 68us/sample - loss: 0.6194 - binary_crossentropy: 0.6096 - val_loss: 0.6097 - val_binary_crossentropy: 0.6001s - loss: 0.6224 - binary_crossentro\n",
      "Epoch 83/100\n",
      "22777/22777 [==============================] - 2s 77us/sample - loss: 0.6187 - binary_crossentropy: 0.6089 - val_loss: 0.6059 - val_binary_crossentropy: 0.5960\n",
      "Epoch 84/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6184 - binary_crossentropy: 0.6083 - val_loss: 0.6109 - val_binary_crossentropy: 0.6008\n",
      "Epoch 85/100\n",
      "22777/22777 [==============================] - 2s 74us/sample - loss: 0.6176 - binary_crossentropy: 0.6076 - val_loss: 0.6062 - val_binary_crossentropy: 0.5963\n",
      "Epoch 86/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6215 - binary_crossentropy: 0.6114 - val_loss: 0.6111 - val_binary_crossentropy: 0.6013\n",
      "Epoch 87/100\n",
      "22777/22777 [==============================] - 2s 73us/sample - loss: 0.6199 - binary_crossentropy: 0.6099 - val_loss: 0.6097 - val_binary_crossentropy: 0.5998\n",
      "Epoch 88/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6204 - binary_crossentropy: 0.6106 - val_loss: 0.6068 - val_binary_crossentropy: 0.5972\n",
      "Epoch 89/100\n",
      "22777/22777 [==============================] - 2s 67us/sample - loss: 0.6188 - binary_crossentropy: 0.6090 - val_loss: 0.6061 - val_binary_crossentropy: 0.5961\n",
      "Epoch 90/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6169 - binary_crossentropy: 0.6071 - val_loss: 0.6067 - val_binary_crossentropy: 0.5972loss: 0.6163 - binary_crossentropy: 0.60\n",
      "Epoch 91/100\n",
      "22777/22777 [==============================] - 2s 68us/sample - loss: 0.6199 - binary_crossentropy: 0.6099 - val_loss: 0.6076 - val_binary_crossentropy: 0.5980\n",
      "Epoch 92/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6194 - binary_crossentropy: 0.6094 - val_loss: 0.6076 - val_binary_crossentropy: 0.5975 0s - loss: 0.6178 - binary_crossentropy: 0\n",
      "Epoch 93/100\n",
      "22777/22777 [==============================] - 2s 75us/sample - loss: 0.6167 - binary_crossentropy: 0.6067 - val_loss: 0.6084 - val_binary_crossentropy: 0.5984\n",
      "Epoch 94/100\n",
      "22777/22777 [==============================] - 2s 86us/sample - loss: 0.6194 - binary_crossentropy: 0.6094 - val_loss: 0.6099 - val_binary_crossentropy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "22777/22777 [==============================] - 1s 58us/sample - loss: 0.6181 - binary_crossentropy: 0.6082 - val_loss: 0.6102 - val_binary_crossentropy: 0.6003\n",
      "Epoch 96/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6180 - binary_crossentropy: 0.6084 - val_loss: 0.6080 - val_binary_crossentropy: 0.5986\n",
      "Epoch 97/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6184 - binary_crossentropy: 0.6086 - val_loss: 0.6073 - val_binary_crossentropy: 0.5977\n",
      "Epoch 98/100\n",
      "22777/22777 [==============================] - 2s 89us/sample - loss: 0.6180 - binary_crossentropy: 0.6082 - val_loss: 0.6054 - val_binary_crossentropy: 0.5956\n",
      "Epoch 99/100\n",
      "22777/22777 [==============================] - 1s 59us/sample - loss: 0.6200 - binary_crossentropy: 0.6102 - val_loss: 0.6048 - val_binary_crossentropy: 0.5950\n",
      "Epoch 100/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6192 - binary_crossentropy: 0.6094 - val_loss: 0.6078 - val_binary_crossentropy: 0.5981\n",
      "train, loss and metric: [1.1283702819073786, 0.5491803, 0.6823327]\n"
     ]
    }
   ],
   "source": [
    "# L2규제, 드롭아웃 모두 적용\n",
    "\n",
    "l2_dpt_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                       activation=tf.nn.relu, input_shape=(186,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                       activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "]) \n",
    "adam=optimizers.Adam(lr=0.01)\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "l2_dpt_model.compile(optimizer=sgd,\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "l2_model.fit(xData, yData,epochs=100,batch_size=64,validation_data=(xData, yData),verbose=1)\n",
    "loss_and_metric = l2_dpt_model.evaluate(testX, testY, batch_size=32, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입양 확률 :  94.2203%\n",
      "입양 확률 :  36.7390%\n",
      "입양 확률 :  35.8996%\n",
      "입양 확률 :  78.0932%\n",
      "입양 확률 :  21.0893%\n",
      "입양 확률 :  21.0893%\n",
      "입양 확률 :  91.3862%\n",
      "입양 확률 :  78.4416%\n",
      "입양 확률 :  89.5666%\n",
      "입양 확률 :  84.8468%\n",
      "입양 확률 :  72.6395%\n",
      "입양 확률 :  85.3167%\n",
      "입양 확률 :  55.5937%\n",
      "입양 확률 :  49.5257%\n",
      "입양 확률 :  51.3644%\n",
      "입양 확률 :  28.9706%\n",
      "입양 확률 :  44.0449%\n",
      "입양 확률 :  37.9210%\n",
      "입양 확률 :  83.8701%\n",
      "입양 확률 :  23.1563%\n",
      "입양 확률 :  64.8517%\n",
      "입양 확률 :  64.8517%\n",
      "입양 확률 :  53.8228%\n",
      "입양 확률 :  46.9142%\n",
      "입양 확률 :  71.4867%\n",
      "입양 확률 :  58.0059%\n",
      "입양 확률 :  54.1604%\n",
      "입양 확률 :  57.8769%\n",
      "입양 확률 :  41.1052%\n",
      "입양 확률 :  54.8027%\n",
      "입양 확률 :  56.1087%\n",
      "입양 확률 :  41.1052%\n",
      "입양 확률 :  40.0840%\n",
      "입양 확률 :  37.2096%\n",
      "입양 확률 :  90.8167%\n",
      "입양 확률 :  88.6520%\n",
      "입양 확률 :  19.2490%\n",
      "입양 확률 :  69.2019%\n",
      "입양 확률 :  76.6373%\n",
      "입양 확률 :  28.4616%\n",
      "입양 확률 :  26.2082%\n",
      "입양 확률 :  37.8162%\n",
      "입양 확률 :  49.3927%\n",
      "입양 확률 :  31.0500%\n",
      "입양 확률 :  32.5425%\n",
      "입양 확률 :  45.5628%\n",
      "입양 확률 :  49.3927%\n",
      "입양 확률 :  51.3507%\n",
      "입양 확률 :  36.3324%\n",
      "입양 확률 :  45.9654%\n",
      "입양 확률 :  29.5362%\n",
      "입양 확률 :  29.1457%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  52.2923%\n",
      "입양 확률 :  54.0260%\n",
      "입양 확률 :  51.3507%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  32.1351%\n",
      "입양 확률 :  67.2334%\n",
      "입양 확률 :  56.3661%\n",
      "입양 확률 :  57.1026%\n",
      "입양 확률 :  55.8354%\n",
      "입양 확률 :  37.6229%\n",
      "입양 확률 :  93.1751%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  78.7943%\n",
      "입양 확률 :  18.4336%\n",
      "입양 확률 :  80.2123%\n",
      "입양 확률 :  72.8484%\n",
      "입양 확률 :  51.0164%\n",
      "입양 확률 :  53.1521%\n",
      "입양 확률 :  77.7039%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  37.9588%\n",
      "입양 확률 :  42.8758%\n",
      "입양 확률 :  51.4375%\n",
      "입양 확률 :  34.8071%\n",
      "입양 확률 :  90.5109%\n",
      "입양 확률 :  23.0991%\n",
      "입양 확률 :  74.9863%\n",
      "입양 확률 :  48.8126%\n",
      "입양 확률 :  52.8710%\n",
      "입양 확률 :  48.1297%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  53.9207%\n",
      "입양 확률 :  48.7735%\n",
      "입양 확률 :  23.6678%\n",
      "입양 확률 :  75.7269%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  57.5152%\n",
      "입양 확률 :  50.9764%\n",
      "입양 확률 :  90.9335%\n",
      "입양 확률 :  34.4362%\n",
      "입양 확률 :  80.4421%\n",
      "입양 확률 :  86.2377%\n",
      "입양 확률 :  24.7418%\n",
      "입양 확률 :  62.9177%\n",
      "입양 확률 :  85.2348%\n",
      "입양 확률 :  28.6270%\n",
      "입양 확률 :  84.8854%\n",
      "입양 확률 :  65.3681%\n",
      "입양 확률 :  29.6700%\n",
      "입양 확률 :  42.5086%\n",
      "입양 확률 :  71.8598%\n",
      "입양 확률 :  37.7539%\n",
      "입양 확률 :  32.4765%\n",
      "입양 확률 :  38.1661%\n",
      "입양 확률 :  86.8071%\n",
      "입양 확률 :  79.7014%\n",
      "입양 확률 :  22.1511%\n",
      "입양 확률 :  22.1511%\n",
      "입양 확률 :  81.6765%\n",
      "입양 확률 :  26.6789%\n",
      "입양 확률 :  65.5374%\n",
      "입양 확률 :  48.4780%\n",
      "입양 확률 :  63.2604%\n",
      "입양 확률 :  89.2275%\n",
      "입양 확률 :  30.8939%\n",
      "입양 확률 :  37.8441%\n",
      "입양 확률 :  38.0527%\n",
      "입양 확률 :  29.3965%\n",
      "입양 확률 :  76.1217%\n",
      "입양 확률 :  83.7344%\n",
      "입양 확률 :  82.3084%\n",
      "입양 확률 :  35.1551%\n",
      "입양 확률 :  80.5109%\n",
      "입양 확률 :  94.7565%\n",
      "입양 확률 :  78.0636%\n",
      "입양 확률 :  59.0956%\n",
      "입양 확률 :  61.4141%\n",
      "입양 확률 :  25.9249%\n",
      "입양 확률 :  94.6280%\n",
      "입양 확률 :  94.1429%\n",
      "입양 확률 :  59.0332%\n",
      "입양 확률 :  90.5268%\n",
      "입양 확률 :  89.4795%\n",
      "입양 확률 :  90.4354%\n",
      "입양 확률 :  28.0512%\n",
      "입양 확률 :  36.5923%\n",
      "입양 확률 :  31.5406%\n",
      "입양 확률 :  35.0414%\n",
      "입양 확률 :  29.4471%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  86.8184%\n",
      "입양 확률 :  44.3399%\n",
      "입양 확률 :  70.0254%\n",
      "입양 확률 :  89.8535%\n",
      "입양 확률 :  43.6976%\n",
      "입양 확률 :  49.5257%\n",
      "입양 확률 :  24.8949%\n",
      "입양 확률 :  31.8996%\n",
      "입양 확률 :  28.3564%\n",
      "입양 확률 :  69.9115%\n",
      "입양 확률 :  87.0251%\n",
      "입양 확률 :  36.3324%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  66.9685%\n",
      "입양 확률 :  78.0211%\n",
      "입양 확률 :  39.7200%\n",
      "입양 확률 :  29.8014%\n",
      "입양 확률 :  87.8142%\n",
      "입양 확률 :  55.7829%\n",
      "입양 확률 :  92.1527%\n",
      "입양 확률 :  82.1423%\n",
      "입양 확률 :  49.8603%\n",
      "입양 확률 :  91.5583%\n",
      "입양 확률 :  73.2581%\n",
      "입양 확률 :  89.3106%\n",
      "입양 확률 :  86.8845%\n",
      "입양 확률 :  36.3459%\n",
      "입양 확률 :  74.8865%\n",
      "입양 확률 :  26.7738%\n",
      "입양 확률 :  76.2915%\n",
      "입양 확률 :  55.9331%\n",
      "입양 확률 :  91.4863%\n",
      "입양 확률 :  29.6403%\n",
      "입양 확률 :  77.2823%\n",
      "입양 확률 :  84.6162%\n",
      "입양 확률 :  44.8503%\n",
      "입양 확률 :  80.0782%\n",
      "입양 확률 :  32.7578%\n",
      "입양 확률 :  39.8271%\n",
      "입양 확률 :  37.7214%\n",
      "입양 확률 :  41.7302%\n",
      "입양 확률 :  90.8608%\n",
      "입양 확률 :  31.8540%\n",
      "입양 확률 :  43.6976%\n",
      "입양 확률 :  39.6527%\n",
      "입양 확률 :  40.5991%\n",
      "입양 확률 :  86.8982%\n",
      "입양 확률 :  46.6477%\n",
      "입양 확률 :  34.0550%\n",
      "입양 확률 :  91.7288%\n",
      "입양 확률 :  42.0999%\n",
      "입양 확률 :  82.7919%\n",
      "입양 확률 :  39.7626%\n",
      "입양 확률 :  75.2077%\n",
      "입양 확률 :  38.4672%\n",
      "입양 확률 :  80.2841%\n",
      "입양 확률 :  74.9565%\n",
      "입양 확률 :  80.4142%\n",
      "입양 확률 :  84.9896%\n",
      "입양 확률 :  72.0752%\n",
      "입양 확률 :  27.7959%\n",
      "입양 확률 :  52.4399%\n",
      "입양 확률 :  54.0417%\n",
      "입양 확률 :  40.3163%\n",
      "입양 확률 :  55.1982%\n",
      "입양 확률 :  95.1264%\n",
      "입양 확률 :  73.9199%\n",
      "입양 확률 :  26.0297%\n",
      "입양 확률 :  49.9497%\n",
      "입양 확률 :  40.4894%\n",
      "입양 확률 :  71.9049%\n",
      "입양 확률 :  80.2524%\n",
      "입양 확률 :  53.8228%\n",
      "입양 확률 :  30.5333%\n",
      "입양 확률 :  36.2937%\n",
      "입양 확률 :  44.1794%\n",
      "입양 확률 :  28.2019%\n",
      "입양 확률 :  71.3230%\n",
      "입양 확률 :  71.3230%\n",
      "입양 확률 :  62.0971%\n",
      "입양 확률 :  67.3646%\n",
      "입양 확률 :  91.4151%\n",
      "입양 확률 :  78.5369%\n",
      "입양 확률 :  33.3205%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  60.2206%\n",
      "입양 확률 :  24.6817%\n",
      "입양 확률 :  93.9052%\n",
      "입양 확률 :  67.0049%\n",
      "입양 확률 :  67.2633%\n",
      "입양 확률 :  48.2329%\n",
      "입양 확률 :  87.2070%\n",
      "입양 확률 :  37.5005%\n",
      "입양 확률 :  55.5821%\n",
      "입양 확률 :  86.9302%\n",
      "입양 확률 :  36.5923%\n",
      "입양 확률 :  29.1846%\n",
      "입양 확률 :  83.3939%\n",
      "입양 확률 :  79.4073%\n",
      "입양 확률 :  30.9433%\n",
      "입양 확률 :  32.0811%\n",
      "입양 확률 :  30.2279%\n",
      "입양 확률 :  56.1816%\n",
      "입양 확률 :  29.3114%\n",
      "입양 확률 :  88.4804%\n",
      "입양 확률 :  37.4983%\n",
      "입양 확률 :  85.4370%\n",
      "입양 확률 :  29.4495%\n",
      "입양 확률 :  34.0754%\n",
      "입양 확률 :  91.5203%\n",
      "입양 확률 :  40.3446%\n",
      "입양 확률 :  40.7096%\n",
      "입양 확률 :  82.0429%\n",
      "입양 확률 :  43.7205%\n",
      "입양 확률 :  94.1259%\n",
      "입양 확률 :  93.7749%\n",
      "입양 확률 :  32.7578%\n",
      "입양 확률 :  89.7685%\n",
      "입양 확률 :  57.5454%\n",
      "입양 확률 :  27.6363%\n",
      "입양 확률 :  33.2161%\n",
      "입양 확률 :  23.2291%\n",
      "입양 확률 :  42.7267%\n",
      "입양 확률 :  85.2137%\n",
      "입양 확률 :  40.6669%\n",
      "입양 확률 :  84.5175%\n",
      "입양 확률 :  54.4749%\n",
      "입양 확률 :  48.5200%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  28.2052%\n",
      "입양 확률 :  76.6274%\n",
      "입양 확률 :  90.2871%\n",
      "입양 확률 :  63.5538%\n",
      "입양 확률 :  25.3717%\n",
      "입양 확률 :  46.1768%\n",
      "입양 확률 :  45.3451%\n",
      "입양 확률 :  42.0999%\n",
      "입양 확률 :  36.7390%\n",
      "입양 확률 :  36.3324%\n",
      "입양 확률 :  88.9029%\n",
      "입양 확률 :  33.5215%\n",
      "입양 확률 :  83.5877%\n",
      "입양 확률 :  84.4071%\n",
      "입양 확률 :  44.9242%\n",
      "입양 확률 :  93.1353%\n",
      "입양 확률 :  93.0980%\n",
      "입양 확률 :  71.1721%\n",
      "입양 확률 :  33.2620%\n",
      "입양 확률 :  88.0267%\n",
      "입양 확률 :  27.7433%\n",
      "입양 확률 :  82.5484%\n",
      "입양 확률 :  23.8201%\n",
      "입양 확률 :  70.6739%\n",
      "입양 확률 :  27.7433%\n",
      "입양 확률 :  90.6982%\n",
      "입양 확률 :  27.3487%\n",
      "입양 확률 :  34.1240%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  31.3785%\n",
      "입양 확률 :  47.1705%\n",
      "입양 확률 :  51.7130%\n",
      "입양 확률 :  33.3122%\n",
      "입양 확률 :  29.6297%\n",
      "입양 확률 :  76.7626%\n",
      "입양 확률 :  53.2499%\n",
      "입양 확률 :  28.9213%\n",
      "입양 확률 :  48.7735%\n",
      "입양 확률 :  76.6945%\n",
      "입양 확률 :  90.6940%\n",
      "입양 확률 :  88.4009%\n",
      "입양 확률 :  75.0052%\n",
      "입양 확률 :  23.1924%\n",
      "입양 확률 :  37.5005%\n",
      "입양 확률 :  30.2065%\n",
      "입양 확률 :  54.0701%\n",
      "입양 확률 :  68.7554%\n",
      "입양 확률 :  84.6845%\n",
      "입양 확률 :  36.9821%\n",
      "입양 확률 :  78.4158%\n",
      "입양 확률 :  36.5923%\n",
      "입양 확률 :  40.4196%\n",
      "입양 확률 :  86.4652%\n",
      "입양 확률 :  82.5119%\n",
      "입양 확률 :  24.6226%\n",
      "입양 확률 :  30.2970%\n",
      "입양 확률 :  69.4716%\n",
      "입양 확률 :  93.0375%\n",
      "입양 확률 :  33.6043%\n",
      "입양 확률 :  90.0557%\n",
      "입양 확률 :  50.7865%\n",
      "입양 확률 :  33.3205%\n",
      "입양 확률 :  32.4314%\n",
      "입양 확률 :  82.5378%\n",
      "입양 확률 :  29.6516%\n",
      "입양 확률 :  74.6187%\n",
      "입양 확률 :  33.0861%\n",
      "입양 확률 :  76.5208%\n",
      "입양 확률 :  39.1582%\n",
      "입양 확률 :  39.1582%\n",
      "입양 확률 :  27.7513%\n",
      "입양 확률 :  85.2101%\n",
      "입양 확률 :  29.1949%\n",
      "입양 확률 :  28.9213%\n",
      "입양 확률 :  34.1780%\n",
      "입양 확률 :  37.3953%\n",
      "입양 확률 :  39.9117%\n",
      "입양 확률 :  30.6148%\n",
      "입양 확률 :  27.3846%\n",
      "입양 확률 :  55.7829%\n",
      "입양 확률 :  55.7829%\n",
      "입양 확률 :  84.6056%\n",
      "입양 확률 :  29.5503%\n",
      "입양 확률 :  80.6437%\n",
      "입양 확률 :  48.7735%\n",
      "입양 확률 :  29.0381%\n",
      "입양 확률 :  85.7431%\n",
      "입양 확률 :  29.5508%\n",
      "입양 확률 :  29.5007%\n",
      "입양 확률 :  29.5007%\n",
      "입양 확률 :  36.3402%\n",
      "입양 확률 :  22.9240%\n",
      "입양 확률 :  68.0388%\n",
      "입양 확률 :  45.0437%\n",
      "입양 확률 :  51.8110%\n",
      "입양 확률 :  91.0538%\n",
      "입양 확률 :  92.6616%\n",
      "입양 확률 :  27.0242%\n",
      "입양 확률 :  36.8133%\n",
      "입양 확률 :  73.4615%\n",
      "입양 확률 :  64.4615%\n",
      "입양 확률 :  92.7757%\n",
      "입양 확률 :  82.4978%\n",
      "입양 확률 :  56.0847%\n",
      "입양 확률 :  57.7592%\n",
      "입양 확률 :  73.3543%\n",
      "입양 확률 :  43.9328%\n",
      "입양 확률 :  84.2009%\n",
      "입양 확률 :  43.5355%\n",
      "입양 확률 :  22.8924%\n",
      "입양 확률 :  72.6577%\n",
      "입양 확률 :  29.1657%\n",
      "입양 확률 :  88.6260%\n",
      "입양 확률 :  42.2912%\n",
      "입양 확률 :  36.0405%\n",
      "입양 확률 :  94.3621%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  29.5317%\n",
      "입양 확률 :  75.3754%\n",
      "입양 확률 :  54.0260%\n",
      "입양 확률 :  54.0260%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  31.3785%\n",
      "입양 확률 :  42.0999%\n",
      "입양 확률 :  58.0729%\n",
      "입양 확률 :  31.4567%\n",
      "입양 확률 :  25.0710%\n",
      "입양 확률 :  28.8452%\n",
      "입양 확률 :  94.4262%\n",
      "입양 확률 :  38.4951%\n",
      "입양 확률 :  36.7675%\n",
      "입양 확률 :  20.2064%\n",
      "입양 확률 :  28.9213%\n",
      "입양 확률 :  77.4118%\n",
      "입양 확률 :  44.3877%\n",
      "입양 확률 :  91.2746%\n",
      "입양 확률 :  58.3606%\n",
      "입양 확률 :  58.3606%\n",
      "입양 확률 :  57.1406%\n",
      "입양 확률 :  94.4116%\n",
      "입양 확률 :  66.8996%\n",
      "입양 확률 :  36.2556%\n",
      "입양 확률 :  89.6569%\n",
      "입양 확률 :  77.3612%\n",
      "입양 확률 :  79.5870%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  91.3021%\n",
      "입양 확률 :  21.5133%\n",
      "입양 확률 :  21.5133%\n",
      "입양 확률 :  53.4980%\n",
      "입양 확률 :  39.2845%\n",
      "입양 확률 :  42.2721%\n",
      "입양 확률 :  32.6121%\n",
      "입양 확률 :  33.0232%\n",
      "입양 확률 :  91.6300%\n",
      "입양 확률 :  87.2243%\n",
      "입양 확률 :  86.9037%\n",
      "입양 확률 :  20.0483%\n",
      "입양 확률 :  50.5222%\n",
      "입양 확률 :  44.1166%\n",
      "입양 확률 :  57.5966%\n",
      "입양 확률 :  85.0742%\n",
      "입양 확률 :  85.0742%\n",
      "입양 확률 :  85.0742%\n",
      "입양 확률 :  92.5027%\n",
      "입양 확률 :  33.8111%\n",
      "입양 확률 :  35.8180%\n",
      "입양 확률 :  73.8789%\n",
      "입양 확률 :  19.6655%\n",
      "입양 확률 :  20.9785%\n",
      "입양 확률 :  48.2864%\n",
      "입양 확률 :  55.5369%\n",
      "입양 확률 :  82.0286%\n",
      "입양 확률 :  28.0213%\n",
      "입양 확률 :  25.0031%\n",
      "입양 확률 :  71.9830%\n",
      "입양 확률 :  69.3335%\n",
      "입양 확률 :  94.2947%\n",
      "입양 확률 :  54.5583%\n",
      "입양 확률 :  79.8950%\n",
      "입양 확률 :  79.5124%\n",
      "입양 확률 :  65.0101%\n",
      "입양 확률 :  92.5092%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입양 확률 :  28.6237%\n",
      "입양 확률 :  93.3353%\n",
      "입양 확률 :  32.6441%\n",
      "입양 확률 :  37.7122%\n",
      "입양 확률 :  67.2223%\n",
      "입양 확률 :  23.0380%\n",
      "입양 확률 :  70.3892%\n",
      "입양 확률 :  77.7126%\n",
      "입양 확률 :  55.1501%\n",
      "입양 확률 :  57.7917%\n",
      "입양 확률 :  67.0752%\n",
      "입양 확률 :  32.6870%\n",
      "입양 확률 :  88.6794%\n",
      "입양 확률 :  50.1714%\n",
      "입양 확률 :  34.4334%\n",
      "입양 확률 :  30.2486%\n",
      "입양 확률 :  57.1593%\n",
      "입양 확률 :  53.8719%\n",
      "입양 확률 :  71.0483%\n",
      "입양 확률 :  66.8481%\n",
      "입양 확률 :  83.2895%\n",
      "입양 확률 :  59.9851%\n",
      "입양 확률 :  87.3223%\n",
      "입양 확률 :  94.8906%\n",
      "입양 확률 :  53.2306%\n",
      "입양 확률 :  41.5467%\n",
      "입양 확률 :  41.7502%\n",
      "입양 확률 :  26.5065%\n",
      "입양 확률 :  29.7671%\n",
      "입양 확률 :  96.1752%\n",
      "입양 확률 :  44.4502%\n",
      "입양 확률 :  92.8657%\n",
      "입양 확률 :  39.4909%\n",
      "입양 확률 :  83.0424%\n",
      "입양 확률 :  91.3181%\n",
      "입양 확률 :  86.7357%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  23.3083%\n",
      "입양 확률 :  24.4934%\n",
      "입양 확률 :  90.5356%\n",
      "입양 확률 :  65.2899%\n",
      "입양 확률 :  32.4555%\n",
      "입양 확률 :  20.8052%\n",
      "입양 확률 :  31.4452%\n",
      "입양 확률 :  50.1362%\n",
      "입양 확률 :  52.8710%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  53.4489%\n",
      "입양 확률 :  85.6347%\n",
      "입양 확률 :  89.7685%\n",
      "입양 확률 :  30.2853%\n",
      "입양 확률 :  57.8625%\n",
      "입양 확률 :  33.0917%\n",
      "입양 확률 :  52.3523%\n",
      "입양 확률 :  90.5433%\n",
      "입양 확률 :  94.5191%\n",
      "입양 확률 :  36.3402%\n",
      "입양 확률 :  26.6885%\n",
      "입양 확률 :  58.0436%\n",
      "입양 확률 :  34.7650%\n",
      "입양 확률 :  37.8441%\n",
      "입양 확률 :  36.5673%\n",
      "입양 확률 :  52.7714%\n",
      "입양 확률 :  43.0492%\n",
      "입양 확률 :  90.9383%\n",
      "입양 확률 :  31.3785%\n",
      "입양 확률 :  92.8120%\n",
      "입양 확률 :  80.4843%\n",
      "입양 확률 :  56.6195%\n",
      "입양 확률 :  75.4732%\n",
      "입양 확률 :  73.3082%\n",
      "입양 확률 :  69.7706%\n",
      "입양 확률 :  46.3540%\n",
      "입양 확률 :  27.0691%\n",
      "입양 확률 :  54.5583%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  32.0362%\n",
      "입양 확률 :  54.5583%\n",
      "입양 확률 :  51.0287%\n",
      "입양 확률 :  56.4868%\n",
      "입양 확률 :  55.1727%\n",
      "입양 확률 :  27.1687%\n",
      "입양 확률 :  79.5345%\n",
      "입양 확률 :  78.0818%\n",
      "입양 확률 :  26.6011%\n",
      "입양 확률 :  27.5421%\n",
      "입양 확률 :  27.5421%\n",
      "입양 확률 :  26.6011%\n",
      "입양 확률 :  35.2598%\n",
      "입양 확률 :  28.5249%\n",
      "입양 확률 :  24.5133%\n",
      "입양 확률 :  82.6250%\n",
      "입양 확률 :  69.2903%\n",
      "입양 확률 :  26.1384%\n",
      "입양 확률 :  48.7082%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  32.1908%\n",
      "입양 확률 :  70.5507%\n",
      "입양 확률 :  35.4440%\n",
      "입양 확률 :  92.4061%\n",
      "입양 확률 :  31.9113%\n",
      "입양 확률 :  31.9113%\n",
      "입양 확률 :  31.9113%\n",
      "입양 확률 :  30.7316%\n",
      "입양 확률 :  40.7673%\n",
      "입양 확률 :  32.9232%\n",
      "입양 확률 :  29.0579%\n",
      "입양 확률 :  32.0362%\n",
      "입양 확률 :  35.4440%\n",
      "입양 확률 :  86.6981%\n",
      "입양 확률 :  78.8287%\n",
      "입양 확률 :  35.2400%\n",
      "입양 확률 :  23.0991%\n",
      "입양 확률 :  81.9916%\n",
      "입양 확률 :  39.6089%\n",
      "입양 확률 :  74.2966%\n",
      "입양 확률 :  35.8483%\n",
      "입양 확률 :  77.1089%\n",
      "입양 확률 :  38.0417%\n",
      "입양 확률 :  77.1674%\n",
      "입양 확률 :  75.7726%\n",
      "입양 확률 :  87.7377%\n",
      "입양 확률 :  80.3187%\n",
      "입양 확률 :  64.9833%\n",
      "입양 확률 :  59.9470%\n",
      "입양 확률 :  59.2415%\n",
      "입양 확률 :  83.3474%\n",
      "입양 확률 :  29.4303%\n",
      "입양 확률 :  90.9939%\n",
      "입양 확률 :  81.1342%\n",
      "입양 확률 :  61.0305%\n",
      "입양 확률 :  82.8998%\n",
      "입양 확률 :  76.6702%\n",
      "입양 확률 :  34.4896%\n",
      "입양 확률 :  43.6037%\n",
      "입양 확률 :  32.9014%\n",
      "입양 확률 :  23.4589%\n",
      "입양 확률 :  39.5481%\n",
      "입양 확률 :  49.2593%\n",
      "입양 확률 :  51.5592%\n",
      "입양 확률 :  51.5592%\n",
      "입양 확률 :  88.9153%\n",
      "입양 확률 :  90.1937%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    new_x=train_data[i, :].reshape(1,186)\n",
    "    print('입양 확률 : %8.4f%%' % (l2_model.predict(new_x)*100))\n",
    "l2_model.save('l2_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
