{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\auddu\\anaconda3\\envs\\auddus\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "# a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "# b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "\n",
    "# tensorflow, numpy 랜덤 값을 설정합니다.\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kindNum</th>\n",
       "      <th>neuterYn</th>\n",
       "      <th>sexCd</th>\n",
       "      <th>weight</th>\n",
       "      <th>noticeDays</th>\n",
       "      <th>age2</th>\n",
       "      <th>processState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.0</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>7.46</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114.0</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22787</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22788</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22789</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22790</th>\n",
       "      <td>128.0</td>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>6.00</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22791</th>\n",
       "      <td>114.0</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22777 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       kindNum neuterYn sexCd  weight  noticeDays  age2  processState\n",
       "0        128.0        N     F    7.46          10    12             0\n",
       "1        114.0        N     M    7.00          14     1             1\n",
       "2        114.0        U     M    4.50          11     2             0\n",
       "3         67.0        N     M   10.00           8     1             0\n",
       "4        114.0        N     M    6.00           8     4             0\n",
       "...        ...      ...   ...     ...         ...   ...           ...\n",
       "22787    114.0        N     M    1.00          10     0             1\n",
       "22788    114.0        N     M    1.00          10     0             1\n",
       "22789    114.0        N     M    1.00          10     0             1\n",
       "22790    128.0        U     F    6.00          12     3             0\n",
       "22791    114.0        N     M    3.50          10     0             0\n",
       "\n",
       "[22777 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doginfo.csv파일 데이터를 pandas를 이용해 읽어옵니다.\n",
    "dog_data=pd.read_csv(\"doginfo.csv\")\n",
    "dog_train=pd.read_csv(\"trainDoginfo.csv\")\n",
    "kindCd=pd.read_csv(\"kindCd.csv\")\n",
    "\n",
    "dog_data = dog_data.dropna(axis=0)\n",
    "dog_train = dog_train.dropna(axis=0)\n",
    "kindCd_data = kindCd.dropna(axis=0)\n",
    "\n",
    "dog_data\n",
    "# print(dog_train)\n",
    "# print(kindCd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54.  56.  55. 118. 115.  37.  81. 204.  83.  82.  38.  39.  40.  43.\n",
      "  42. 153.  41. 120. 155.  69.  71. 142.  93. 167.  70. 166.  94. 121.\n",
      " 152.  73. 146.  72. 159.  76.  75.  79.  78.  77.  74.  80. 114. 133.\n",
      "  12.  17.  15. 164. 157. 148.  16.  20.  21.  22.  24. 208.  23.  26.\n",
      "  27. 169.  25.  19.  13.  18.  14. 162.  85.  96.  95.   1.  34. 104.\n",
      "  31.  99. 122. 123.  97. 132. 105. 154. 124. 100. 103. 151. 139. 101.\n",
      " 102.  98. 136. 202. 160. 203.   8. 131.   9. 119. 150. 210.  57.  58.\n",
      "  59.   6.   4.   7.   5. 143.  11.  10. 137.  84. 163. 112. 113. 149.\n",
      " 211. 110. 205. 108. 109.  60.  46.  47.  44.  45.  53.  62.  61.  52.\n",
      " 165.  51. 156. 129.  67.  35.  33.  32. 158. 144.  30.  29.  64. 207.\n",
      "  28.   2.  68. 125. 141. 145.  36.  66.  65.  63. 140. 107. 106. 209.\n",
      "  86.  88.  90.  87. 138.  89. 126. 127. 128.  91.   3. 161.  50. 168.\n",
      "  49. 147.  92.  48. 135. 206. 130. 134. 111.]\n",
      "(177,)\n"
     ]
    }
   ],
   "source": [
    "kindCd = np.array(kindCd_data, dtype = np.float64)\n",
    "kindCd_train=np.array(kindCd_data, dtype=np.float64)\n",
    "\n",
    "kindCd = kindCd.reshape(177)\n",
    "kindCd_train=kindCd_train.reshape(177)\n",
    "print(kindCd)\n",
    "print(kindCd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuterYn</th>\n",
       "      <th>sexCd</th>\n",
       "      <th>weight</th>\n",
       "      <th>noticeDays</th>\n",
       "      <th>age2</th>\n",
       "      <th>processState</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>202.0</th>\n",
       "      <th>203.0</th>\n",
       "      <th>204.0</th>\n",
       "      <th>205.0</th>\n",
       "      <th>206.0</th>\n",
       "      <th>207.0</th>\n",
       "      <th>208.0</th>\n",
       "      <th>209.0</th>\n",
       "      <th>210.0</th>\n",
       "      <th>211.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>7.46</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>7.00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>4.50</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22787</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22788</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22789</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22790</th>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>6.00</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22791</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22777 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neuterYn sexCd  weight  noticeDays  age2  processState  1.0  2.0  3.0  \\\n",
       "0            N     F    7.46          10    12             0    0    0    0   \n",
       "1            N     M    7.00          14     1             1    0    0    0   \n",
       "2            U     M    4.50          11     2             0    0    0    0   \n",
       "3            N     M   10.00           8     1             0    0    0    0   \n",
       "4            N     M    6.00           8     4             0    0    0    0   \n",
       "...        ...   ...     ...         ...   ...           ...  ...  ...  ...   \n",
       "22787        N     M    1.00          10     0             1    0    0    0   \n",
       "22788        N     M    1.00          10     0             1    0    0    0   \n",
       "22789        N     M    1.00          10     0             1    0    0    0   \n",
       "22790        U     F    6.00          12     3             0    0    0    0   \n",
       "22791        N     M    3.50          10     0             0    0    0    0   \n",
       "\n",
       "       4.0  ...  202.0  203.0  204.0  205.0  206.0  207.0  208.0  209.0  \\\n",
       "0        0  ...      0      0      0      0      0      0      0      0   \n",
       "1        0  ...      0      0      0      0      0      0      0      0   \n",
       "2        0  ...      0      0      0      0      0      0      0      0   \n",
       "3        0  ...      0      0      0      0      0      0      0      0   \n",
       "4        0  ...      0      0      0      0      0      0      0      0   \n",
       "...    ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "22787    0  ...      0      0      0      0      0      0      0      0   \n",
       "22788    0  ...      0      0      0      0      0      0      0      0   \n",
       "22789    0  ...      0      0      0      0      0      0      0      0   \n",
       "22790    0  ...      0      0      0      0      0      0      0      0   \n",
       "22791    0  ...      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       210.0  211.0  \n",
       "0          0      0  \n",
       "1          0      0  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "...      ...    ...  \n",
       "22787      0      0  \n",
       "22788      0      0  \n",
       "22789      0      0  \n",
       "22790      0      0  \n",
       "22791      0      0  \n",
       "\n",
       "[22777 rows x 183 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kindNum을 원핫 인코딩\n",
    "kindCd = pd.concat((pd.get_dummies(dog_data.kindNum, columns=kindCd), pd.DataFrame(columns=kindCd))).fillna(0)\n",
    "# kindCd\n",
    "\n",
    "# 학습데이터에서 kindNum 열을 삭제한 후, 원핫 인코딩된 kindCd를 붙임\n",
    "dog_data.drop(['kindNum'], axis='columns', inplace=True)\n",
    "dog_data = pd.concat([dog_data, kindCd], axis=1)\n",
    "\n",
    "\n",
    "# kindNum을 원핫 인코딩\n",
    "kindCd_train = pd.concat((pd.get_dummies(dog_train.kindNum, columns=kindCd_train), pd.DataFrame(columns=kindCd_train))).fillna(0)\n",
    "\n",
    "# 테스트데이터에서 kindNum 열을 삭제한 후, 원핫 인코딩된 kindCd를 붙임\n",
    "dog_train.drop(['kindNum'], axis='columns', inplace=True)\n",
    "dog_train = pd.concat([dog_train, kindCd_train], axis=1)\n",
    "dog_data\n",
    "# dog_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix = column)], axis = 1)\n",
    "        data = data.drop(column, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       weight  noticeDays  age2  processState  1.0  2.0  3.0  4.0  5.0  6.0  \\\n",
      "0        7.46          10    12             0    0    0    0    0    0    0   \n",
      "1        7.00          14     1             1    0    0    0    0    0    0   \n",
      "2        4.50          11     2             0    0    0    0    0    0    0   \n",
      "3       10.00           8     1             0    0    0    0    0    0    0   \n",
      "4        6.00           8     4             0    0    0    0    0    0    0   \n",
      "...       ...         ...   ...           ...  ...  ...  ...  ...  ...  ...   \n",
      "22787    1.00          10     0             1    0    0    0    0    0    0   \n",
      "22788    1.00          10     0             1    0    0    0    0    0    0   \n",
      "22789    1.00          10     0             1    0    0    0    0    0    0   \n",
      "22790    6.00          12     3             0    0    0    0    0    0    0   \n",
      "22791    3.50          10     0             0    0    0    0    0    0    0   \n",
      "\n",
      "       ...  208.0  209.0  210.0  211.0  neuterYn_N  neuterYn_U  neuterYn_Y  \\\n",
      "0      ...      0      0      0      0           1           0           0   \n",
      "1      ...      0      0      0      0           1           0           0   \n",
      "2      ...      0      0      0      0           0           1           0   \n",
      "3      ...      0      0      0      0           1           0           0   \n",
      "4      ...      0      0      0      0           1           0           0   \n",
      "...    ...    ...    ...    ...    ...         ...         ...         ...   \n",
      "22787  ...      0      0      0      0           1           0           0   \n",
      "22788  ...      0      0      0      0           1           0           0   \n",
      "22789  ...      0      0      0      0           1           0           0   \n",
      "22790  ...      0      0      0      0           0           1           0   \n",
      "22791  ...      0      0      0      0           1           0           0   \n",
      "\n",
      "       sexCd_F  sexCd_M  sexCd_Q  \n",
      "0            1        0        0  \n",
      "1            0        1        0  \n",
      "2            0        1        0  \n",
      "3            0        1        0  \n",
      "4            0        1        0  \n",
      "...        ...      ...      ...  \n",
      "22787        0        1        0  \n",
      "22788        0        1        0  \n",
      "22789        0        1        0  \n",
      "22790        1        0        0  \n",
      "22791        0        1        0  \n",
      "\n",
      "[22777 rows x 187 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy_columns = [\"neuterYn\", \"sexCd\"]\n",
    "data = dummy_data(dog_data, dummy_columns)\n",
    "train_data = dummy_data(dog_train, dummy_columns)\n",
    "data.head()\n",
    "train_data.head()\n",
    "# print(type(dog_data))\n",
    "# print(type(data))\n",
    "\n",
    "print(data)\n",
    "\n",
    "data = np.array(data, dtype = np.float64)\n",
    "train_data = np.array(train_data, dtype = np.float64)\n",
    "\n",
    "# data\n",
    "# print(data.shape)\n",
    "# print(len(train_data))\n",
    "# print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.46 10.   12.   ...  1.    0.    0.  ]\n",
      " [ 7.   14.    1.   ...  0.    1.    0.  ]\n",
      " [ 4.5  11.    2.   ...  0.    1.    0.  ]\n",
      " ...\n",
      " [ 1.   10.    0.   ...  0.    1.    0.  ]\n",
      " [ 6.   12.    3.   ...  1.    0.    0.  ]\n",
      " [ 3.5  10.    0.   ...  0.    1.    0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22777, 186)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data[:, :3]\n",
    "b = data[:, 4:]\n",
    "\n",
    "# print(a[0,:])\n",
    "# print(b)\n",
    "\n",
    "#numpy 배열에서 데이터 변화요인(kindCd, neuterYn, sexCd, weight, noticeDays, age2)으로 사용할 데이터를 뽑아냅니다.\n",
    "xData = np.concatenate([a, b], axis = 1)\n",
    "\n",
    "print(xData)\n",
    "type(xData)\n",
    "xData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy배열에서 결과(입양여부)로 사용할 데이터를 뽑아냅니다.\n",
    "yData=data[:,[3]]\n",
    "# yData = yData.astype('int32')\n",
    "print(yData)\n",
    "type(yData)\n",
    "yData.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Dense(1, input_dim=186, activation='sigmoid'))\n",
    "# sgd=optimizers.SGD(lr=0.01)\n",
    "# model.compile(optimizer=sgd ,loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
    "# # 옵티마이저는 경사하강법 sgd를 사용합니다.\n",
    "# # 손실 함수(Loss function)는 binary_crossentropy(이진 크로스 엔트로피)를 사용합니다.\n",
    "# model.fit(xData,yData, batch_size=128, epochs=200, shuffle=False)\n",
    "# # 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22777 samples, validate on 22777 samples\n",
      "Epoch 1/100\n",
      "22777/22777 [==============================] - 2s 99us/sample - loss: 0.7177 - acc: 0.5887 - binary_crossentropy: 0.6724 - val_loss: 0.7057 - val_acc: 0.6189 - val_binary_crossentropy: 0.6606\n",
      "Epoch 2/100\n",
      "22777/22777 [==============================] - 3s 126us/sample - loss: 0.7020 - acc: 0.6205 - binary_crossentropy: 0.6571 - val_loss: 0.6967 - val_acc: 0.6298 - val_binary_crossentropy: 0.6521\n",
      "Epoch 3/100\n",
      "22777/22777 [==============================] - 1s 57us/sample - loss: 0.6931 - acc: 0.6307 - binary_crossentropy: 0.6486 - val_loss: 0.6864 - val_acc: 0.6425 - val_binary_crossentropy: 0.6421\n",
      "Epoch 4/100\n",
      "22777/22777 [==============================] - 2s 84us/sample - loss: 0.6826 - acc: 0.6433 - binary_crossentropy: 0.6385 - val_loss: 0.6743 - val_acc: 0.6551 - val_binary_crossentropy: 0.6304\n",
      "Epoch 5/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6729 - acc: 0.6494 - binary_crossentropy: 0.6291 - val_loss: 0.6739 - val_acc: 0.6447 - val_binary_crossentropy: 0.6302\n",
      "Epoch 6/100\n",
      "22777/22777 [==============================] - 3s 120us/sample - loss: 0.6660 - acc: 0.6549 - binary_crossentropy: 0.6225 - val_loss: 0.6683 - val_acc: 0.6517 - val_binary_crossentropy: 0.6250\n",
      "Epoch 7/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6613 - acc: 0.6594 - binary_crossentropy: 0.6182 - val_loss: 0.6556 - val_acc: 0.6633 - val_binary_crossentropy: 0.6127\n",
      "Epoch 8/100\n",
      "22777/22777 [==============================] - 2s 77us/sample - loss: 0.6600 - acc: 0.6608 - binary_crossentropy: 0.6173 - val_loss: 0.6933 - val_acc: 0.6373 - val_binary_crossentropy: 0.6509\n",
      "Epoch 9/100\n",
      "22777/22777 [==============================] - 2s 89us/sample - loss: 0.6575 - acc: 0.6622 - binary_crossentropy: 0.6153 - val_loss: 0.6536 - val_acc: 0.6626 - val_binary_crossentropy: 0.6117\n",
      "Epoch 10/100\n",
      "22777/22777 [==============================] - 3s 115us/sample - loss: 0.6559 - acc: 0.6612 - binary_crossentropy: 0.6142 - val_loss: 0.6538 - val_acc: 0.6601 - val_binary_crossentropy: 0.6124\n",
      "Epoch 11/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6523 - acc: 0.6668 - binary_crossentropy: 0.6112 - val_loss: 0.6680 - val_acc: 0.6503 - val_binary_crossentropy: 0.6270\n",
      "Epoch 12/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6517 - acc: 0.6676 - binary_crossentropy: 0.6111 - val_loss: 0.6500 - val_acc: 0.6667 - val_binary_crossentropy: 0.6095\n",
      "Epoch 13/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6497 - acc: 0.6665 - binary_crossentropy: 0.6095 - val_loss: 0.6491 - val_acc: 0.6702 - val_binary_crossentropy: 0.6091\n",
      "Epoch 14/100\n",
      "22777/22777 [==============================] - 3s 122us/sample - loss: 0.6481 - acc: 0.6697 - binary_crossentropy: 0.6084 - val_loss: 0.6442 - val_acc: 0.6694 - val_binary_crossentropy: 0.6047\n",
      "Epoch 15/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6479 - acc: 0.6703 - binary_crossentropy: 0.6086 - val_loss: 0.6417 - val_acc: 0.6752 - val_binary_crossentropy: 0.6027\n",
      "Epoch 16/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6451 - acc: 0.6727 - binary_crossentropy: 0.6063 - val_loss: 0.6412 - val_acc: 0.6765 - val_binary_crossentropy: 0.6026\n",
      "Epoch 17/100\n",
      "22777/22777 [==============================] - 2s 103us/sample - loss: 0.6448 - acc: 0.6708 - binary_crossentropy: 0.6064 - val_loss: 0.6404 - val_acc: 0.6741 - val_binary_crossentropy: 0.6023\n",
      "Epoch 18/100\n",
      "22777/22777 [==============================] - 3s 111us/sample - loss: 0.6450 - acc: 0.6706 - binary_crossentropy: 0.6071 - val_loss: 0.6394 - val_acc: 0.6773 - val_binary_crossentropy: 0.6017\n",
      "Epoch 19/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6435 - acc: 0.6715 - binary_crossentropy: 0.6061 - val_loss: 0.6400 - val_acc: 0.6740 - val_binary_crossentropy: 0.6028\n",
      "Epoch 20/100\n",
      "22777/22777 [==============================] - 2s 83us/sample - loss: 0.6422 - acc: 0.6742 - binary_crossentropy: 0.6052 - val_loss: 0.6408 - val_acc: 0.6748 - val_binary_crossentropy: 0.6040\n",
      "Epoch 21/100\n",
      "22777/22777 [==============================] - 2s 107us/sample - loss: 0.6411 - acc: 0.6725 - binary_crossentropy: 0.6046 - val_loss: 0.6379 - val_acc: 0.6765 - val_binary_crossentropy: 0.6016\n",
      "Epoch 22/100\n",
      "22777/22777 [==============================] - 2s 101us/sample - loss: 0.6411 - acc: 0.6736 - binary_crossentropy: 0.6050 - val_loss: 0.6379 - val_acc: 0.6747 - val_binary_crossentropy: 0.6019\n",
      "Epoch 23/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6397 - acc: 0.6729 - binary_crossentropy: 0.6040 - val_loss: 0.6367 - val_acc: 0.6763 - val_binary_crossentropy: 0.6012\n",
      "Epoch 24/100\n",
      "22777/22777 [==============================] - 2s 77us/sample - loss: 0.6389 - acc: 0.6739 - binary_crossentropy: 0.6036 - val_loss: 0.6362 - val_acc: 0.6746 - val_binary_crossentropy: 0.6012\n",
      "Epoch 25/100\n",
      "22777/22777 [==============================] - 2s 101us/sample - loss: 0.6384 - acc: 0.6751 - binary_crossentropy: 0.6036 - val_loss: 0.6355 - val_acc: 0.6761 - val_binary_crossentropy: 0.6008\n",
      "Epoch 26/100\n",
      "22777/22777 [==============================] - 2s 92us/sample - loss: 0.6376 - acc: 0.6734 - binary_crossentropy: 0.6031 - val_loss: 0.6332 - val_acc: 0.6791 - val_binary_crossentropy: 0.5989\n",
      "Epoch 27/100\n",
      "22777/22777 [==============================] - 2s 68us/sample - loss: 0.6369 - acc: 0.6758 - binary_crossentropy: 0.6028 - val_loss: 0.6345 - val_acc: 0.6759 - val_binary_crossentropy: 0.6007\n",
      "Epoch 28/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6363 - acc: 0.6727 - binary_crossentropy: 0.6026 - val_loss: 0.6349 - val_acc: 0.6784 - val_binary_crossentropy: 0.6014\n",
      "Epoch 29/100\n",
      "22777/22777 [==============================] - 2s 103us/sample - loss: 0.6351 - acc: 0.6780 - binary_crossentropy: 0.6018 - val_loss: 0.6396 - val_acc: 0.6736 - val_binary_crossentropy: 0.6065\n",
      "Epoch 30/100\n",
      "22777/22777 [==============================] - 2s 106us/sample - loss: 0.6343 - acc: 0.6778 - binary_crossentropy: 0.6014 - val_loss: 0.6303 - val_acc: 0.6815 - val_binary_crossentropy: 0.5975\n",
      "Epoch 31/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6337 - acc: 0.6778 - binary_crossentropy: 0.6011 - val_loss: 0.6319 - val_acc: 0.6817 - val_binary_crossentropy: 0.5995\n",
      "Epoch 32/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6341 - acc: 0.6745 - binary_crossentropy: 0.6020 - val_loss: 0.6318 - val_acc: 0.6788 - val_binary_crossentropy: 0.5999\n",
      "Epoch 33/100\n",
      "22777/22777 [==============================] - 3s 112us/sample - loss: 0.6319 - acc: 0.6766 - binary_crossentropy: 0.6000 - val_loss: 0.6320 - val_acc: 0.6771 - val_binary_crossentropy: 0.6004\n",
      "Epoch 34/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6330 - acc: 0.6770 - binary_crossentropy: 0.6015 - val_loss: 0.6303 - val_acc: 0.6790 - val_binary_crossentropy: 0.5990\n",
      "Epoch 35/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6316 - acc: 0.6781 - binary_crossentropy: 0.6005 - val_loss: 0.6278 - val_acc: 0.6803 - val_binary_crossentropy: 0.5969\n",
      "Epoch 36/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6312 - acc: 0.6763 - binary_crossentropy: 0.6004 - val_loss: 0.6323 - val_acc: 0.6763 - val_binary_crossentropy: 0.6018\n",
      "Epoch 37/100\n",
      "22777/22777 [==============================] - 2s 107us/sample - loss: 0.6303 - acc: 0.6761 - binary_crossentropy: 0.5999 - val_loss: 0.6344 - val_acc: 0.6733 - val_binary_crossentropy: 0.6042\n",
      "Epoch 38/100\n",
      "22777/22777 [==============================] - 2s 99us/sample - loss: 0.6293 - acc: 0.6802 - binary_crossentropy: 0.5993 - val_loss: 0.6266 - val_acc: 0.6786 - val_binary_crossentropy: 0.5968\n",
      "Epoch 39/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6293 - acc: 0.6759 - binary_crossentropy: 0.5996 - val_loss: 0.6254 - val_acc: 0.6828 - val_binary_crossentropy: 0.5959\n",
      "Epoch 40/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6293 - acc: 0.6771 - binary_crossentropy: 0.5999 - val_loss: 0.6340 - val_acc: 0.6745 - val_binary_crossentropy: 0.6048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "22777/22777 [==============================] - 2s 108us/sample - loss: 0.6275 - acc: 0.6795 - binary_crossentropy: 0.5984 - val_loss: 0.6241 - val_acc: 0.6813 - val_binary_crossentropy: 0.5952\n",
      "Epoch 42/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6271 - acc: 0.6773 - binary_crossentropy: 0.5984 - val_loss: 0.6249 - val_acc: 0.6825 - val_binary_crossentropy: 0.5964\n",
      "Epoch 43/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6268 - acc: 0.6812 - binary_crossentropy: 0.5984 - val_loss: 0.6238 - val_acc: 0.6805 - val_binary_crossentropy: 0.5956\n",
      "Epoch 44/100\n",
      "22777/22777 [==============================] - 2s 75us/sample - loss: 0.6270 - acc: 0.6786 - binary_crossentropy: 0.5989 - val_loss: 0.6286 - val_acc: 0.6741 - val_binary_crossentropy: 0.6007\n",
      "Epoch 45/100\n",
      "22777/22777 [==============================] - 2s 101us/sample - loss: 0.6260 - acc: 0.6797 - binary_crossentropy: 0.5982 - val_loss: 0.6439 - val_acc: 0.6665 - val_binary_crossentropy: 0.6163\n",
      "Epoch 46/100\n",
      "22777/22777 [==============================] - 2s 97us/sample - loss: 0.6254 - acc: 0.6789 - binary_crossentropy: 0.5979 - val_loss: 0.6365 - val_acc: 0.6719 - val_binary_crossentropy: 0.6092\n",
      "Epoch 47/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6246 - acc: 0.6798 - binary_crossentropy: 0.5974 - val_loss: 0.6387 - val_acc: 0.6640 - val_binary_crossentropy: 0.6118\n",
      "Epoch 48/100\n",
      "22777/22777 [==============================] - 2s 68us/sample - loss: 0.6247 - acc: 0.6790 - binary_crossentropy: 0.5979 - val_loss: 0.6253 - val_acc: 0.6751 - val_binary_crossentropy: 0.5986\n",
      "Epoch 49/100\n",
      "22777/22777 [==============================] - 2s 105us/sample - loss: 0.6244 - acc: 0.6793 - binary_crossentropy: 0.5979 - val_loss: 0.6239 - val_acc: 0.6792 - val_binary_crossentropy: 0.5975\n",
      "Epoch 50/100\n",
      "22777/22777 [==============================] - 2s 97us/sample - loss: 0.6240 - acc: 0.6800 - binary_crossentropy: 0.5978 - val_loss: 0.6203 - val_acc: 0.6831 - val_binary_crossentropy: 0.5942\n",
      "Epoch 51/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6250 - acc: 0.6791 - binary_crossentropy: 0.5990 - val_loss: 0.6240 - val_acc: 0.6756 - val_binary_crossentropy: 0.5982\n",
      "Epoch 52/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6231 - acc: 0.6799 - binary_crossentropy: 0.5974 - val_loss: 0.6234 - val_acc: 0.6769 - val_binary_crossentropy: 0.5978\n",
      "Epoch 53/100\n",
      "22777/22777 [==============================] - 2s 107us/sample - loss: 0.6234 - acc: 0.6782 - binary_crossentropy: 0.5980 - val_loss: 0.6196 - val_acc: 0.6817 - val_binary_crossentropy: 0.5944\n",
      "Epoch 54/100\n",
      "22777/22777 [==============================] - 2s 98us/sample - loss: 0.6229 - acc: 0.6796 - binary_crossentropy: 0.5978 - val_loss: 0.6201 - val_acc: 0.6828 - val_binary_crossentropy: 0.5952\n",
      "Epoch 55/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6217 - acc: 0.6799 - binary_crossentropy: 0.5969 - val_loss: 0.6291 - val_acc: 0.6751 - val_binary_crossentropy: 0.6044\n",
      "Epoch 56/100\n",
      "22777/22777 [==============================] - 2s 77us/sample - loss: 0.6219 - acc: 0.6781 - binary_crossentropy: 0.5973 - val_loss: 0.6218 - val_acc: 0.6812 - val_binary_crossentropy: 0.5974\n",
      "Epoch 57/100\n",
      "22777/22777 [==============================] - 2s 104us/sample - loss: 0.6219 - acc: 0.6792 - binary_crossentropy: 0.5976 - val_loss: 0.6197 - val_acc: 0.6815 - val_binary_crossentropy: 0.5955\n",
      "Epoch 58/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6212 - acc: 0.6820 - binary_crossentropy: 0.5972 - val_loss: 0.6177 - val_acc: 0.6816 - val_binary_crossentropy: 0.5938\n",
      "Epoch 59/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6208 - acc: 0.6820 - binary_crossentropy: 0.5970 - val_loss: 0.6185 - val_acc: 0.6818 - val_binary_crossentropy: 0.5948\n",
      "Epoch 60/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6203 - acc: 0.6799 - binary_crossentropy: 0.5968 - val_loss: 0.6170 - val_acc: 0.6836 - val_binary_crossentropy: 0.5936\n",
      "Epoch 61/100\n",
      "22777/22777 [==============================] - 2s 106us/sample - loss: 0.6210 - acc: 0.6778 - binary_crossentropy: 0.5977 - val_loss: 0.6163 - val_acc: 0.6837 - val_binary_crossentropy: 0.5931\n",
      "Epoch 62/100\n",
      "22777/22777 [==============================] - 2s 106us/sample - loss: 0.6206 - acc: 0.6811 - binary_crossentropy: 0.5975 - val_loss: 0.6177 - val_acc: 0.6808 - val_binary_crossentropy: 0.5947\n",
      "Epoch 63/100\n",
      "22777/22777 [==============================] - 2s 76us/sample - loss: 0.6198 - acc: 0.6800 - binary_crossentropy: 0.5970 - val_loss: 0.6171 - val_acc: 0.6821 - val_binary_crossentropy: 0.5945\n",
      "Epoch 64/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6195 - acc: 0.6816 - binary_crossentropy: 0.5969 - val_loss: 0.6171 - val_acc: 0.6814 - val_binary_crossentropy: 0.5946\n",
      "Epoch 65/100\n",
      "22777/22777 [==============================] - 2s 109us/sample - loss: 0.6195 - acc: 0.6784 - binary_crossentropy: 0.5972 - val_loss: 0.6171 - val_acc: 0.6803 - val_binary_crossentropy: 0.5949\n",
      "Epoch 66/100\n",
      "22777/22777 [==============================] - 2s 97us/sample - loss: 0.6188 - acc: 0.6800 - binary_crossentropy: 0.5967 - val_loss: 0.6164 - val_acc: 0.6823 - val_binary_crossentropy: 0.5944\n",
      "Epoch 67/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6189 - acc: 0.6784 - binary_crossentropy: 0.5971 - val_loss: 0.6174 - val_acc: 0.6833 - val_binary_crossentropy: 0.5957\n",
      "Epoch 68/100\n",
      "22777/22777 [==============================] - 2s 85us/sample - loss: 0.6186 - acc: 0.6776 - binary_crossentropy: 0.5970 - val_loss: 0.6146 - val_acc: 0.6842 - val_binary_crossentropy: 0.5931\n",
      "Epoch 69/100\n",
      "22777/22777 [==============================] - 3s 131us/sample - loss: 0.6181 - acc: 0.6797 - binary_crossentropy: 0.5967 - val_loss: 0.6167 - val_acc: 0.6805 - val_binary_crossentropy: 0.5954\n",
      "Epoch 70/100\n",
      "22777/22777 [==============================] - 2s 102us/sample - loss: 0.6185 - acc: 0.6801 - binary_crossentropy: 0.5973 - val_loss: 0.6155 - val_acc: 0.6844 - val_binary_crossentropy: 0.5944\n",
      "Epoch 71/100\n",
      "22777/22777 [==============================] - 2s 85us/sample - loss: 0.6184 - acc: 0.6816 - binary_crossentropy: 0.5974 - val_loss: 0.6157 - val_acc: 0.6826 - val_binary_crossentropy: 0.5949\n",
      "Epoch 72/100\n",
      "22777/22777 [==============================] - 2s 93us/sample - loss: 0.6171 - acc: 0.6798 - binary_crossentropy: 0.5964 - val_loss: 0.6148 - val_acc: 0.6825 - val_binary_crossentropy: 0.5942\n",
      "Epoch 73/100\n",
      "22777/22777 [==============================] - 2s 109us/sample - loss: 0.6176 - acc: 0.6806 - binary_crossentropy: 0.5970 - val_loss: 0.6135 - val_acc: 0.6827 - val_binary_crossentropy: 0.5930\n",
      "Epoch 74/100\n",
      "22777/22777 [==============================] - 1s 64us/sample - loss: 0.6168 - acc: 0.6795 - binary_crossentropy: 0.5965 - val_loss: 0.6173 - val_acc: 0.6822 - val_binary_crossentropy: 0.5971\n",
      "Epoch 75/100\n",
      "22777/22777 [==============================] - 2s 77us/sample - loss: 0.6160 - acc: 0.6806 - binary_crossentropy: 0.5959 - val_loss: 0.6127 - val_acc: 0.6836 - val_binary_crossentropy: 0.5927\n",
      "Epoch 76/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6161 - acc: 0.6791 - binary_crossentropy: 0.5961 - val_loss: 0.6151 - val_acc: 0.6805 - val_binary_crossentropy: 0.5952\n",
      "Epoch 77/100\n",
      "22777/22777 [==============================] - 3s 127us/sample - loss: 0.6168 - acc: 0.6811 - binary_crossentropy: 0.5971 - val_loss: 0.6171 - val_acc: 0.6820 - val_binary_crossentropy: 0.5975\n",
      "Epoch 78/100\n",
      "22777/22777 [==============================] - 2s 83us/sample - loss: 0.6162 - acc: 0.6803 - binary_crossentropy: 0.5967 - val_loss: 0.6121 - val_acc: 0.6838 - val_binary_crossentropy: 0.5927\n",
      "Epoch 79/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6148 - acc: 0.6810 - binary_crossentropy: 0.5954 - val_loss: 0.6237 - val_acc: 0.6761 - val_binary_crossentropy: 0.6044\n",
      "Epoch 80/100\n",
      "22777/22777 [==============================] - 2s 80us/sample - loss: 0.6156 - acc: 0.6774 - binary_crossentropy: 0.5964 - val_loss: 0.6344 - val_acc: 0.6633 - val_binary_crossentropy: 0.6153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "22777/22777 [==============================] - 2s 109us/sample - loss: 0.6149 - acc: 0.6816 - binary_crossentropy: 0.5959 - val_loss: 0.6259 - val_acc: 0.6732 - val_binary_crossentropy: 0.6070\n",
      "Epoch 82/100\n",
      "22777/22777 [==============================] - 1s 63us/sample - loss: 0.6146 - acc: 0.6810 - binary_crossentropy: 0.5959 - val_loss: 0.6554 - val_acc: 0.6484 - val_binary_crossentropy: 0.6367\n",
      "Epoch 83/100\n",
      "22777/22777 [==============================] - 2s 78us/sample - loss: 0.6150 - acc: 0.6807 - binary_crossentropy: 0.5964 - val_loss: 0.6127 - val_acc: 0.6812 - val_binary_crossentropy: 0.5942\n",
      "Epoch 84/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6150 - acc: 0.6795 - binary_crossentropy: 0.5966 - val_loss: 0.6446 - val_acc: 0.6531 - val_binary_crossentropy: 0.6263\n",
      "Epoch 85/100\n",
      "22777/22777 [==============================] - 3s 121us/sample - loss: 0.6141 - acc: 0.6811 - binary_crossentropy: 0.5959 - val_loss: 0.6119 - val_acc: 0.6838 - val_binary_crossentropy: 0.5937\n",
      "Epoch 86/100\n",
      "22777/22777 [==============================] - 2s 86us/sample - loss: 0.6139 - acc: 0.6811 - binary_crossentropy: 0.5958 - val_loss: 0.6125 - val_acc: 0.6829 - val_binary_crossentropy: 0.5945\n",
      "Epoch 87/100\n",
      "22777/22777 [==============================] - 2s 85us/sample - loss: 0.6143 - acc: 0.6807 - binary_crossentropy: 0.5964 - val_loss: 0.6119 - val_acc: 0.6850 - val_binary_crossentropy: 0.5941\n",
      "Epoch 88/100\n",
      "22777/22777 [==============================] - 2s 93us/sample - loss: 0.6135 - acc: 0.6817 - binary_crossentropy: 0.5958 - val_loss: 0.6151 - val_acc: 0.6819 - val_binary_crossentropy: 0.5975\n",
      "Epoch 89/100\n",
      "22777/22777 [==============================] - 2s 107us/sample - loss: 0.6139 - acc: 0.6797 - binary_crossentropy: 0.5963 - val_loss: 0.6100 - val_acc: 0.6846 - val_binary_crossentropy: 0.5926\n",
      "Epoch 90/100\n",
      "22777/22777 [==============================] - 1s 65us/sample - loss: 0.6132 - acc: 0.6810 - binary_crossentropy: 0.5958 - val_loss: 0.6165 - val_acc: 0.6805 - val_binary_crossentropy: 0.5992\n",
      "Epoch 91/100\n",
      "22777/22777 [==============================] - 2s 81us/sample - loss: 0.6131 - acc: 0.6826 - binary_crossentropy: 0.5959 - val_loss: 0.6113 - val_acc: 0.6810 - val_binary_crossentropy: 0.5942\n",
      "Epoch 92/100\n",
      "22777/22777 [==============================] - 2s 96us/sample - loss: 0.6136 - acc: 0.6805 - binary_crossentropy: 0.5966 - val_loss: 0.6174 - val_acc: 0.6796 - val_binary_crossentropy: 0.6004\n",
      "Epoch 93/100\n",
      "22777/22777 [==============================] - 3s 125us/sample - loss: 0.6131 - acc: 0.6814 - binary_crossentropy: 0.5962 - val_loss: 0.6271 - val_acc: 0.6693 - val_binary_crossentropy: 0.6103\n",
      "Epoch 94/100\n",
      "22777/22777 [==============================] - 2s 79us/sample - loss: 0.6125 - acc: 0.6812 - binary_crossentropy: 0.5958 - val_loss: 0.6104 - val_acc: 0.6842 - val_binary_crossentropy: 0.5937\n",
      "Epoch 95/100\n",
      "22777/22777 [==============================] - 2s 72us/sample - loss: 0.6118 - acc: 0.6817 - binary_crossentropy: 0.5952 - val_loss: 0.6127 - val_acc: 0.6778 - val_binary_crossentropy: 0.5961\n",
      "Epoch 96/100\n",
      "22777/22777 [==============================] - 2s 71us/sample - loss: 0.6129 - acc: 0.6799 - binary_crossentropy: 0.5965 - val_loss: 0.6096 - val_acc: 0.6837 - val_binary_crossentropy: 0.5932\n",
      "Epoch 97/100\n",
      "22777/22777 [==============================] - 2s 102us/sample - loss: 0.6126 - acc: 0.6813 - binary_crossentropy: 0.5963 - val_loss: 0.6108 - val_acc: 0.6814 - val_binary_crossentropy: 0.5945\n",
      "Epoch 98/100\n",
      "22777/22777 [==============================] - 2s 82us/sample - loss: 0.6119 - acc: 0.6804 - binary_crossentropy: 0.5957 - val_loss: 0.6087 - val_acc: 0.6837 - val_binary_crossentropy: 0.5926\n",
      "Epoch 99/100\n",
      "22777/22777 [==============================] - 2s 74us/sample - loss: 0.6125 - acc: 0.6813 - binary_crossentropy: 0.5965 - val_loss: 0.6096 - val_acc: 0.6824 - val_binary_crossentropy: 0.5936\n",
      "Epoch 100/100\n",
      "22777/22777 [==============================] - 2s 73us/sample - loss: 0.6126 - acc: 0.6817 - binary_crossentropy: 0.5967 - val_loss: 0.6133 - val_acc: 0.6791 - val_binary_crossentropy: 0.5975\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                2992      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,281\n",
      "Trainable params: 3,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l2_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.relu, input_shape=(186,)),\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "\n",
    "l2_model.compile(optimizer='sgd',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "l2_model_history = l2_model.fit(xData, yData,\n",
    "                                epochs=100,\n",
    "                                batch_size=64,\n",
    "                                validation_data=(xData, yData),\n",
    "                                verbose=1)\n",
    "\n",
    "l2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입양 확률 :  94.2203%\n",
      "입양 확률 :  36.7390%\n",
      "입양 확률 :  35.8996%\n",
      "입양 확률 :  78.0932%\n",
      "입양 확률 :  21.0893%\n",
      "입양 확률 :  21.0893%\n",
      "입양 확률 :  91.3862%\n",
      "입양 확률 :  78.4416%\n",
      "입양 확률 :  89.5666%\n",
      "입양 확률 :  84.8468%\n",
      "입양 확률 :  72.6395%\n",
      "입양 확률 :  85.3167%\n",
      "입양 확률 :  55.5937%\n",
      "입양 확률 :  49.5257%\n",
      "입양 확률 :  51.3644%\n",
      "입양 확률 :  28.9706%\n",
      "입양 확률 :  44.0449%\n",
      "입양 확률 :  37.9210%\n",
      "입양 확률 :  83.8701%\n",
      "입양 확률 :  23.1563%\n",
      "입양 확률 :  64.8517%\n",
      "입양 확률 :  64.8517%\n",
      "입양 확률 :  53.8228%\n",
      "입양 확률 :  46.9142%\n",
      "입양 확률 :  71.4867%\n",
      "입양 확률 :  58.0059%\n",
      "입양 확률 :  54.1604%\n",
      "입양 확률 :  57.8769%\n",
      "입양 확률 :  41.1052%\n",
      "입양 확률 :  54.8027%\n",
      "입양 확률 :  56.1087%\n",
      "입양 확률 :  41.1052%\n",
      "입양 확률 :  40.0840%\n",
      "입양 확률 :  37.2096%\n",
      "입양 확률 :  90.8167%\n",
      "입양 확률 :  88.6520%\n",
      "입양 확률 :  19.2490%\n",
      "입양 확률 :  69.2019%\n",
      "입양 확률 :  76.6373%\n",
      "입양 확률 :  28.4616%\n",
      "입양 확률 :  26.2082%\n",
      "입양 확률 :  37.8162%\n",
      "입양 확률 :  49.3927%\n",
      "입양 확률 :  31.0500%\n",
      "입양 확률 :  32.5425%\n",
      "입양 확률 :  45.5628%\n",
      "입양 확률 :  49.3927%\n",
      "입양 확률 :  51.3507%\n",
      "입양 확률 :  36.3324%\n",
      "입양 확률 :  45.9654%\n",
      "입양 확률 :  29.5362%\n",
      "입양 확률 :  29.1457%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  52.2923%\n",
      "입양 확률 :  54.0260%\n",
      "입양 확률 :  51.3507%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  32.1351%\n",
      "입양 확률 :  67.2334%\n",
      "입양 확률 :  56.3661%\n",
      "입양 확률 :  57.1026%\n",
      "입양 확률 :  55.8354%\n",
      "입양 확률 :  37.6229%\n",
      "입양 확률 :  93.1751%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  78.7943%\n",
      "입양 확률 :  18.4336%\n",
      "입양 확률 :  80.2123%\n",
      "입양 확률 :  72.8484%\n",
      "입양 확률 :  51.0164%\n",
      "입양 확률 :  53.1521%\n",
      "입양 확률 :  77.7039%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  37.9588%\n",
      "입양 확률 :  42.8758%\n",
      "입양 확률 :  51.4375%\n",
      "입양 확률 :  34.8071%\n",
      "입양 확률 :  90.5109%\n",
      "입양 확률 :  23.0991%\n",
      "입양 확률 :  74.9863%\n",
      "입양 확률 :  48.8126%\n",
      "입양 확률 :  52.8710%\n",
      "입양 확률 :  48.1297%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  53.9207%\n",
      "입양 확률 :  48.7735%\n",
      "입양 확률 :  23.6678%\n",
      "입양 확률 :  75.7269%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  57.5152%\n",
      "입양 확률 :  50.9764%\n",
      "입양 확률 :  90.9335%\n",
      "입양 확률 :  34.4362%\n",
      "입양 확률 :  80.4421%\n",
      "입양 확률 :  86.2377%\n",
      "입양 확률 :  24.7418%\n",
      "입양 확률 :  62.9177%\n",
      "입양 확률 :  85.2348%\n",
      "입양 확률 :  28.6270%\n",
      "입양 확률 :  84.8854%\n",
      "입양 확률 :  65.3681%\n",
      "입양 확률 :  29.6700%\n",
      "입양 확률 :  42.5086%\n",
      "입양 확률 :  71.8598%\n",
      "입양 확률 :  37.7539%\n",
      "입양 확률 :  32.4765%\n",
      "입양 확률 :  38.1661%\n",
      "입양 확률 :  86.8071%\n",
      "입양 확률 :  79.7014%\n",
      "입양 확률 :  22.1511%\n",
      "입양 확률 :  22.1511%\n",
      "입양 확률 :  81.6765%\n",
      "입양 확률 :  26.6789%\n",
      "입양 확률 :  65.5374%\n",
      "입양 확률 :  48.4780%\n",
      "입양 확률 :  63.2604%\n",
      "입양 확률 :  89.2275%\n",
      "입양 확률 :  30.8939%\n",
      "입양 확률 :  37.8441%\n",
      "입양 확률 :  38.0527%\n",
      "입양 확률 :  29.3965%\n",
      "입양 확률 :  76.1217%\n",
      "입양 확률 :  83.7344%\n",
      "입양 확률 :  82.3084%\n",
      "입양 확률 :  35.1551%\n",
      "입양 확률 :  80.5109%\n",
      "입양 확률 :  94.7565%\n",
      "입양 확률 :  78.0636%\n",
      "입양 확률 :  59.0956%\n",
      "입양 확률 :  61.4141%\n",
      "입양 확률 :  25.9249%\n",
      "입양 확률 :  94.6280%\n",
      "입양 확률 :  94.1429%\n",
      "입양 확률 :  59.0332%\n",
      "입양 확률 :  90.5268%\n",
      "입양 확률 :  89.4795%\n",
      "입양 확률 :  90.4354%\n",
      "입양 확률 :  28.0512%\n",
      "입양 확률 :  36.5923%\n",
      "입양 확률 :  31.5406%\n",
      "입양 확률 :  35.0414%\n",
      "입양 확률 :  29.4471%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  86.8184%\n",
      "입양 확률 :  44.3399%\n",
      "입양 확률 :  70.0254%\n",
      "입양 확률 :  89.8535%\n",
      "입양 확률 :  43.6976%\n",
      "입양 확률 :  49.5257%\n",
      "입양 확률 :  24.8949%\n",
      "입양 확률 :  31.8996%\n",
      "입양 확률 :  28.3564%\n",
      "입양 확률 :  69.9115%\n",
      "입양 확률 :  87.0251%\n",
      "입양 확률 :  36.3324%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  66.9685%\n",
      "입양 확률 :  78.0211%\n",
      "입양 확률 :  39.7200%\n",
      "입양 확률 :  29.8014%\n",
      "입양 확률 :  87.8142%\n",
      "입양 확률 :  55.7829%\n",
      "입양 확률 :  92.1527%\n",
      "입양 확률 :  82.1423%\n",
      "입양 확률 :  49.8603%\n",
      "입양 확률 :  91.5583%\n",
      "입양 확률 :  73.2581%\n",
      "입양 확률 :  89.3106%\n",
      "입양 확률 :  86.8845%\n",
      "입양 확률 :  36.3459%\n",
      "입양 확률 :  74.8865%\n",
      "입양 확률 :  26.7738%\n",
      "입양 확률 :  76.2915%\n",
      "입양 확률 :  55.9331%\n",
      "입양 확률 :  91.4863%\n",
      "입양 확률 :  29.6403%\n",
      "입양 확률 :  77.2823%\n",
      "입양 확률 :  84.6162%\n",
      "입양 확률 :  44.8503%\n",
      "입양 확률 :  80.0782%\n",
      "입양 확률 :  32.7578%\n",
      "입양 확률 :  39.8271%\n",
      "입양 확률 :  37.7214%\n",
      "입양 확률 :  41.7302%\n",
      "입양 확률 :  90.8608%\n",
      "입양 확률 :  31.8540%\n",
      "입양 확률 :  43.6976%\n",
      "입양 확률 :  39.6527%\n",
      "입양 확률 :  40.5991%\n",
      "입양 확률 :  86.8982%\n",
      "입양 확률 :  46.6477%\n",
      "입양 확률 :  34.0550%\n",
      "입양 확률 :  91.7288%\n",
      "입양 확률 :  42.0999%\n",
      "입양 확률 :  82.7919%\n",
      "입양 확률 :  39.7626%\n",
      "입양 확률 :  75.2077%\n",
      "입양 확률 :  38.4672%\n",
      "입양 확률 :  80.2841%\n",
      "입양 확률 :  74.9565%\n",
      "입양 확률 :  80.4142%\n",
      "입양 확률 :  84.9896%\n",
      "입양 확률 :  72.0752%\n",
      "입양 확률 :  27.7959%\n",
      "입양 확률 :  52.4399%\n",
      "입양 확률 :  54.0417%\n",
      "입양 확률 :  40.3163%\n",
      "입양 확률 :  55.1982%\n",
      "입양 확률 :  95.1264%\n",
      "입양 확률 :  73.9199%\n",
      "입양 확률 :  26.0297%\n",
      "입양 확률 :  49.9497%\n",
      "입양 확률 :  40.4894%\n",
      "입양 확률 :  71.9049%\n",
      "입양 확률 :  80.2524%\n",
      "입양 확률 :  53.8228%\n",
      "입양 확률 :  30.5333%\n",
      "입양 확률 :  36.2937%\n",
      "입양 확률 :  44.1794%\n",
      "입양 확률 :  28.2019%\n",
      "입양 확률 :  71.3230%\n",
      "입양 확률 :  71.3230%\n",
      "입양 확률 :  62.0971%\n",
      "입양 확률 :  67.3646%\n",
      "입양 확률 :  91.4151%\n",
      "입양 확률 :  78.5369%\n",
      "입양 확률 :  33.3205%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  60.2206%\n",
      "입양 확률 :  24.6817%\n",
      "입양 확률 :  93.9052%\n",
      "입양 확률 :  67.0049%\n",
      "입양 확률 :  67.2633%\n",
      "입양 확률 :  48.2329%\n",
      "입양 확률 :  87.2070%\n",
      "입양 확률 :  37.5005%\n",
      "입양 확률 :  55.5821%\n",
      "입양 확률 :  86.9302%\n",
      "입양 확률 :  36.5923%\n",
      "입양 확률 :  29.1846%\n",
      "입양 확률 :  83.3939%\n",
      "입양 확률 :  79.4073%\n",
      "입양 확률 :  30.9433%\n",
      "입양 확률 :  32.0811%\n",
      "입양 확률 :  30.2279%\n",
      "입양 확률 :  56.1816%\n",
      "입양 확률 :  29.3114%\n",
      "입양 확률 :  88.4804%\n",
      "입양 확률 :  37.4983%\n",
      "입양 확률 :  85.4370%\n",
      "입양 확률 :  29.4495%\n",
      "입양 확률 :  34.0754%\n",
      "입양 확률 :  91.5203%\n",
      "입양 확률 :  40.3446%\n",
      "입양 확률 :  40.7096%\n",
      "입양 확률 :  82.0429%\n",
      "입양 확률 :  43.7205%\n",
      "입양 확률 :  94.1259%\n",
      "입양 확률 :  93.7749%\n",
      "입양 확률 :  32.7578%\n",
      "입양 확률 :  89.7685%\n",
      "입양 확률 :  57.5454%\n",
      "입양 확률 :  27.6363%\n",
      "입양 확률 :  33.2161%\n",
      "입양 확률 :  23.2291%\n",
      "입양 확률 :  42.7267%\n",
      "입양 확률 :  85.2137%\n",
      "입양 확률 :  40.6669%\n",
      "입양 확률 :  84.5175%\n",
      "입양 확률 :  54.4749%\n",
      "입양 확률 :  48.5200%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  28.2052%\n",
      "입양 확률 :  76.6274%\n",
      "입양 확률 :  90.2871%\n",
      "입양 확률 :  63.5538%\n",
      "입양 확률 :  25.3717%\n",
      "입양 확률 :  46.1768%\n",
      "입양 확률 :  45.3451%\n",
      "입양 확률 :  42.0999%\n",
      "입양 확률 :  36.7390%\n",
      "입양 확률 :  36.3324%\n",
      "입양 확률 :  88.9029%\n",
      "입양 확률 :  33.5215%\n",
      "입양 확률 :  83.5877%\n",
      "입양 확률 :  84.4071%\n",
      "입양 확률 :  44.9242%\n",
      "입양 확률 :  93.1353%\n",
      "입양 확률 :  93.0980%\n",
      "입양 확률 :  71.1721%\n",
      "입양 확률 :  33.2620%\n",
      "입양 확률 :  88.0267%\n",
      "입양 확률 :  27.7433%\n",
      "입양 확률 :  82.5484%\n",
      "입양 확률 :  23.8201%\n",
      "입양 확률 :  70.6739%\n",
      "입양 확률 :  27.7433%\n",
      "입양 확률 :  90.6982%\n",
      "입양 확률 :  27.3487%\n",
      "입양 확률 :  34.1240%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  31.3785%\n",
      "입양 확률 :  47.1705%\n",
      "입양 확률 :  51.7130%\n",
      "입양 확률 :  33.3122%\n",
      "입양 확률 :  29.6297%\n",
      "입양 확률 :  76.7626%\n",
      "입양 확률 :  53.2499%\n",
      "입양 확률 :  28.9213%\n",
      "입양 확률 :  48.7735%\n",
      "입양 확률 :  76.6945%\n",
      "입양 확률 :  90.6940%\n",
      "입양 확률 :  88.4009%\n",
      "입양 확률 :  75.0052%\n",
      "입양 확률 :  23.1924%\n",
      "입양 확률 :  37.5005%\n",
      "입양 확률 :  30.2065%\n",
      "입양 확률 :  54.0701%\n",
      "입양 확률 :  68.7554%\n",
      "입양 확률 :  84.6845%\n",
      "입양 확률 :  36.9821%\n",
      "입양 확률 :  78.4158%\n",
      "입양 확률 :  36.5923%\n",
      "입양 확률 :  40.4196%\n",
      "입양 확률 :  86.4652%\n",
      "입양 확률 :  82.5119%\n",
      "입양 확률 :  24.6226%\n",
      "입양 확률 :  30.2970%\n",
      "입양 확률 :  69.4716%\n",
      "입양 확률 :  93.0375%\n",
      "입양 확률 :  33.6043%\n",
      "입양 확률 :  90.0557%\n",
      "입양 확률 :  50.7865%\n",
      "입양 확률 :  33.3205%\n",
      "입양 확률 :  32.4314%\n",
      "입양 확률 :  82.5378%\n",
      "입양 확률 :  29.6516%\n",
      "입양 확률 :  74.6187%\n",
      "입양 확률 :  33.0861%\n",
      "입양 확률 :  76.5208%\n",
      "입양 확률 :  39.1582%\n",
      "입양 확률 :  39.1582%\n",
      "입양 확률 :  27.7513%\n",
      "입양 확률 :  85.2101%\n",
      "입양 확률 :  29.1949%\n",
      "입양 확률 :  28.9213%\n",
      "입양 확률 :  34.1780%\n",
      "입양 확률 :  37.3953%\n",
      "입양 확률 :  39.9117%\n",
      "입양 확률 :  30.6148%\n",
      "입양 확률 :  27.3846%\n",
      "입양 확률 :  55.7829%\n",
      "입양 확률 :  55.7829%\n",
      "입양 확률 :  84.6056%\n",
      "입양 확률 :  29.5503%\n",
      "입양 확률 :  80.6437%\n",
      "입양 확률 :  48.7735%\n",
      "입양 확률 :  29.0381%\n",
      "입양 확률 :  85.7431%\n",
      "입양 확률 :  29.5508%\n",
      "입양 확률 :  29.5007%\n",
      "입양 확률 :  29.5007%\n",
      "입양 확률 :  36.3402%\n",
      "입양 확률 :  22.9240%\n",
      "입양 확률 :  68.0388%\n",
      "입양 확률 :  45.0437%\n",
      "입양 확률 :  51.8110%\n",
      "입양 확률 :  91.0538%\n",
      "입양 확률 :  92.6616%\n",
      "입양 확률 :  27.0242%\n",
      "입양 확률 :  36.8133%\n",
      "입양 확률 :  73.4615%\n",
      "입양 확률 :  64.4615%\n",
      "입양 확률 :  92.7757%\n",
      "입양 확률 :  82.4978%\n",
      "입양 확률 :  56.0847%\n",
      "입양 확률 :  57.7592%\n",
      "입양 확률 :  73.3543%\n",
      "입양 확률 :  43.9328%\n",
      "입양 확률 :  84.2009%\n",
      "입양 확률 :  43.5355%\n",
      "입양 확률 :  22.8924%\n",
      "입양 확률 :  72.6577%\n",
      "입양 확률 :  29.1657%\n",
      "입양 확률 :  88.6260%\n",
      "입양 확률 :  42.2912%\n",
      "입양 확률 :  36.0405%\n",
      "입양 확률 :  94.3621%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.0398%\n",
      "입양 확률 :  61.8593%\n",
      "입양 확률 :  29.5317%\n",
      "입양 확률 :  75.3754%\n",
      "입양 확률 :  54.0260%\n",
      "입양 확률 :  54.0260%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  55.1988%\n",
      "입양 확률 :  42.3845%\n",
      "입양 확률 :  31.3785%\n",
      "입양 확률 :  42.0999%\n",
      "입양 확률 :  58.0729%\n",
      "입양 확률 :  31.4567%\n",
      "입양 확률 :  25.0710%\n",
      "입양 확률 :  28.8452%\n",
      "입양 확률 :  94.4262%\n",
      "입양 확률 :  38.4951%\n",
      "입양 확률 :  36.7675%\n",
      "입양 확률 :  20.2064%\n",
      "입양 확률 :  28.9213%\n",
      "입양 확률 :  77.4118%\n",
      "입양 확률 :  44.3877%\n",
      "입양 확률 :  91.2746%\n",
      "입양 확률 :  58.3606%\n",
      "입양 확률 :  58.3606%\n",
      "입양 확률 :  57.1406%\n",
      "입양 확률 :  94.4116%\n",
      "입양 확률 :  66.8996%\n",
      "입양 확률 :  36.2556%\n",
      "입양 확률 :  89.6569%\n",
      "입양 확률 :  77.3612%\n",
      "입양 확률 :  79.5870%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  91.3021%\n",
      "입양 확률 :  21.5133%\n",
      "입양 확률 :  21.5133%\n",
      "입양 확률 :  53.4980%\n",
      "입양 확률 :  39.2845%\n",
      "입양 확률 :  42.2721%\n",
      "입양 확률 :  32.6121%\n",
      "입양 확률 :  33.0232%\n",
      "입양 확률 :  91.6300%\n",
      "입양 확률 :  87.2243%\n",
      "입양 확률 :  86.9037%\n",
      "입양 확률 :  20.0483%\n",
      "입양 확률 :  50.5222%\n",
      "입양 확률 :  44.1166%\n",
      "입양 확률 :  57.5966%\n",
      "입양 확률 :  85.0742%\n",
      "입양 확률 :  85.0742%\n",
      "입양 확률 :  85.0742%\n",
      "입양 확률 :  92.5027%\n",
      "입양 확률 :  33.8111%\n",
      "입양 확률 :  35.8180%\n",
      "입양 확률 :  73.8789%\n",
      "입양 확률 :  19.6655%\n",
      "입양 확률 :  20.9785%\n",
      "입양 확률 :  48.2864%\n",
      "입양 확률 :  55.5369%\n",
      "입양 확률 :  82.0286%\n",
      "입양 확률 :  28.0213%\n",
      "입양 확률 :  25.0031%\n",
      "입양 확률 :  71.9830%\n",
      "입양 확률 :  69.3335%\n",
      "입양 확률 :  94.2947%\n",
      "입양 확률 :  54.5583%\n",
      "입양 확률 :  79.8950%\n",
      "입양 확률 :  79.5124%\n",
      "입양 확률 :  65.0101%\n",
      "입양 확률 :  92.5092%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입양 확률 :  28.6237%\n",
      "입양 확률 :  93.3353%\n",
      "입양 확률 :  32.6441%\n",
      "입양 확률 :  37.7122%\n",
      "입양 확률 :  67.2223%\n",
      "입양 확률 :  23.0380%\n",
      "입양 확률 :  70.3892%\n",
      "입양 확률 :  77.7126%\n",
      "입양 확률 :  55.1501%\n",
      "입양 확률 :  57.7917%\n",
      "입양 확률 :  67.0752%\n",
      "입양 확률 :  32.6870%\n",
      "입양 확률 :  88.6794%\n",
      "입양 확률 :  50.1714%\n",
      "입양 확률 :  34.4334%\n",
      "입양 확률 :  30.2486%\n",
      "입양 확률 :  57.1593%\n",
      "입양 확률 :  53.8719%\n",
      "입양 확률 :  71.0483%\n",
      "입양 확률 :  66.8481%\n",
      "입양 확률 :  83.2895%\n",
      "입양 확률 :  59.9851%\n",
      "입양 확률 :  87.3223%\n",
      "입양 확률 :  94.8906%\n",
      "입양 확률 :  53.2306%\n",
      "입양 확률 :  41.5467%\n",
      "입양 확률 :  41.7502%\n",
      "입양 확률 :  26.5065%\n",
      "입양 확률 :  29.7671%\n",
      "입양 확률 :  96.1752%\n",
      "입양 확률 :  44.4502%\n",
      "입양 확률 :  92.8657%\n",
      "입양 확률 :  39.4909%\n",
      "입양 확률 :  83.0424%\n",
      "입양 확률 :  91.3181%\n",
      "입양 확률 :  86.7357%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  23.3083%\n",
      "입양 확률 :  24.4934%\n",
      "입양 확률 :  90.5356%\n",
      "입양 확률 :  65.2899%\n",
      "입양 확률 :  32.4555%\n",
      "입양 확률 :  20.8052%\n",
      "입양 확률 :  31.4452%\n",
      "입양 확률 :  50.1362%\n",
      "입양 확률 :  52.8710%\n",
      "입양 확률 :  53.2796%\n",
      "입양 확률 :  53.4489%\n",
      "입양 확률 :  85.6347%\n",
      "입양 확률 :  89.7685%\n",
      "입양 확률 :  30.2853%\n",
      "입양 확률 :  57.8625%\n",
      "입양 확률 :  33.0917%\n",
      "입양 확률 :  52.3523%\n",
      "입양 확률 :  90.5433%\n",
      "입양 확률 :  94.5191%\n",
      "입양 확률 :  36.3402%\n",
      "입양 확률 :  26.6885%\n",
      "입양 확률 :  58.0436%\n",
      "입양 확률 :  34.7650%\n",
      "입양 확률 :  37.8441%\n",
      "입양 확률 :  36.5673%\n",
      "입양 확률 :  52.7714%\n",
      "입양 확률 :  43.0492%\n",
      "입양 확률 :  90.9383%\n",
      "입양 확률 :  31.3785%\n",
      "입양 확률 :  92.8120%\n",
      "입양 확률 :  80.4843%\n",
      "입양 확률 :  56.6195%\n",
      "입양 확률 :  75.4732%\n",
      "입양 확률 :  73.3082%\n",
      "입양 확률 :  69.7706%\n",
      "입양 확률 :  46.3540%\n",
      "입양 확률 :  27.0691%\n",
      "입양 확률 :  54.5583%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  32.0362%\n",
      "입양 확률 :  54.5583%\n",
      "입양 확률 :  51.0287%\n",
      "입양 확률 :  56.4868%\n",
      "입양 확률 :  55.1727%\n",
      "입양 확률 :  27.1687%\n",
      "입양 확률 :  79.5345%\n",
      "입양 확률 :  78.0818%\n",
      "입양 확률 :  26.6011%\n",
      "입양 확률 :  27.5421%\n",
      "입양 확률 :  27.5421%\n",
      "입양 확률 :  26.6011%\n",
      "입양 확률 :  35.2598%\n",
      "입양 확률 :  28.5249%\n",
      "입양 확률 :  24.5133%\n",
      "입양 확률 :  82.6250%\n",
      "입양 확률 :  69.2903%\n",
      "입양 확률 :  26.1384%\n",
      "입양 확률 :  48.7082%\n",
      "입양 확률 :  54.5117%\n",
      "입양 확률 :  32.1908%\n",
      "입양 확률 :  70.5507%\n",
      "입양 확률 :  35.4440%\n",
      "입양 확률 :  92.4061%\n",
      "입양 확률 :  31.9113%\n",
      "입양 확률 :  31.9113%\n",
      "입양 확률 :  31.9113%\n",
      "입양 확률 :  30.7316%\n",
      "입양 확률 :  40.7673%\n",
      "입양 확률 :  32.9232%\n",
      "입양 확률 :  29.0579%\n",
      "입양 확률 :  32.0362%\n",
      "입양 확률 :  35.4440%\n",
      "입양 확률 :  86.6981%\n",
      "입양 확률 :  78.8287%\n",
      "입양 확률 :  35.2400%\n",
      "입양 확률 :  23.0991%\n",
      "입양 확률 :  81.9916%\n",
      "입양 확률 :  39.6089%\n",
      "입양 확률 :  74.2966%\n",
      "입양 확률 :  35.8483%\n",
      "입양 확률 :  77.1089%\n",
      "입양 확률 :  38.0417%\n",
      "입양 확률 :  77.1674%\n",
      "입양 확률 :  75.7726%\n",
      "입양 확률 :  87.7377%\n",
      "입양 확률 :  80.3187%\n",
      "입양 확률 :  64.9833%\n",
      "입양 확률 :  59.9470%\n",
      "입양 확률 :  59.2415%\n",
      "입양 확률 :  83.3474%\n",
      "입양 확률 :  29.4303%\n",
      "입양 확률 :  90.9939%\n",
      "입양 확률 :  81.1342%\n",
      "입양 확률 :  61.0305%\n",
      "입양 확률 :  82.8998%\n",
      "입양 확률 :  76.6702%\n",
      "입양 확률 :  34.4896%\n",
      "입양 확률 :  43.6037%\n",
      "입양 확률 :  32.9014%\n",
      "입양 확률 :  23.4589%\n",
      "입양 확률 :  39.5481%\n",
      "입양 확률 :  49.2593%\n",
      "입양 확률 :  51.5592%\n",
      "입양 확률 :  51.5592%\n",
      "입양 확률 :  88.9153%\n",
      "입양 확률 :  90.1937%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    new_x=train_data[i, :].reshape(1,186)\n",
    "    print('입양 확률 : %8.4f%%' % (l2_model.predict(new_x)*100))\n",
    "l2_model.save('l2_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
