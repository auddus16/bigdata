{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "# a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "# b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "\n",
    "# tensorflow, numpy 랜덤 값을 설정합니다.\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       kindNum neuterYn sexCd  weight  noticeDays  age2  processState\n",
      "0        128.0        N     F    7.46          10    12             0\n",
      "1        114.0        N     M    7.00          14     1             1\n",
      "2        114.0        U     M    4.50          11     2             0\n",
      "3         67.0        N     M   10.00           8     1             0\n",
      "4        114.0        N     M    6.00           8     4             0\n",
      "...        ...      ...   ...     ...         ...   ...           ...\n",
      "22787    114.0        N     M    1.00          10     0             1\n",
      "22788    114.0        N     M    1.00          10     0             1\n",
      "22789    114.0        N     M    1.00          10     0             1\n",
      "22790    128.0        U     F    6.00          12     3             0\n",
      "22791    114.0        N     M    3.50          10     0             0\n",
      "\n",
      "[22777 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#doginfo.csv파일 데이터를 pandas를 이용해 읽어옵니다.\n",
    "dog_data=pd.read_csv(\"doginfo.csv\")\n",
    "\n",
    "dog_data = dog_data.dropna(axis=0)\n",
    "print(dog_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_batch= next(iter(train_ds))[0]\n",
    "# def demo(feature_column):\n",
    "#     feature_layer = layers.DenseFeatures(feature_column)\n",
    "#     print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128.   0.   1. ...  10.  12.   0.]\n",
      " [114.   0.   0. ...  14.   1.   1.]\n",
      " [114.   1.   0. ...  11.   2.   0.]\n",
      " ...\n",
      " [114.   0.   0. ...  10.   0.   1.]\n",
      " [128.   1.   1. ...  12.   3.   0.]\n",
      " [114.   0.   0. ...  10.   0.   0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kindCd_embedding=feature_column.embedding_column(kindCd, dimension=114)\n",
    "# demo(kindCd_embedding)\n",
    "\n",
    "#읽어온 데이터를 파이썬에서 처리하기 적합하게 numpy 배열 형태로 변환합니다.\n",
    "\n",
    "dog_data.loc[dog_data[\"neuterYn\"] == \"N\", \"neuterYn\"] = 0\n",
    "dog_data.loc[dog_data[\"neuterYn\"] == \"U\", \"neuterYn\"] = 1\n",
    "dog_data.loc[dog_data[\"neuterYn\"] == \"Y\", \"neuterYn\"] = 2\n",
    "\n",
    "dog_data.loc[dog_data[\"sexCd\"] == \"M\", \"sexCd\"] = 0\n",
    "dog_data.loc[dog_data[\"sexCd\"] == \"F\", \"sexCd\"] = 1\n",
    "dog_data.loc[dog_data[\"sexCd\"] == \"Q\", \"sexCd\"] = 2\n",
    "\n",
    "# del dog_data['kindCd']\n",
    "# del dog_data['kindCd.1']\n",
    "\n",
    "# dog_data.drop(['kindCd', 'kindCd.1', 'kindNum.1'], axis='columns', inplace=True)\n",
    "\n",
    "# dog_data.drop(['neuterYn', 'sexCd'], axis='columns', inplace=True)\n",
    "data=np.array(dog_data, dtype=np.float64)\n",
    "\n",
    "\n",
    "print(data)\n",
    "print(type(data))\n",
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128.     0.     1.     7.46  10.    12.  ]\n",
      " [114.     0.     0.     7.    14.     1.  ]\n",
      " [114.     1.     0.     4.5   11.     2.  ]\n",
      " ...\n",
      " [114.     0.     0.     1.    10.     0.  ]\n",
      " [128.     1.     1.     6.    12.     3.  ]\n",
      " [114.     0.     0.     3.5   10.     0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22777, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy 배열에서 데이터 변화요인(kindCd, neuterYn, sexCd, weight, noticeDays, age2)으로 사용할 데이터를 뽑아냅니다.\n",
    "xData=data[:, :6]\n",
    "#xData=xData.reshape(136662, 1)\n",
    "print(xData)\n",
    "type(xData)\n",
    "xData.dtype\n",
    "xData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy배열에서 결과(입양여부)로 사용할 데이터를 뽑아냅니다.\n",
    "yData=data[:,[6]]\n",
    "# yData = yData.astype('int32')\n",
    "print(yData)\n",
    "type(yData)\n",
    "yData.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(?, 6), dtype=float64)\n",
      "Tensor(\"Placeholder_3:0\", shape=(?, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# #뽑아낸 데이터를 tensorflow로 처리하기 위해 placeholder를 만듭니다.\n",
    "X=tf.placeholder(tf.float64, [None, 6])\n",
    "Y=tf.placeholder(tf.float64, [None, 1])\n",
    "# #다변인 선형 회귀 모델의 기울기와 y절편을 임의의 값으로 초기화합니다.\n",
    "a=tf.Variable(tf.random_normal([6, 1], mean = 0.1, stddev = 0.01, dtype=tf.float64))#6행 1열 난수를 발생시킵니다.\n",
    "b=tf.Variable(tf.random_normal([1], dtype=tf.float64)) #1행 1열 난수를 발생시킵니다.\n",
    "print(X)\n",
    "print(Y)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#뽑아낸 데이터를 tensorflow로 처리하기 위해 placeholder를 만듭니다.\n",
    "# X=tf.placeholder(dtype=tf.float32, shape=[None, 6])\n",
    "# Y=tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "#다변인 선형 회귀 모델의 기울기와 y절편을 임의의 값으로 초기화합니다.\n",
    "# a=tf.Variable(tf.zeros([6,1], dtype=tf.float32))#6행 1열 난수를 발생시킵니다.\n",
    "# b=tf.Variable(tf.zeros([1], dtype=tf.float32)) #1행 1열 난수를 발생시킵니다.\n",
    "# print(X)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "minimize() missing 1 required positional argument: 'var_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-914ca59c32c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# optimizer=tf.train.AdamOptimizer(0.0005).minimize(cost)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: minimize() missing 1 required positional argument: 'var_list'"
     ]
    }
   ],
   "source": [
    "# #행렬의 곱셈 연산을 이용해 다변인 성형 회귀 모델의 가설 식을 세웁니다. ->예측값\n",
    "# y=tf.matmul(X, a)+b\n",
    "# #y=tf.clip_by_value(y, 1e-5, 1-(1e-5))\n",
    "\n",
    "# #오차 함수를 만듭니다.\n",
    "# loss= tf.reduce_mean(tf.square(y-Y))\n",
    "# #loss= tf.clip_by_value(loss, 1e-5, 1-(1e-5))\n",
    "\n",
    "# #경사하강법 알고리즘을 사용해서 오차 함수 결과를 최소로 하는 식을 만듭니다. \n",
    "# gradient_descent=tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "\n",
    "# # 시그모이드 방정식을 만듭니다.\n",
    "y = tf.sigmoid(tf.matmul(X, a) + b)\n",
    "# # 오차 함수\n",
    "# loss = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))\n",
    "# 경사 하강 알고리즘\n",
    "# # gradient_descent = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "# gradient_descent = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# y=tf.nn.softmax(tf.matmul(X, a)+ b)\n",
    "# cost= tf.reduce_mean(-tf.reduce_sum(Y*tf.log(y), reduction_indices=1))\n",
    "cost = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))\n",
    "# optimizer=tf.train.AdamOptimizer(0.0005).minimize(cost)\n",
    "optimizer = tf.keras.optimizers.Adam(0.0005).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(y >= 0.5, dtype = tf.float64)\n",
    "\n",
    "# 예상값이 실제값과 일치하는 정도(정확도)를 계산합니다.\n",
    "# tf.equal(): tensorflow에서 인수로 지정된 값이 같으면 True, 다르면 False 결과를 tf.float64로 캐스팅 시키고 시행된 전체 평균을 계산합니다.\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float64))  # 정확도 (0 또는 1) \n",
    "\n",
    "with tf.Session() as sess:  # 세션 구간을 만듦\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10001):\n",
    "        # count : 학습 횟수, a1 : 기울기(공부 시간), asess.run(cost, feed_dict={X:xData, Y:yData}))\n",
    "        a_, b_, cost_, _ = sess.run([a, b, cost, optimizer], feed_dict = {X:xData, Y:yData})\n",
    "        if i % 2000 == 0:\n",
    "            print(sess.run(y, feed_dict={X:xData}))\n",
    "            print('count:{}, a1 = {}, a2 = {}, a3 = {}, a4 = {}, a5 = {}, a6 = {}, b = {}, loss = {}'.format(i, a_[0], a_[1], a_[2], a_[3], a_[4], a_[5], b_, cost_)) # 학습시킨 데이터 출력\n",
    "#     saver=tf.train.Saver()\n",
    "#     save_path=saver.save(sess, './dogsaved.ckpt')\n",
    "#     print('학습된 모델을 저장했습니다.')\n",
    "    new_x = np.array([114, 0, 1, 6.3, 10, 1], dtype=np.float64).reshape(1, 6)  # reshape() 함수를 이용해서 1행 2열인 2차원 numpy 배열을 만듭니다.\n",
    "    print(new_x)\n",
    "    # sigmoid() 함수 연산 결과에 테스트 데이터를 대입시켜 연산합니다.\n",
    "    result, new_y = sess.run([predicted, y], feed_dict = {X:new_x})\n",
    "#     print('품종 : %d, 중성화 : %d' % (new_x[:, 0], new_x[:, 1]), end=',')\n",
    "    print('합격 여부(sigmoid() 함수 실행 결과를 0.5 이상은 1, 미만은 0으로 반환) : %d, 합격 확률(sigmoid() 함수 실행 결과) : %f)' % (result, new_y))\n",
    "    \n",
    "#     for i in range(11):\n",
    "#         new_x = np.array([0, i]).reshape(1, 6)  # 과외 시간만 계속 늘림\n",
    "    result, new_y = sess.run([predicted, y], feed_dict={X:new_x})\n",
    "#         print('품종 : %d, 과외 시간 : %2d, ' % (new_x[:, 0], new_x[:, 1]), end=',')\n",
    "    print('입양 여부 : %s, 입양 확률 : %8.4f%%' % ('합격' if result == 1 else '불합격', new_y*100))\n",
    "#     print(sess.run(accuracy, feed_dict = {Y : yData}))\n",
    "\n",
    "# #init=tf.initialize_all_variables()\n",
    "# sess=tf.Session()\n",
    "# #sess.run(init)\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# for step in range(2001):\n",
    "# #     print(sess.run(y, feed_dict={X : xData}))\n",
    "#     sess.run(optimizer, feed_dict={X:xData, Y:yData})\n",
    "# #     sess.run(optimizer)\n",
    "#     if step % 200 == 0:\n",
    "#         print(step, sess.run(cost, feed_dict={X:xData, Y:yData}), sess.run(a), sess.run(b))\n",
    "# #     if step % 200 == 0:\n",
    "# #         print(step, sess.run(a), sess.run(b), {}, a3 = {}, a4 = {}, a5 = {}, a6 = {}, b = {}, loss = {}'.format(i, a_[0], a_[1], a_[2], a_[3], a_[4], a_[5], b_, cost_)) # 학습시킨 데이터 출력\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-224-75a16fcc1350>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-224-75a16fcc1350>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    new_x = np.array([6, 5]).reshape(1, 6)  # reshape() 함수를 이용해서 1행 2열인 2차원 numpy 배열을 만듭니다.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# #학습을 시킨 후 학습된 모델을 저장합니다.\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(10001):\n",
    "#         loss_, y_, _ = sess.run([loss, y, gradient_descent], feed_dict={X:xData, Y:yData})\n",
    "#         if i % 500 ==0:\n",
    "#             print(\"count:%6d, loss=%12.3f. print=%6.1f\" %(i, loss_, y_[0]))\n",
    "\n",
    "\n",
    "# with tf.Session() as sess:  # 세션 구간을 만듦\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(3001):\n",
    "#         # count : 학습 횟수, a1 : 기울기(공부 시간), a2 : 기울기(과외 시간), b : y절편, loss : 오차 함수\n",
    "#         a_, b_, loss_, _ = sess.run([a, b, loss, gradient_descent], feed_dict = {X:xData, Y:yData})\n",
    "#         if i % 300 == 0:\n",
    "#             print('count : {}, a1 = {}, a2 = {}, a3 = {}, a4 = {}, a5 = {}, a6 = {}, b = {}, loss = {}'.format(i, a_[0], a_[1], a_[2], a_[3], a_[4], a_[5], b_, loss_)) # 학습시킨 데이터 출력\n",
    "            \n",
    "# 학습 완료 -----------------------------------------------------------------------------------------------------\n",
    "#테스트 데이터\n",
    "\n",
    "#     new_x = np.array([6, 5]).reshape(1, 6)  # reshape() 함수를 이용해서 1행 2열인 2차원 numpy 배열을 만듭니다.\n",
    "    \n",
    "#     # sigmoid() 함수 연산 결과에 테스트 데이터를 대입시켜 연산합니다.\n",
    "#     result, new_y = sess.run([predicted, y], feed_dict = {X:new_x})\n",
    "#     print('공부 시간 : %d, 과외 시간 : %d' % (new_x[:, 0], new_x[:, 1]))\n",
    "#     print('합격 여부(sigmoid() 함수 실행 결과를 0.5 이상은 1, 미만은 0으로 반환) : %d, 합격 확률(sigmoid() 함수 실행 결과) : %f)' % (result, new_y))\n",
    "    \n",
    "#     for i in range(11):\n",
    "# #         new_x = np.array([0, i]).reshape(1, 6)  # 과외 시간만 계속 늘림\n",
    "#         result, new_y = sess.run([predicted, y], feed_dict={X:new_x})\n",
    "# #         print('품종 : %d, 과외 시간 : %2d, ' % (new_x[:, 0], new_x[:, 1]), end=',')\n",
    "#         print('입양 여부 : %s, 입양 확률 : %8.4f%%' % ('합격' if result == 1 else '불합격', new_y*100))\n",
    "\n",
    "\n",
    "# 학습이 완료되면 학습된 모델을 디스크에 저장합니다.\n",
    "# tf.train.Saver(): 학습된 모델을 디스트로 저장 또는 불로오는 객체를 생성하는 함수\n",
    "    saver= tf.train.Saver()\n",
    "#     saver_path=saver.save(sess, './dogsave.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
