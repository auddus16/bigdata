{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, Conv2D\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, SGD\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
    "# from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
    "# from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "# a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "# b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "\n",
    "# tensorflow, numpy 랜덤 값을 설정합니다.\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuterYn</th>\n",
       "      <th>sexCd</th>\n",
       "      <th>weight</th>\n",
       "      <th>noticeDays</th>\n",
       "      <th>age2</th>\n",
       "      <th>processState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>1.7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>1.7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>U</td>\n",
       "      <td>F</td>\n",
       "      <td>3.6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>3.1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    neuterYn sexCd  weight  noticeDays  age2  processState\n",
       "0          N     M     0.8          10     0             1\n",
       "1          N     M     5.0          10     1             0\n",
       "2          N     F     5.0          10    13             0\n",
       "3          N     M     5.0          10     3             0\n",
       "4          N     M    15.0          10     7             0\n",
       "..       ...   ...     ...         ...   ...           ...\n",
       "606        Y     M     6.4          11    10             0\n",
       "607        U     F     1.7          11     0             0\n",
       "608        U     F     1.7          11     0             1\n",
       "609        U     F     3.6          11     2             1\n",
       "610        N     M     3.1          11     2             0\n",
       "\n",
       "[611 rows x 6 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doginfo.csv파일 데이터를 pandas를 이용해 읽어옵니다.\n",
    "dog_data=pd.read_csv(\"doginfo2.csv\")\n",
    "# dog_train=pd.read_csv(\"testDog2.csv\")\n",
    "# kindCd=pd.read_csv(\"kindCd.csv\")\n",
    "\n",
    "dog_data = dog_data.dropna(axis=0)\n",
    "# dog_train = dog_train.dropna(axis=0)\n",
    "# kindCd_data = kindCd.dropna(axis=0)\n",
    "\n",
    "dog_data\n",
    "dog_train\n",
    "# print(dog_train)\n",
    "# print(kindCd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindCd = np.array(kindCd_data, dtype = np.float64)\n",
    "# kindCd_train=np.array(kindCd_data, dtype=np.float64)\n",
    "\n",
    "# kindCd = kindCd.reshape(177)\n",
    "# kindCd_train=kindCd_train.reshape(177)\n",
    "# print(kindCd)\n",
    "# print(kindCd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kindNum을 원핫 인코딩\n",
    "# kindCd = pd.concat((pd.get_dummies(dog_data.kindNum, columns=kindCd), pd.DataFrame(columns=kindCd))).fillna(0)\n",
    "# # kindCd\n",
    "\n",
    "# # 학습데이터에서 kindNum 열을 삭제한 후, 원핫 인코딩된 kindCd를 붙임\n",
    "# dog_data.drop(['kindNum'], axis='columns', inplace=True)\n",
    "# dog_data = pd.concat([dog_data, kindCd], axis=1)\n",
    "\n",
    "\n",
    "# # kindNum을 원핫 인코딩\n",
    "# kindCd_train = pd.concat((pd.get_dummies(dog_train.kindNum, columns=kindCd_train), pd.DataFrame(columns=kindCd_train))).fillna(0)\n",
    "\n",
    "# # 테스트데이터에서 kindNum 열을 삭제한 후, 원핫 인코딩된 kindCd를 붙임\n",
    "# dog_train.drop(['kindNum'], axis='columns', inplace=True)\n",
    "# dog_train = pd.concat([dog_train, kindCd_train], axis=1)\n",
    "# dog_data\n",
    "# # dog_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_data(data, columns):\n",
    "    for column in columns:\n",
    "        data = pd.concat([data, pd.get_dummies(data[column], prefix = column)], axis = 1)\n",
    "        data = data.drop(column, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       weight  noticeDays  age2  processState  neuterYn_N  neuterYn_U  \\\n",
      "0        7.46          10    12             0           1           0   \n",
      "1        7.00          14     1             1           1           0   \n",
      "2        4.50          11     2             0           0           1   \n",
      "3       10.00           8     1             0           1           0   \n",
      "4        6.00           8     4             0           1           0   \n",
      "...       ...         ...   ...           ...         ...         ...   \n",
      "22787    1.00          10     0             1           1           0   \n",
      "22788    1.00          10     0             1           1           0   \n",
      "22789    1.00          10     0             1           1           0   \n",
      "22790    6.00          12     3             0           0           1   \n",
      "22791    3.50          10     0             0           1           0   \n",
      "\n",
      "       neuterYn_Y  sexCd_F  sexCd_M  sexCd_Q  \n",
      "0               0        1        0        0  \n",
      "1               0        0        1        0  \n",
      "2               0        0        1        0  \n",
      "3               0        0        1        0  \n",
      "4               0        0        1        0  \n",
      "...           ...      ...      ...      ...  \n",
      "22787           0        0        1        0  \n",
      "22788           0        0        1        0  \n",
      "22789           0        0        1        0  \n",
      "22790           0        1        0        0  \n",
      "22791           0        0        1        0  \n",
      "\n",
      "[22792 rows x 10 columns]\n",
      "14586 훈련 샘플\n",
      "3647 검증 샘플\n",
      "4559 테스트 샘플\n"
     ]
    }
   ],
   "source": [
    "dummy_columns = [\"neuterYn\", \"sexCd\"]\n",
    "data = dummy_data(dog_data, dummy_columns)\n",
    "# train_data = dummy_data(dog_train, dummy_columns)\n",
    "data.head()\n",
    "# train_data.head()\n",
    "# print(type(dog_data))\n",
    "# print(type(data))\n",
    "\n",
    "print(data)\n",
    "\n",
    "data = np.array(data, dtype = np.float64)\n",
    "# train_data = np.array(train_data, dtype = np.float64)\n",
    "\n",
    "# data\n",
    "# print(data.shape)\n",
    "# print(len(train_data))\n",
    "# print(train_data.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), '훈련 샘플')\n",
    "print(len(val), '검증 샘플')\n",
    "print(len(test), '테스트 샘플')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.  10.   4.  ...  1.   0.   0. ]\n",
      " [ 7.5 10.   2.  ...  1.   0.   0. ]\n",
      " [15.  10.   2.  ...  0.   1.   0. ]\n",
      " ...\n",
      " [ 4.8 10.   6.  ...  1.   0.   0. ]\n",
      " [ 2.  10.   0.  ...  0.   1.   0. ]\n",
      " [ 5.6 10.   2.  ...  1.   0.   0. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4559, 9)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = train[:, :3]\n",
    "b = train[:, 4:]\n",
    "\n",
    "# print(a[0,:])\n",
    "# print(b)\n",
    "\n",
    "#numpy 배열에서 데이터 변화요인(kindCd, neuterYn, sexCd, weight, noticeDays, age2)으로 사용할 데이터를 뽑아냅니다.\n",
    "xData = np.concatenate([a, b], axis = 1)\n",
    "\n",
    "a = test[:, :3]\n",
    "b = test[:, 4:]\n",
    "testX = np.concatenate([a, b], axis = 1)\n",
    "\n",
    "a = val[:, :3]\n",
    "b = val[:, 4:]\n",
    "valX = np.concatenate([a, b], axis = 1)\n",
    "\n",
    "print(xData)\n",
    "type(xData)\n",
    "xData.shape\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#numpy배열에서 결과(입양여부)로 사용할 데이터를 뽑아냅니다.\n",
    "yData=train[:,[3]]\n",
    "testY = test[:,[3]]\n",
    "valY = val[:,[3]]\n",
    "\n",
    "# yData = yData.astype('int32')\n",
    "print(yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "xData = mm_scaler.fit_transform(xData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14586 samples, validate on 3647 samples\n",
      "Epoch 1/100\n",
      "14586/14586 [==============================] - 2s 162us/sample - loss: 0.7040 - acc: 0.5128 - binary_crossentropy: 0.7040 - val_loss: 0.8804 - val_acc: 0.4546 - val_binary_crossentropy: 0.8804\n",
      "Epoch 2/100\n",
      "14586/14586 [==============================] - 2s 118us/sample - loss: 0.6919 - acc: 0.5330 - binary_crossentropy: 0.6919 - val_loss: 0.8265 - val_acc: 0.4535 - val_binary_crossentropy: 0.8265\n",
      "Epoch 3/100\n",
      "14586/14586 [==============================] - 2s 117us/sample - loss: 0.6902 - acc: 0.5376 - binary_crossentropy: 0.6902 - val_loss: 0.7899 - val_acc: 0.4505 - val_binary_crossentropy: 0.7899\n",
      "Epoch 4/100\n",
      "14586/14586 [==============================] - 2s 153us/sample - loss: 0.6886 - acc: 0.5479 - binary_crossentropy: 0.6886 - val_loss: 0.7693 - val_acc: 0.4461 - val_binary_crossentropy: 0.7693\n",
      "Epoch 5/100\n",
      "14586/14586 [==============================] - 3s 181us/sample - loss: 0.6878 - acc: 0.5503 - binary_crossentropy: 0.6878 - val_loss: 0.7575 - val_acc: 0.4494 - val_binary_crossentropy: 0.7575\n",
      "Epoch 6/100\n",
      "14586/14586 [==============================] - 3s 180us/sample - loss: 0.6875 - acc: 0.5529 - binary_crossentropy: 0.6875 - val_loss: 0.7403 - val_acc: 0.4587 - val_binary_crossentropy: 0.7403\n",
      "Epoch 7/100\n",
      "14586/14586 [==============================] - 3s 191us/sample - loss: 0.6872 - acc: 0.5503 - binary_crossentropy: 0.6872 - val_loss: 0.7370 - val_acc: 0.4593 - val_binary_crossentropy: 0.7370\n",
      "Epoch 8/100\n",
      "14586/14586 [==============================] - 3s 194us/sample - loss: 0.6865 - acc: 0.5550 - binary_crossentropy: 0.6865 - val_loss: 0.7410 - val_acc: 0.4593 - val_binary_crossentropy: 0.7410\n",
      "Epoch 9/100\n",
      "14586/14586 [==============================] - 2s 170us/sample - loss: 0.6853 - acc: 0.5567 - binary_crossentropy: 0.6853 - val_loss: 0.7431 - val_acc: 0.4620 - val_binary_crossentropy: 0.7431\n",
      "Epoch 10/100\n",
      "14586/14586 [==============================] - 2s 126us/sample - loss: 0.6855 - acc: 0.5549 - binary_crossentropy: 0.6855 - val_loss: 0.7493 - val_acc: 0.4617 - val_binary_crossentropy: 0.7493\n",
      "Epoch 11/100\n",
      "14586/14586 [==============================] - 2s 163us/sample - loss: 0.6861 - acc: 0.5570 - binary_crossentropy: 0.6861 - val_loss: 0.7448 - val_acc: 0.4645 - val_binary_crossentropy: 0.7448\n",
      "Epoch 12/100\n",
      "14586/14586 [==============================] - 3s 172us/sample - loss: 0.6860 - acc: 0.5561 - binary_crossentropy: 0.6860 - val_loss: 0.7358 - val_acc: 0.4648 - val_binary_crossentropy: 0.7358\n",
      "Epoch 13/100\n",
      "14586/14586 [==============================] - 3s 204us/sample - loss: 0.6853 - acc: 0.5570 - binary_crossentropy: 0.6853 - val_loss: 0.7273 - val_acc: 0.4752 - val_binary_crossentropy: 0.7273\n",
      "Epoch 14/100\n",
      "14586/14586 [==============================] - 3s 192us/sample - loss: 0.6855 - acc: 0.5566 - binary_crossentropy: 0.6855 - val_loss: 0.7251 - val_acc: 0.4820 - val_binary_crossentropy: 0.7251\n",
      "Epoch 15/100\n",
      "14586/14586 [==============================] - 3s 198us/sample - loss: 0.6850 - acc: 0.5582 - binary_crossentropy: 0.6850 - val_loss: 0.7291 - val_acc: 0.4746 - val_binary_crossentropy: 0.7291\n",
      "Epoch 16/100\n",
      "14586/14586 [==============================] - 2s 138us/sample - loss: 0.6856 - acc: 0.5564 - binary_crossentropy: 0.6856 - val_loss: 0.7257 - val_acc: 0.4779 - val_binary_crossentropy: 0.7257\n",
      "Epoch 17/100\n",
      "14586/14586 [==============================] - 2s 154us/sample - loss: 0.6853 - acc: 0.5580 - binary_crossentropy: 0.6853 - val_loss: 0.7234 - val_acc: 0.4905 - val_binary_crossentropy: 0.7234\n",
      "Epoch 18/100\n",
      "14586/14586 [==============================] - 3s 179us/sample - loss: 0.6843 - acc: 0.5579 - binary_crossentropy: 0.6843 - val_loss: 0.7248 - val_acc: 0.4925 - val_binary_crossentropy: 0.7248\n",
      "Epoch 19/100\n",
      "14586/14586 [==============================] - 3s 221us/sample - loss: 0.6840 - acc: 0.5585 - binary_crossentropy: 0.6840 - val_loss: 0.7240 - val_acc: 0.4919 - val_binary_crossentropy: 0.7240\n",
      "Epoch 20/100\n",
      "14586/14586 [==============================] - 3s 219us/sample - loss: 0.6845 - acc: 0.5575 - binary_crossentropy: 0.6845 - val_loss: 0.7251 - val_acc: 0.4957 - val_binary_crossentropy: 0.7251\n",
      "Epoch 21/100\n",
      "14586/14586 [==============================] - 2s 144us/sample - loss: 0.6841 - acc: 0.5579 - binary_crossentropy: 0.6841 - val_loss: 0.7257 - val_acc: 0.5078 - val_binary_crossentropy: 0.7257\n",
      "Epoch 22/100\n",
      "14586/14586 [==============================] - 2s 125us/sample - loss: 0.6838 - acc: 0.5595 - binary_crossentropy: 0.6838 - val_loss: 0.7277 - val_acc: 0.5106 - val_binary_crossentropy: 0.7277\n",
      "Epoch 23/100\n",
      "14586/14586 [==============================] - 2s 126us/sample - loss: 0.6847 - acc: 0.5572 - binary_crossentropy: 0.6847 - val_loss: 0.7265 - val_acc: 0.5339 - val_binary_crossentropy: 0.7265\n",
      "Epoch 24/100\n",
      "14586/14586 [==============================] - 2s 142us/sample - loss: 0.6848 - acc: 0.5590 - binary_crossentropy: 0.6848 - val_loss: 0.7282 - val_acc: 0.5243 - val_binary_crossentropy: 0.7282\n",
      "Epoch 25/100\n",
      "14586/14586 [==============================] - 3s 195us/sample - loss: 0.6839 - acc: 0.5604 - binary_crossentropy: 0.6839 - val_loss: 0.7288 - val_acc: 0.5385 - val_binary_crossentropy: 0.7288\n",
      "Epoch 26/100\n",
      "14586/14586 [==============================] - 2s 166us/sample - loss: 0.6846 - acc: 0.5594 - binary_crossentropy: 0.6846 - val_loss: 0.7300 - val_acc: 0.5383 - val_binary_crossentropy: 0.7300\n",
      "Epoch 27/100\n",
      "14586/14586 [==============================] - 2s 125us/sample - loss: 0.6845 - acc: 0.5606 - binary_crossentropy: 0.6845 - val_loss: 0.7329 - val_acc: 0.5383 - val_binary_crossentropy: 0.7329\n",
      "Epoch 28/100\n",
      "14586/14586 [==============================] - 3s 194us/sample - loss: 0.6829 - acc: 0.5604 - binary_crossentropy: 0.6829 - val_loss: 0.7351 - val_acc: 0.5440 - val_binary_crossentropy: 0.7351\n",
      "Epoch 29/100\n",
      "14586/14586 [==============================] - 2s 125us/sample - loss: 0.6842 - acc: 0.5608 - binary_crossentropy: 0.6842 - val_loss: 0.7385 - val_acc: 0.5429 - val_binary_crossentropy: 0.7385\n",
      "Epoch 30/100\n",
      "14586/14586 [==============================] - 2s 142us/sample - loss: 0.6835 - acc: 0.5611 - binary_crossentropy: 0.6835 - val_loss: 0.7387 - val_acc: 0.5457 - val_binary_crossentropy: 0.7387\n",
      "Epoch 31/100\n",
      "14586/14586 [==============================] - 2s 123us/sample - loss: 0.6831 - acc: 0.5605 - binary_crossentropy: 0.6831 - val_loss: 0.7411 - val_acc: 0.5457 - val_binary_crossentropy: 0.7411\n",
      "Epoch 32/100\n",
      "14586/14586 [==============================] - 2s 123us/sample - loss: 0.6832 - acc: 0.5609 - binary_crossentropy: 0.6832 - val_loss: 0.7472 - val_acc: 0.5566 - val_binary_crossentropy: 0.7472\n",
      "Epoch 33/100\n",
      "14586/14586 [==============================] - 3s 193us/sample - loss: 0.6841 - acc: 0.5602 - binary_crossentropy: 0.6841 - val_loss: 0.7500 - val_acc: 0.5525 - val_binary_crossentropy: 0.7500\n",
      "Epoch 34/100\n",
      "14586/14586 [==============================] - 3s 203us/sample - loss: 0.6838 - acc: 0.5596 - binary_crossentropy: 0.6838 - val_loss: 0.7501 - val_acc: 0.5561 - val_binary_crossentropy: 0.7501\n",
      "Epoch 35/100\n",
      "14586/14586 [==============================] - 3s 191us/sample - loss: 0.6825 - acc: 0.5613 - binary_crossentropy: 0.6825 - val_loss: 0.7552 - val_acc: 0.5572 - val_binary_crossentropy: 0.7552\n",
      "Epoch 36/100\n",
      "14586/14586 [==============================] - 2s 135us/sample - loss: 0.6828 - acc: 0.5598 - binary_crossentropy: 0.6828 - val_loss: 0.7682 - val_acc: 0.5723 - val_binary_crossentropy: 0.7682\n",
      "Epoch 37/100\n",
      "14586/14586 [==============================] - 2s 131us/sample - loss: 0.6835 - acc: 0.5594 - binary_crossentropy: 0.6835 - val_loss: 0.7677 - val_acc: 0.5703 - val_binary_crossentropy: 0.7677\n",
      "Epoch 38/100\n",
      "14586/14586 [==============================] - 3s 199us/sample - loss: 0.6831 - acc: 0.5609 - binary_crossentropy: 0.6831 - val_loss: 0.7696 - val_acc: 0.5659 - val_binary_crossentropy: 0.7696\n",
      "Epoch 39/100\n",
      "14586/14586 [==============================] - 2s 167us/sample - loss: 0.6830 - acc: 0.5603 - binary_crossentropy: 0.6830 - val_loss: 0.7770 - val_acc: 0.5739 - val_binary_crossentropy: 0.7770\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14586/14586 [==============================] - 3s 204us/sample - loss: 0.6820 - acc: 0.5608 - binary_crossentropy: 0.6820 - val_loss: 0.7812 - val_acc: 0.5739 - val_binary_crossentropy: 0.7812\n",
      "Epoch 41/100\n",
      "14586/14586 [==============================] - 3s 179us/sample - loss: 0.6825 - acc: 0.5603 - binary_crossentropy: 0.6825 - val_loss: 0.7858 - val_acc: 0.5733 - val_binary_crossentropy: 0.7858\n",
      "Epoch 42/100\n",
      "14586/14586 [==============================] - 2s 136us/sample - loss: 0.6820 - acc: 0.5603 - binary_crossentropy: 0.6820 - val_loss: 0.7973 - val_acc: 0.5758 - val_binary_crossentropy: 0.7973\n",
      "Epoch 43/100\n",
      "14586/14586 [==============================] - 2s 119us/sample - loss: 0.6825 - acc: 0.5601 - binary_crossentropy: 0.6825 - val_loss: 0.8068 - val_acc: 0.5728 - val_binary_crossentropy: 0.8068\n",
      "Epoch 44/100\n",
      "14586/14586 [==============================] - 2s 116us/sample - loss: 0.6829 - acc: 0.5607 - binary_crossentropy: 0.6829 - val_loss: 0.8086 - val_acc: 0.5714 - val_binary_crossentropy: 0.8086\n",
      "Epoch 45/100\n",
      "14586/14586 [==============================] - 2s 117us/sample - loss: 0.6830 - acc: 0.5594 - binary_crossentropy: 0.6830 - val_loss: 0.8212 - val_acc: 0.5632 - val_binary_crossentropy: 0.8212\n",
      "Epoch 46/100\n",
      "14586/14586 [==============================] - 3s 176us/sample - loss: 0.6827 - acc: 0.5609 - binary_crossentropy: 0.6827 - val_loss: 0.8297 - val_acc: 0.5638 - val_binary_crossentropy: 0.8297\n",
      "Epoch 47/100\n",
      "14586/14586 [==============================] - 3s 184us/sample - loss: 0.6834 - acc: 0.5610 - binary_crossentropy: 0.6834 - val_loss: 0.8295 - val_acc: 0.5687 - val_binary_crossentropy: 0.8295\n",
      "Epoch 48/100\n",
      "14586/14586 [==============================] - 2s 148us/sample - loss: 0.6818 - acc: 0.5616 - binary_crossentropy: 0.6818 - val_loss: 0.8421 - val_acc: 0.5670 - val_binary_crossentropy: 0.8421\n",
      "Epoch 49/100\n",
      "14586/14586 [==============================] - 2s 156us/sample - loss: 0.6830 - acc: 0.5601 - binary_crossentropy: 0.6830 - val_loss: 0.8476 - val_acc: 0.5668 - val_binary_crossentropy: 0.8476\n",
      "Epoch 50/100\n",
      "14586/14586 [==============================] - 2s 113us/sample - loss: 0.6825 - acc: 0.5609 - binary_crossentropy: 0.6825 - val_loss: 0.8566 - val_acc: 0.5627 - val_binary_crossentropy: 0.8566\n",
      "Epoch 51/100\n",
      "14586/14586 [==============================] - 2s 124us/sample - loss: 0.6816 - acc: 0.5615 - binary_crossentropy: 0.6816 - val_loss: 0.8773 - val_acc: 0.5591 - val_binary_crossentropy: 0.8773\n",
      "Epoch 52/100\n",
      " 8448/14586 [================>.............] - ETA: 0s - loss: 0.6812 - acc: 0.5611 - binary_crossentropy: 0.6812"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model=Sequential()\n",
    "# model.add(Dense(1, input_dim=9, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.add(Dense(32, input_shape = (9, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer='sgd' ,loss='binary_crossentropy', metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "hist = model.fit(xData,yData, batch_size=32, epochs=100, validation_data=(valX, valY), verbose=1)\n",
    "\n",
    "loss_and_metric = model.evaluate(testX, testY, batch_size = 32, verbose = 0)\n",
    "print(\"train, loss and metric : {}\".format(loss_and_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22792 samples, validate on 611 samples\n",
      "Epoch 1/100\n",
      "22792/22792 [==============================] - 1s 56us/sample - loss: 0.8675 - acc: 0.5316 - binary_crossentropy: 0.8675 - val_loss: 0.8734 - val_acc: 0.5254 - val_binary_crossentropy: 0.8734\n",
      "Epoch 2/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.8615 - acc: 0.5330 - binary_crossentropy: 0.8615 - val_loss: 0.8591 - val_acc: 0.5303 - val_binary_crossentropy: 0.8591\n",
      "Epoch 3/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.8526 - acc: 0.5377 - binary_crossentropy: 0.8526 - val_loss: 0.8585 - val_acc: 0.5286 - val_binary_crossentropy: 0.8585\n",
      "Epoch 4/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.8478 - acc: 0.5365 - binary_crossentropy: 0.8478 - val_loss: 0.8535 - val_acc: 0.5368 - val_binary_crossentropy: 0.8535\n",
      "Epoch 5/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.8399 - acc: 0.5392 - binary_crossentropy: 0.8399 - val_loss: 0.8529 - val_acc: 0.5286 - val_binary_crossentropy: 0.8529\n",
      "Epoch 6/100\n",
      "22792/22792 [==============================] - 1s 45us/sample - loss: 0.8366 - acc: 0.5406 - binary_crossentropy: 0.8366 - val_loss: 0.8502 - val_acc: 0.5319 - val_binary_crossentropy: 0.8502\n",
      "Epoch 7/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.8300 - acc: 0.5381 - binary_crossentropy: 0.8300 - val_loss: 0.8378 - val_acc: 0.5319 - val_binary_crossentropy: 0.8378\n",
      "Epoch 8/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.8223 - acc: 0.5452 - binary_crossentropy: 0.8223 - val_loss: 0.8356 - val_acc: 0.5434 - val_binary_crossentropy: 0.8356\n",
      "Epoch 9/100\n",
      "22792/22792 [==============================] - 1s 51us/sample - loss: 0.8201 - acc: 0.5432 - binary_crossentropy: 0.8201 - val_loss: 0.8359 - val_acc: 0.5434 - val_binary_crossentropy: 0.8359\n",
      "Epoch 10/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.8133 - acc: 0.5454 - binary_crossentropy: 0.8133 - val_loss: 0.8274 - val_acc: 0.5385 - val_binary_crossentropy: 0.8274\n",
      "Epoch 11/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.8118 - acc: 0.5427 - binary_crossentropy: 0.8118 - val_loss: 0.8188 - val_acc: 0.5385 - val_binary_crossentropy: 0.8188\n",
      "Epoch 12/100\n",
      "22792/22792 [==============================] - 1s 49us/sample - loss: 0.8029 - acc: 0.5465 - binary_crossentropy: 0.8029 - val_loss: 0.8219 - val_acc: 0.5450 - val_binary_crossentropy: 0.8219\n",
      "Epoch 13/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.7977 - acc: 0.5490 - binary_crossentropy: 0.7977 - val_loss: 0.8135 - val_acc: 0.5417 - val_binary_crossentropy: 0.8135\n",
      "Epoch 14/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7947 - acc: 0.5496 - binary_crossentropy: 0.7947 - val_loss: 0.8065 - val_acc: 0.5434 - val_binary_crossentropy: 0.8065\n",
      "Epoch 15/100\n",
      "22792/22792 [==============================] - 1s 48us/sample - loss: 0.7905 - acc: 0.5484 - binary_crossentropy: 0.7905 - val_loss: 0.8017 - val_acc: 0.5434 - val_binary_crossentropy: 0.8017\n",
      "Epoch 16/100\n",
      "22792/22792 [==============================] - 1s 47us/sample - loss: 0.7875 - acc: 0.5488 - binary_crossentropy: 0.7875 - val_loss: 0.7977 - val_acc: 0.5401 - val_binary_crossentropy: 0.7977\n",
      "Epoch 17/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7817 - acc: 0.5543 - binary_crossentropy: 0.7817 - val_loss: 0.7902 - val_acc: 0.5434 - val_binary_crossentropy: 0.7902\n",
      "Epoch 18/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7780 - acc: 0.5520 - binary_crossentropy: 0.7780 - val_loss: 0.7882 - val_acc: 0.5417 - val_binary_crossentropy: 0.7882\n",
      "Epoch 19/100\n",
      "22792/22792 [==============================] - 1s 45us/sample - loss: 0.7765 - acc: 0.5501 - binary_crossentropy: 0.7765 - val_loss: 0.7900 - val_acc: 0.5434 - val_binary_crossentropy: 0.7900\n",
      "Epoch 20/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7704 - acc: 0.5587 - binary_crossentropy: 0.7704 - val_loss: 0.7806 - val_acc: 0.5417 - val_binary_crossentropy: 0.7806\n",
      "Epoch 21/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7680 - acc: 0.5551 - binary_crossentropy: 0.7680 - val_loss: 0.7768 - val_acc: 0.5466 - val_binary_crossentropy: 0.7768\n",
      "Epoch 22/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7662 - acc: 0.5581 - binary_crossentropy: 0.7662 - val_loss: 0.7729 - val_acc: 0.5401 - val_binary_crossentropy: 0.7729\n",
      "Epoch 23/100\n",
      "22792/22792 [==============================] - 1s 45us/sample - loss: 0.7575 - acc: 0.5598 - binary_crossentropy: 0.7575 - val_loss: 0.7730 - val_acc: 0.5434 - val_binary_crossentropy: 0.7730\n",
      "Epoch 24/100\n",
      "22792/22792 [==============================] - 1s 57us/sample - loss: 0.7579 - acc: 0.5600 - binary_crossentropy: 0.7579 - val_loss: 0.7617 - val_acc: 0.5434 - val_binary_crossentropy: 0.7617\n",
      "Epoch 25/100\n",
      "22792/22792 [==============================] - 1s 57us/sample - loss: 0.7522 - acc: 0.5612 - binary_crossentropy: 0.7522 - val_loss: 0.7643 - val_acc: 0.5466 - val_binary_crossentropy: 0.7643\n",
      "Epoch 26/100\n",
      "22792/22792 [==============================] - 1s 55us/sample - loss: 0.7481 - acc: 0.5605 - binary_crossentropy: 0.7481 - val_loss: 0.7598 - val_acc: 0.5434 - val_binary_crossentropy: 0.7598\n",
      "Epoch 27/100\n",
      "22792/22792 [==============================] - 2s 67us/sample - loss: 0.7471 - acc: 0.5630 - binary_crossentropy: 0.7471 - val_loss: 0.7574 - val_acc: 0.5385 - val_binary_crossentropy: 0.7574\n",
      "Epoch 28/100\n",
      "22792/22792 [==============================] - 1s 50us/sample - loss: 0.7466 - acc: 0.5595 - binary_crossentropy: 0.7466 - val_loss: 0.7542 - val_acc: 0.5352 - val_binary_crossentropy: 0.7542\n",
      "Epoch 29/100\n",
      "22792/22792 [==============================] - 1s 48us/sample - loss: 0.7441 - acc: 0.5572 - binary_crossentropy: 0.7441 - val_loss: 0.7550 - val_acc: 0.5401 - val_binary_crossentropy: 0.7550\n",
      "Epoch 30/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.7399 - acc: 0.5617 - binary_crossentropy: 0.7399 - val_loss: 0.7488 - val_acc: 0.5401 - val_binary_crossentropy: 0.7488\n",
      "Epoch 31/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.7369 - acc: 0.5653 - binary_crossentropy: 0.7369 - val_loss: 0.7449 - val_acc: 0.5336 - val_binary_crossentropy: 0.7449\n",
      "Epoch 32/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.7374 - acc: 0.5637 - binary_crossentropy: 0.7374 - val_loss: 0.7475 - val_acc: 0.5352 - val_binary_crossentropy: 0.7475\n",
      "Epoch 33/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.7316 - acc: 0.5681 - binary_crossentropy: 0.7316 - val_loss: 0.7425 - val_acc: 0.5368 - val_binary_crossentropy: 0.7425\n",
      "Epoch 34/100\n",
      "22792/22792 [==============================] - ETA: 0s - loss: 0.7299 - acc: 0.5655 - binary_crossentropy: 0.729 - 1s 42us/sample - loss: 0.7292 - acc: 0.5664 - binary_crossentropy: 0.7292 - val_loss: 0.7420 - val_acc: 0.5319 - val_binary_crossentropy: 0.7420\n",
      "Epoch 35/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.7252 - acc: 0.5722 - binary_crossentropy: 0.7252 - val_loss: 0.7461 - val_acc: 0.5336 - val_binary_crossentropy: 0.7461\n",
      "Epoch 36/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.7243 - acc: 0.5671 - binary_crossentropy: 0.7243 - val_loss: 0.7399 - val_acc: 0.5319 - val_binary_crossentropy: 0.7399\n",
      "Epoch 37/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.7250 - acc: 0.5705 - binary_crossentropy: 0.7250 - val_loss: 0.7339 - val_acc: 0.5368 - val_binary_crossentropy: 0.7339\n",
      "Epoch 38/100\n",
      "22792/22792 [==============================] - 1s 50us/sample - loss: 0.7216 - acc: 0.5725 - binary_crossentropy: 0.7216 - val_loss: 0.7334 - val_acc: 0.5401 - val_binary_crossentropy: 0.7334\n",
      "Epoch 39/100\n",
      "22792/22792 [==============================] - 1s 61us/sample - loss: 0.7191 - acc: 0.5741 - binary_crossentropy: 0.7191 - val_loss: 0.7331 - val_acc: 0.5385 - val_binary_crossentropy: 0.7331\n",
      "Epoch 40/100\n",
      "22792/22792 [==============================] - 1s 50us/sample - loss: 0.7183 - acc: 0.5718 - binary_crossentropy: 0.7183 - val_loss: 0.7311 - val_acc: 0.5385 - val_binary_crossentropy: 0.7311\n",
      "Epoch 41/100\n",
      "22792/22792 [==============================] - 1s 47us/sample - loss: 0.7167 - acc: 0.5718 - binary_crossentropy: 0.7167 - val_loss: 0.7291 - val_acc: 0.5368 - val_binary_crossentropy: 0.7291\n",
      "Epoch 42/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.7139 - acc: 0.5715 - binary_crossentropy: 0.7139 - val_loss: 0.7302 - val_acc: 0.5336 - val_binary_crossentropy: 0.7302\n",
      "Epoch 43/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7139 - acc: 0.5717 - binary_crossentropy: 0.7139 - val_loss: 0.7282 - val_acc: 0.5352 - val_binary_crossentropy: 0.7282\n",
      "Epoch 44/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7109 - acc: 0.5759 - binary_crossentropy: 0.7109 - val_loss: 0.7268 - val_acc: 0.5368 - val_binary_crossentropy: 0.7268\n",
      "Epoch 45/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7099 - acc: 0.5756 - binary_crossentropy: 0.7099 - val_loss: 0.7238 - val_acc: 0.5336 - val_binary_crossentropy: 0.7238\n",
      "Epoch 46/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7104 - acc: 0.5770 - binary_crossentropy: 0.7104 - val_loss: 0.7272 - val_acc: 0.5401 - val_binary_crossentropy: 0.7272\n",
      "Epoch 47/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7064 - acc: 0.5749 - binary_crossentropy: 0.7064 - val_loss: 0.7193 - val_acc: 0.5434 - val_binary_crossentropy: 0.7193\n",
      "Epoch 48/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7043 - acc: 0.5804 - binary_crossentropy: 0.7043 - val_loss: 0.7252 - val_acc: 0.5336 - val_binary_crossentropy: 0.7252\n",
      "Epoch 49/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7061 - acc: 0.5769 - binary_crossentropy: 0.7061 - val_loss: 0.7229 - val_acc: 0.5385 - val_binary_crossentropy: 0.7229\n",
      "Epoch 50/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.7036 - acc: 0.5784 - binary_crossentropy: 0.7036 - val_loss: 0.7157 - val_acc: 0.5417 - val_binary_crossentropy: 0.7157\n",
      "Epoch 51/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7036 - acc: 0.5779 - binary_crossentropy: 0.7036 - val_loss: 0.7174 - val_acc: 0.5385 - val_binary_crossentropy: 0.7174\n",
      "Epoch 52/100\n",
      "22792/22792 [==============================] - 1s 40us/sample - loss: 0.7010 - acc: 0.5819 - binary_crossentropy: 0.7010 - val_loss: 0.7195 - val_acc: 0.5434 - val_binary_crossentropy: 0.7195\n",
      "Epoch 53/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.7005 - acc: 0.5821 - binary_crossentropy: 0.7005 - val_loss: 0.7169 - val_acc: 0.5417 - val_binary_crossentropy: 0.7169\n",
      "Epoch 54/100\n",
      "22792/22792 [==============================] - 1s 47us/sample - loss: 0.7004 - acc: 0.5805 - binary_crossentropy: 0.7004 - val_loss: 0.7150 - val_acc: 0.5466 - val_binary_crossentropy: 0.7150\n",
      "Epoch 55/100\n",
      "22792/22792 [==============================] - 1s 57us/sample - loss: 0.6990 - acc: 0.5810 - binary_crossentropy: 0.6990 - val_loss: 0.7151 - val_acc: 0.5417 - val_binary_crossentropy: 0.7151\n",
      "Epoch 56/100\n",
      "22792/22792 [==============================] - 1s 49us/sample - loss: 0.6962 - acc: 0.5837 - binary_crossentropy: 0.6962 - val_loss: 0.7159 - val_acc: 0.5466 - val_binary_crossentropy: 0.7159\n",
      "Epoch 57/100\n",
      "22792/22792 [==============================] - 1s 47us/sample - loss: 0.6983 - acc: 0.5802 - binary_crossentropy: 0.6983 - val_loss: 0.7153 - val_acc: 0.5516 - val_binary_crossentropy: 0.7153\n",
      "Epoch 58/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.6973 - acc: 0.5784 - binary_crossentropy: 0.6973 - val_loss: 0.7135 - val_acc: 0.5466 - val_binary_crossentropy: 0.7135\n",
      "Epoch 59/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6976 - acc: 0.5758 - binary_crossentropy: 0.6976 - val_loss: 0.7104 - val_acc: 0.5499 - val_binary_crossentropy: 0.7104\n",
      "Epoch 60/100\n",
      "22792/22792 [==============================] - 1s 40us/sample - loss: 0.6947 - acc: 0.5806 - binary_crossentropy: 0.6947 - val_loss: 0.7153 - val_acc: 0.5499 - val_binary_crossentropy: 0.7153\n",
      "Epoch 61/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6938 - acc: 0.5820 - binary_crossentropy: 0.6938 - val_loss: 0.7126 - val_acc: 0.5565 - val_binary_crossentropy: 0.7126\n",
      "Epoch 62/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6941 - acc: 0.5822 - binary_crossentropy: 0.6941 - val_loss: 0.7131 - val_acc: 0.5581 - val_binary_crossentropy: 0.7131\n",
      "Epoch 63/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6896 - acc: 0.5860 - binary_crossentropy: 0.6896 - val_loss: 0.7085 - val_acc: 0.5630 - val_binary_crossentropy: 0.7085\n",
      "Epoch 64/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6910 - acc: 0.5829 - binary_crossentropy: 0.6910 - val_loss: 0.7097 - val_acc: 0.5597 - val_binary_crossentropy: 0.7097\n",
      "Epoch 65/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6899 - acc: 0.5856 - binary_crossentropy: 0.6899 - val_loss: 0.7082 - val_acc: 0.5548 - val_binary_crossentropy: 0.7082\n",
      "Epoch 66/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6899 - acc: 0.5831 - binary_crossentropy: 0.6899 - val_loss: 0.7086 - val_acc: 0.5630 - val_binary_crossentropy: 0.7086\n",
      "Epoch 67/100\n",
      "22792/22792 [==============================] - 1s 40us/sample - loss: 0.6897 - acc: 0.5838 - binary_crossentropy: 0.6897 - val_loss: 0.7116 - val_acc: 0.5597 - val_binary_crossentropy: 0.7116\n",
      "Epoch 68/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6868 - acc: 0.5878 - binary_crossentropy: 0.6868 - val_loss: 0.7082 - val_acc: 0.5597 - val_binary_crossentropy: 0.7082\n",
      "Epoch 69/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6872 - acc: 0.5883 - binary_crossentropy: 0.6872 - val_loss: 0.7069 - val_acc: 0.5696 - val_binary_crossentropy: 0.7069\n",
      "Epoch 70/100\n",
      "22792/22792 [==============================] - 1s 51us/sample - loss: 0.6873 - acc: 0.5863 - binary_crossentropy: 0.6873 - val_loss: 0.7063 - val_acc: 0.5679 - val_binary_crossentropy: 0.7063\n",
      "Epoch 71/100\n",
      "22792/22792 [==============================] - 1s 65us/sample - loss: 0.6867 - acc: 0.5869 - binary_crossentropy: 0.6867 - val_loss: 0.7052 - val_acc: 0.5614 - val_binary_crossentropy: 0.7052\n",
      "Epoch 72/100\n",
      "22792/22792 [==============================] - 1s 55us/sample - loss: 0.6865 - acc: 0.5852 - binary_crossentropy: 0.6865 - val_loss: 0.7048 - val_acc: 0.5663 - val_binary_crossentropy: 0.7048\n",
      "Epoch 73/100\n",
      "22792/22792 [==============================] - 1s 55us/sample - loss: 0.6849 - acc: 0.5870 - binary_crossentropy: 0.6849 - val_loss: 0.7081 - val_acc: 0.5646 - val_binary_crossentropy: 0.7081\n",
      "Epoch 74/100\n",
      "22792/22792 [==============================] - 1s 46us/sample - loss: 0.6844 - acc: 0.5835 - binary_crossentropy: 0.6844 - val_loss: 0.7080 - val_acc: 0.5646 - val_binary_crossentropy: 0.7080\n",
      "Epoch 75/100\n",
      "22792/22792 [==============================] - 1s 43us/sample - loss: 0.6844 - acc: 0.5852 - binary_crossentropy: 0.6844 - val_loss: 0.7055 - val_acc: 0.5712 - val_binary_crossentropy: 0.7055\n",
      "Epoch 76/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6852 - acc: 0.5871 - binary_crossentropy: 0.6852 - val_loss: 0.7068 - val_acc: 0.5663 - val_binary_crossentropy: 0.7068\n",
      "Epoch 77/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.6832 - acc: 0.5871 - binary_crossentropy: 0.6832 - val_loss: 0.7053 - val_acc: 0.5581 - val_binary_crossentropy: 0.7053\n",
      "Epoch 78/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6832 - acc: 0.5870 - binary_crossentropy: 0.6832 - val_loss: 0.7103 - val_acc: 0.5614 - val_binary_crossentropy: 0.7103\n",
      "Epoch 79/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6826 - acc: 0.5879 - binary_crossentropy: 0.6826 - val_loss: 0.7090 - val_acc: 0.5663 - val_binary_crossentropy: 0.7090\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6818 - acc: 0.5893 - binary_crossentropy: 0.6818 - val_loss: 0.7064 - val_acc: 0.5630 - val_binary_crossentropy: 0.7064\n",
      "Epoch 81/100\n",
      "22792/22792 [==============================] - 1s 40us/sample - loss: 0.6813 - acc: 0.5914 - binary_crossentropy: 0.6813 - val_loss: 0.7039 - val_acc: 0.5630 - val_binary_crossentropy: 0.7039\n",
      "Epoch 82/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6796 - acc: 0.5890 - binary_crossentropy: 0.6796 - val_loss: 0.7063 - val_acc: 0.5679 - val_binary_crossentropy: 0.7063\n",
      "Epoch 83/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6826 - acc: 0.5899 - binary_crossentropy: 0.6826 - val_loss: 0.7046 - val_acc: 0.5614 - val_binary_crossentropy: 0.7046\n",
      "Epoch 84/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6821 - acc: 0.5858 - binary_crossentropy: 0.6821 - val_loss: 0.7033 - val_acc: 0.5630 - val_binary_crossentropy: 0.7033\n",
      "Epoch 85/100\n",
      "22792/22792 [==============================] - 1s 45us/sample - loss: 0.6808 - acc: 0.5863 - binary_crossentropy: 0.6808 - val_loss: 0.7029 - val_acc: 0.5663 - val_binary_crossentropy: 0.7029\n",
      "Epoch 86/100\n",
      "22792/22792 [==============================] - 1s 60us/sample - loss: 0.6801 - acc: 0.5899 - binary_crossentropy: 0.6801 - val_loss: 0.7056 - val_acc: 0.5581 - val_binary_crossentropy: 0.7056\n",
      "Epoch 87/100\n",
      "22792/22792 [==============================] - 1s 52us/sample - loss: 0.6785 - acc: 0.5903 - binary_crossentropy: 0.6785 - val_loss: 0.7052 - val_acc: 0.5630 - val_binary_crossentropy: 0.7052\n",
      "Epoch 88/100\n",
      "22792/22792 [==============================] - 1s 49us/sample - loss: 0.6802 - acc: 0.5919 - binary_crossentropy: 0.6802 - val_loss: 0.7011 - val_acc: 0.5646 - val_binary_crossentropy: 0.7011\n",
      "Epoch 89/100\n",
      "22792/22792 [==============================] - 1s 52us/sample - loss: 0.6798 - acc: 0.5890 - binary_crossentropy: 0.6798 - val_loss: 0.7013 - val_acc: 0.5663 - val_binary_crossentropy: 0.7013\n",
      "Epoch 90/100\n",
      "22792/22792 [==============================] - 1s 49us/sample - loss: 0.6797 - acc: 0.5897 - binary_crossentropy: 0.6797 - val_loss: 0.7013 - val_acc: 0.5712 - val_binary_crossentropy: 0.7013\n",
      "Epoch 91/100\n",
      "22792/22792 [==============================] - 1s 59us/sample - loss: 0.6791 - acc: 0.5899 - binary_crossentropy: 0.6791 - val_loss: 0.7019 - val_acc: 0.5696 - val_binary_crossentropy: 0.7019\n",
      "Epoch 92/100\n",
      "22792/22792 [==============================] - 2s 68us/sample - loss: 0.6777 - acc: 0.5898 - binary_crossentropy: 0.6777 - val_loss: 0.7038 - val_acc: 0.5630 - val_binary_crossentropy: 0.7038\n",
      "Epoch 93/100\n",
      "22792/22792 [==============================] - 1s 51us/sample - loss: 0.6780 - acc: 0.5897 - binary_crossentropy: 0.6780 - val_loss: 0.7047 - val_acc: 0.5646 - val_binary_crossentropy: 0.7047\n",
      "Epoch 94/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6780 - acc: 0.5909 - binary_crossentropy: 0.6780 - val_loss: 0.7038 - val_acc: 0.5614 - val_binary_crossentropy: 0.7038\n",
      "Epoch 95/100\n",
      "22792/22792 [==============================] - 1s 41us/sample - loss: 0.6780 - acc: 0.5931 - binary_crossentropy: 0.6780 - val_loss: 0.7013 - val_acc: 0.5679 - val_binary_crossentropy: 0.7013\n",
      "Epoch 96/100\n",
      "22792/22792 [==============================] - 1s 44us/sample - loss: 0.6790 - acc: 0.5906 - binary_crossentropy: 0.6790 - val_loss: 0.7006 - val_acc: 0.5630 - val_binary_crossentropy: 0.7006\n",
      "Epoch 97/100\n",
      "22792/22792 [==============================] - 1s 45us/sample - loss: 0.6769 - acc: 0.5941 - binary_crossentropy: 0.6769 - val_loss: 0.7020 - val_acc: 0.5646 - val_binary_crossentropy: 0.7020\n",
      "Epoch 98/100\n",
      "22792/22792 [==============================] - 1s 40us/sample - loss: 0.6778 - acc: 0.5893 - binary_crossentropy: 0.6778 - val_loss: 0.7001 - val_acc: 0.5630 - val_binary_crossentropy: 0.7001\n",
      "Epoch 99/100\n",
      "22792/22792 [==============================] - 1s 42us/sample - loss: 0.6774 - acc: 0.5943 - binary_crossentropy: 0.6774 - val_loss: 0.7000 - val_acc: 0.5696 - val_binary_crossentropy: 0.7000\n",
      "Epoch 100/100\n",
      "22792/22792 [==============================] - 1s 61us/sample - loss: 0.6769 - acc: 0.5915 - binary_crossentropy: 0.6769 - val_loss: 0.7021 - val_acc: 0.5614 - val_binary_crossentropy: 0.7020\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 16)                160       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 929\n",
      "Trainable params: 833\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "train, loss and metric : [0.7020500614483111, 0.5613748, 0.7020501]\n"
     ]
    }
   ],
   "source": [
    "# l2_model = keras.models.Sequential([\n",
    "#     keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "#                        activation=tf.nn.relu, input_shape=(186,)),\n",
    "#     keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "#                        activation=tf.nn.relu),\n",
    "#     keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "# ])\n",
    "\n",
    "\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "\n",
    "#     model = Sequential([\n",
    "#     Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "#                        activation=tf.nn.relu, input_shape=(186,)),\n",
    "#     Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "#                        activation=tf.nn.relu),\n",
    "#     Dense(1, activation=tf.nn.sigmoid)\n",
    "# ])\n",
    "\n",
    "    model.add(Dense(16, input_shape = (9, )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(32))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dense(50, input_shape = (186, )))\n",
    "#     model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "#     model.add(Activation('sigmoid'))    \n",
    "#     model.add(Dense(50))\n",
    "#     model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "#     model.add(Activation('sigmoid'))    \n",
    "#     model.add(Dense(50))\n",
    "#     model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "#     model.add(Activation('sigmoid'))    \n",
    "#     model.add(Dense(50))\n",
    "    model.add(BatchNormalization())                    # Add Batchnorm layer before Activation\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))   \n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(1))\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "#     sgd=optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "    model.compile(optimizer=Adadelta(rho=0.95),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['accuracy', 'binary_crossentropy'])\n",
    "    return model\n",
    "\n",
    "# mlp_model(l2_model)\n",
    "\n",
    "# sgd=optimizers.SGD(lr=0.01)\n",
    "\n",
    "# l2_model.compile(optimizer='sgd',\n",
    "#                  loss='binary_crossentropy',\n",
    "#                  metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "l2_model = mlp_model()\n",
    "\n",
    "l2_model_history = l2_model.fit(xData, yData,\n",
    "                                epochs=100,\n",
    "                                shuffle = True,\n",
    "                                batch_size=32,\n",
    "                                validation_data=(testX, testY),\n",
    "                                verbose=1)\n",
    "\n",
    "l2_model.summary()\n",
    "\n",
    "loss_and_metric = l2_model.evaluate(testX, testY, batch_size = 32, verbose = 0)\n",
    "print(\"train, loss and metric : {}\".format(loss_and_metric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(train_data)):\n",
    "#     new_x=testX[i, :].reshape(1,186)\n",
    "#     print('입양 확률 : %8.4f%%' % (l2_model.predict(new_x)*100))\n",
    "l2_model.save('l2_model_yj')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
